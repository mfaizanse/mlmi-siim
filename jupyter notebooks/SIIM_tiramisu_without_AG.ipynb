{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SIIM_tiramisu_without_AG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "59580f0884c14615a1e237646dadf147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_929b46f3353d4c31abae1453f3d96cb9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4d2715d8bc1e474e96466a6d46f65ae4",
              "IPY_MODEL_e204d6281eb7481d988a81808c4bcc7f"
            ]
          }
        },
        "929b46f3353d4c31abae1453f3d96cb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d2715d8bc1e474e96466a6d46f65ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0d82dba3cee742178b7eca8fc7eaefbe",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 200,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 200,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dbcd730c65d64cffa319c70faee0c10b"
          }
        },
        "e204d6281eb7481d988a81808c4bcc7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a9c22c4e4a234b3582545609ed75b3e7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 200/200 [00:57&lt;00:00,  3.45it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_24af49fe009f4397a59dc115915a7bf4"
          }
        },
        "0d82dba3cee742178b7eca8fc7eaefbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dbcd730c65d64cffa319c70faee0c10b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a9c22c4e4a234b3582545609ed75b3e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "24af49fe009f4397a59dc115915a7bf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsLPgbdgxb4D",
        "colab_type": "text"
      },
      "source": [
        "# Tiramisu (without Attention Gates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeZ0dtNrgZ9u",
        "colab_type": "text"
      },
      "source": [
        "## Install dependencies and import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7gsu-kmmD3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u92getfvZrFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tqdm -U\n",
        "!pip install nibabel\n",
        "!pip install h5py\n",
        "!pip install dominate\n",
        "!pip install pydicom\n",
        "!pip install https://github.com/ozan-oktay/torchsample/tarball/master#egg=torchsample-0.1.3\n",
        "!pip install git+https://github.com/baldassarreFe/pytorch-densenet-tiramisu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXBjENLveAnP",
        "colab_type": "code",
        "outputId": "35922ab5-eb46-465b-d9c1-ab1c91b66e70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import json\n",
        "import collections\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pydicom\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import matplotlib.pyplot as plt\n",
        "import numbers\n",
        "import PIL\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch Version:  1.4.0\n",
            "Torchvision Version:  0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_3QqLS-V6yC",
        "colab_type": "text"
      },
      "source": [
        "## Setup dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGduGTl4WqGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# local machine directories\n",
        "DATA_DIR = \"/content/data/\"\n",
        "DATA_MASKS_DIR = DATA_DIR + \"masks\"\n",
        "DATA_DICOM_DIR = DATA_DIR + \"input\"\n",
        "\n",
        "# google drive directories\n",
        "DATA_ZIP_FILE_PATH = \"/content/gdrive/My Drive/mlmi/dataset/input.zip\"\n",
        "MASKS_DIR = \"/content/gdrive/My Drive/mlmi/dataset/masks/\"\n",
        "TENSORBOARD_LOGS_DIR = \"/content/gdrive/My Drive/mlmi/results/tensorboard/\"\n",
        "MODEL_SAVE_DIR = \"/content/gdrive/My Drive/mlmi/results/model/\"\n",
        "IMG_RESULT_SAVE_DIR = r'/content/gdrive/My Drive/mlmi/results/imgs/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XITnSUqxZkXe",
        "colab_type": "text"
      },
      "source": [
        "Copy masks from gdrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yof8muQ0sdOs",
        "colab_type": "code",
        "outputId": "e93a213a-bd2f-40bf-c408-8242463f9421",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# create data directory locally\n",
        "if os.path.exists(DATA_DIR) == False:\n",
        "  os.makedirs(DATA_DIR)\n",
        "  print(\"Create directory: \" + DATA_DIR)\n",
        "\n",
        "if os.path.exists(DATA_MASKS_DIR):\n",
        "  shutil.rmtree(DATA_MASKS_DIR)\n",
        "  print(\"Deleted old masks directory: \" + DATA_MASKS_DIR)\n",
        "\n",
        "!cp -r \"$MASKS_DIR\" $DATA_DIR\n",
        "%ls $DATA_MASKS_DIR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create directory: /content/data/\n",
            "simm_DS_test.csv  simm_DS_train.csv  simm_DS_validation.csv  train-rle.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_wBRjKYXuFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ## uncomment this code to reduce the train set size\n",
        "# includeImagesCounts = 50\n",
        "# trainSetCsv = pd.read_csv(DATA_MASKS_DIR + '/simm_DS_train.csv')\n",
        "# tsReduced = trainSetCsv[:includeImagesCounts]\n",
        "# # tsReduced[:5]\n",
        "\n",
        "# tsReduced.to_csv(DATA_MASKS_DIR + '/simm_DS_train.csv', index = None, header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBzkrPwNfdZ_",
        "colab_type": "text"
      },
      "source": [
        "Extract DICOM files from zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg8ThUO3mJhT",
        "colab_type": "code",
        "outputId": "148c226b-a469-4683-ea58-e0e683708d03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# only extract if input folder doesn't exists\n",
        "if os.path.exists(DATA_DICOM_DIR) == False:\n",
        "  #!unzip \"$DATA_ZIP_FILE_PATH\" -d \"$DATA_DIR\"\n",
        "  zip_ref = zipfile.ZipFile(DATA_ZIP_FILE_PATH, 'r')\n",
        "  zip_ref.extractall(DATA_DIR)\n",
        "  zip_ref.close()\n",
        "  print(\"Extracted dicom zip file to directory: \" + DATA_DICOM_DIR)\n",
        "\n",
        "%ls $DATA_DICOM_DIR\n",
        "#%ls \"$DATA_DICOM_DIR/siim/dicom-images-train\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracted dicom zip file to directory: /content/data/input\n",
            "\u001b[0m\u001b[01;34msiim\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6dCJ9tQhEyJ",
        "colab_type": "text"
      },
      "source": [
        "## Model Definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq628aADYjqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rle2mask(rle, width, height):\n",
        "    mask= np.zeros(width* height)\n",
        "    array = np.asarray([int(x) for x in rle.split()])\n",
        "    starts = array[0::2]\n",
        "    lengths = array[1::2]\n",
        "\n",
        "    current_position = 0\n",
        "    for index, start in enumerate(starts):\n",
        "        current_position += start\n",
        "        mask[current_position:current_position+lengths[index]] = 255\n",
        "        current_position += lengths[index]\n",
        "\n",
        "    return mask.reshape(width, height)\n",
        "    \n",
        "class SIMMDataset(Dataset):\n",
        "    \"\"\"SIMM dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, root_dir, split, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            dicomPaths (Array<string>): Array of DICOM file Paths.\n",
        "            mask_csv_file (string): csv file with encoded masks (rle).\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "\n",
        "        self.root_dir = root_dir\n",
        "        self.dir_postfix = 'input/siim/'\n",
        "\n",
        "        self.im_height = 1024\n",
        "        self.im_width = 1024\n",
        "        self.im_chan = 1\n",
        "\n",
        "        ## Read masks file\n",
        "        mask_csv_file = root_dir + 'masks/train-rle.csv' \n",
        "        print(\"Reading masks from: \" + mask_csv_file)\n",
        "        self.encodedMasks = pd.read_csv(mask_csv_file, names=['ImageId', 'EncodedPixels'], index_col='ImageId')\n",
        "\n",
        "        ## Read dataset file names\n",
        "        dsFile = root_dir + 'masks/simm_DS_' + split + '.csv'\n",
        "        print(\"Reading ds from: \" + dsFile)\n",
        "        dsFileData = pd.read_csv(dsFile)\n",
        "        self.dicomPaths = dsFileData['path'].tolist()\n",
        "        # print(\"READ\")\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dicomPaths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        # Read dicom file\n",
        "        dPath = self.dicomPaths[idx]\n",
        "        dicom = pydicom.dcmread(self.root_dir + self.dir_postfix + dPath)\n",
        "        \n",
        "        # get image from dicom to numpy array\n",
        "        image = np.array(dicom.pixel_array)\n",
        "        \n",
        "        # get mask (in rle) from csv\n",
        "        landmarks = np.zeros((self.im_height, self.im_width), dtype=np.bool)\n",
        "        \n",
        "        fileId = dPath.split('/')[-1][:-4]\n",
        "        rle = self.encodedMasks.loc[fileId, 'EncodedPixels']\n",
        "        try:\n",
        "            if type(rle) == str: # if single rle\n",
        "                decodedRle = rle2mask(rle, self.im_height, self.im_width)\n",
        "#                 landmarks = np.expand_dims(decodedRle, axis=2)\n",
        "                landmarks = decodedRle\n",
        "            else: # if multiple rle\n",
        "                for x in rle:\n",
        "                    decodedRle = rle2mask(x, self.im_height, self.im_width)\n",
        "                    landmarks = landmarks + decodedRle\n",
        "#                     landmarks = landmarks + np.expand_dims(decodedRle, axis=2)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            \n",
        "        ## BECAUSE WHEN PLOTING THE GRAPHS WE HAVE TO TRANSPOSE IT.\n",
        "        landmarks = landmarks.T\n",
        "\n",
        "        # for some images, we have multiple masks, so we are adding the masks\n",
        "        # which results in some pixels to > 1\n",
        "        landmarks = (landmarks >= 1).astype('float32')\n",
        "\n",
        "        image = np.array(image)\n",
        "        landmarks = np.array(landmarks)\n",
        "\n",
        "        # converting numpy array to PIL image\n",
        "        image = PIL.Image.fromarray(image)\n",
        "        landmarks = PIL.Image.fromarray(landmarks)\n",
        "\n",
        "        # resizing image to 224\n",
        "        size = (224, 224)\n",
        "        image = image.resize(size, PIL.Image.BILINEAR)\n",
        "        landmarks = landmarks.resize(size, PIL.Image.BILINEAR)\n",
        "\n",
        "        if self.transform:\n",
        "          # torchvision transforms needs PIL image\n",
        "          # apply transformation\n",
        "          image, landmarks = self.transform(image, landmarks)\n",
        "\n",
        "        # convert image to 3 channel\n",
        "        image = image.convert('RGB')\n",
        "\n",
        "        # converting back to numpy array from PIL image\n",
        "        image = np.array(image)\n",
        "        landmarks = np.array(landmarks)\n",
        "\n",
        "        # swap color axis because\n",
        "        # numpy image: H x W x C\n",
        "        # but torch image: C X H X W\n",
        "        image = np.transpose(image, (2, 0, 1))\n",
        "\n",
        "        landmarks = np.expand_dims(landmarks, axis=0)\n",
        "        image = image / 255\n",
        "\n",
        "        return image, landmarks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqMnprX7aF2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from dense import DenseLayer, DenseBlock, TransitionUp, TransitionDown\n",
        "from torch.nn import Module, Conv2d, BatchNorm2d, Linear, init\n",
        "from torch.nn import Sequential\n",
        "from typing import Optional, Sequence, Union\n",
        "\n",
        "## https://github.com/baldassarreFe/pytorch-densenet-tiramisu\n",
        "class FCDenseNet(Module):\n",
        "    def __init__(self,\n",
        "                 in_channels: int = 3,\n",
        "                 out_channels: int = 1,\n",
        "                 initial_num_features: int = 48,\n",
        "                 dropout: float = 0.2,\n",
        "\n",
        "                 down_dense_growth_rates: Union[int, Sequence[int]] = 16,\n",
        "                 down_dense_bottleneck_ratios: Union[Optional[int], Sequence[Optional[int]]] = None,\n",
        "                 down_dense_num_layers: Union[int, Sequence[int]] = (4, 5, 7, 10, 12),\n",
        "                 down_transition_compression_factors: Union[float, Sequence[float]] = 1.0,\n",
        "\n",
        "                 middle_dense_growth_rate: int = 16,\n",
        "                 middle_dense_bottleneck: Optional[int] = None,\n",
        "                 middle_dense_num_layers: int = 15,\n",
        "\n",
        "                 up_dense_growth_rates: Union[int, Sequence[int]] = 16,\n",
        "                 up_dense_bottleneck_ratios: Union[Optional[int], Sequence[Optional[int]]] = None,\n",
        "                 up_dense_num_layers: Union[int, Sequence[int]] = (12, 10, 7, 5, 4)):\n",
        "      \n",
        "        super(FCDenseNet, self).__init__()\n",
        "\n",
        "        # region Parameters handling\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        if type(down_dense_growth_rates) == int:\n",
        "            down_dense_growth_rates = (down_dense_growth_rates,) * 5\n",
        "        if down_dense_bottleneck_ratios is None or type(down_dense_bottleneck_ratios) == int:\n",
        "            down_dense_bottleneck_ratios = (down_dense_bottleneck_ratios,) * 5\n",
        "        if type(down_dense_num_layers) == int:\n",
        "            down_dense_num_layers = (down_dense_num_layers,) * 5\n",
        "        if type(down_transition_compression_factors) == float:\n",
        "            down_transition_compression_factors = (down_transition_compression_factors,) * 5\n",
        "\n",
        "        if type(up_dense_growth_rates) == int:\n",
        "            up_dense_growth_rates = (up_dense_growth_rates,) * 5\n",
        "        if up_dense_bottleneck_ratios is None or type(up_dense_bottleneck_ratios) == int:\n",
        "            up_dense_bottleneck_ratios = (up_dense_bottleneck_ratios,) * 5\n",
        "        if type(up_dense_num_layers) == int:\n",
        "            up_dense_num_layers = (up_dense_num_layers,) * 5\n",
        "        # endregion\n",
        "\n",
        "        # region First convolution\n",
        "        self.features = Conv2d(in_channels, initial_num_features, kernel_size=3, padding=1, bias=False)\n",
        "        current_channels = self.features.out_channels\n",
        "        # endregion\n",
        "\n",
        "        # region Downward path\n",
        "        # Pairs of Dense Blocks with input concatenation and TransitionDown layers\n",
        "        down_dense_params = [\n",
        "            {\n",
        "                'concat_input': True,\n",
        "                'growth_rate': gr,\n",
        "                'num_layers': nl,\n",
        "                'dense_layer_params': {\n",
        "                    'dropout': dropout,\n",
        "                    'bottleneck_ratio': br\n",
        "                }\n",
        "            }\n",
        "            for gr, nl, br in\n",
        "            zip(down_dense_growth_rates, down_dense_num_layers, down_dense_bottleneck_ratios)\n",
        "        ]\n",
        "\n",
        "        down_transition_params = [\n",
        "            {\n",
        "                'dropout': dropout,\n",
        "                'compression': c\n",
        "            } for c in down_transition_compression_factors\n",
        "        ]\n",
        "\n",
        "        skip_connections_channels = []\n",
        "\n",
        "        self.down_dense = Module()\n",
        "        self.down_trans = Module()\n",
        "\n",
        "        down_pairs_params = zip(down_dense_params, down_transition_params)\n",
        "        for i, (dense_params, transition_params) in enumerate(down_pairs_params):\n",
        "            block = DenseBlock(current_channels, **dense_params)\n",
        "            current_channels = block.out_channels\n",
        "            self.down_dense.add_module(f'block_{i}', block)\n",
        "\n",
        "            skip_connections_channels.append(block.out_channels)\n",
        "\n",
        "            transition = TransitionDown(current_channels, **transition_params)\n",
        "            current_channels = transition.out_channels\n",
        "            self.down_trans.add_module(f'trans_{i}', transition)\n",
        "        # endregion\n",
        "\n",
        "        # region Middle block\n",
        "        # Renamed from \"bottleneck\" in the paper, to avoid confusion with the Bottleneck of DenseLayers\n",
        "        self.middle = DenseBlock(\n",
        "            current_channels,\n",
        "            middle_dense_growth_rate,\n",
        "            middle_dense_num_layers,\n",
        "            concat_input=True,\n",
        "            dense_layer_params={\n",
        "                'dropout': dropout,\n",
        "                'bottleneck_ratio': middle_dense_bottleneck\n",
        "            })\n",
        "        current_channels = self.middle.out_channels\n",
        "        # endregion\n",
        "\n",
        "        # region Upward path\n",
        "        # Pairs of TransitionUp layers and Dense Blocks without input concatenation\n",
        "        up_transition_params = [\n",
        "            {\n",
        "                'skip_channels': sc,\n",
        "            } for sc in reversed(skip_connections_channels)\n",
        "        ]\n",
        "        up_dense_params = [\n",
        "            {\n",
        "                'concat_input': False,\n",
        "                'growth_rate': gr,\n",
        "                'num_layers': nl,\n",
        "                'dense_layer_params': {\n",
        "                    'dropout': dropout,\n",
        "                    'bottleneck_ratio': br\n",
        "                }\n",
        "            }\n",
        "            for gr, nl, br in\n",
        "            zip(up_dense_growth_rates, up_dense_num_layers, up_dense_bottleneck_ratios)\n",
        "        ]\n",
        "\n",
        "        self.up_dense = Module()\n",
        "        self.up_trans = Module()\n",
        "        up_pairs_params = zip(up_transition_params, up_dense_params)\n",
        "        for i, (transition_params_up, dense_params_up) in enumerate(up_pairs_params):\n",
        "            transition = TransitionUp(current_channels, **transition_params_up)\n",
        "            current_channels = transition.out_channels\n",
        "            self.up_trans.add_module(f'trans_{i}', transition)\n",
        "\n",
        "            block = DenseBlock(current_channels, **dense_params_up)\n",
        "            current_channels = block.out_channels\n",
        "            self.up_dense.add_module(f'block_{i}', block)\n",
        "        # endregion\n",
        "\n",
        "        # region Final convolution\n",
        "        self.final = Conv2d(current_channels, out_channels, kernel_size=1, bias=False)\n",
        "        # endregion\n",
        "\n",
        "        # region Weight initialization\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, Conv2d):\n",
        "                init.kaiming_normal_(module.weight)\n",
        "            elif isinstance(module, BatchNorm2d):\n",
        "                module.reset_parameters()\n",
        "            elif isinstance(module, Linear):\n",
        "                init.xavier_uniform_(module.weight)\n",
        "                init.constant_(module.bias, 0)\n",
        "        # endregion\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = self.features(x)\n",
        "\n",
        "        skip_tensors = []\n",
        "        for dense, trans in zip(self.down_dense.children(), self.down_trans.children()):\n",
        "            res = dense(res)\n",
        "            skip_tensors.append(res)\n",
        "            res = trans(res)\n",
        "\n",
        "        res = self.middle(res)\n",
        "\n",
        "        for skip, trans, dense in zip(reversed(skip_tensors), self.up_trans.children(), self.up_dense.children()):\n",
        "            res = trans(res, skip)\n",
        "            res = dense(res)\n",
        "\n",
        "        res = self.final(res)\n",
        "\n",
        "        return torch.sigmoid(res)\n",
        "\n",
        "    # def predict(self, x):\n",
        "    #     logits = self(x)\n",
        "    #     return F.softmax(logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DXmfSVodOwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model to use\n",
        "class FCDenseNet103(FCDenseNet):\n",
        "    def __init__(self, in_channels=3, out_channels=1000, dropout=0.0):\n",
        "        super(FCDenseNet103, self).__init__(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=out_channels,\n",
        "            initial_num_features=48,\n",
        "            dropout=dropout,\n",
        "\n",
        "            down_dense_growth_rates=16,\n",
        "            down_dense_bottleneck_ratios=None,\n",
        "            down_dense_num_layers=(4, 5, 7, 10, 12),\n",
        "            down_transition_compression_factors=1.0,\n",
        "\n",
        "            middle_dense_growth_rate=16,\n",
        "            middle_dense_bottleneck=None,\n",
        "            middle_dense_num_layers=15,\n",
        "\n",
        "            up_dense_growth_rates=16,\n",
        "            up_dense_bottleneck_ratios=None,\n",
        "            up_dense_num_layers=(12, 10, 7, 5, 4)\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOuDOXyMaAtw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SIMMSoftDiceLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SIMMSoftDiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        smooth = 0.01\n",
        "        batch_size = input.size(0)\n",
        "\n",
        "        # input = torch.sigmoid(input).view(batch_size, -1)\n",
        "        input = input.view(batch_size, -1)\n",
        "        labels = target.contiguous().view(batch_size, -1)\n",
        "\n",
        "        inter = torch.sum(input * labels, 1) + smooth\n",
        "        union = torch.sum(input, 1) + torch.sum(labels, 1) + smooth\n",
        "\n",
        "        score = torch.sum(2.0 * inter / union, 0)\n",
        "        score = 1.0 - score / float(batch_size)\n",
        "        \n",
        "        return score\n",
        "\n",
        "class SIMMHardDiceScore(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SIMMHardDiceScore, self).__init__()\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        smooth = 0.01\n",
        "\n",
        "        # convert input to hard classification\n",
        "        hardClf = input.clone()\n",
        "        hardClf[hardClf > 0.5] = 1\n",
        "        hardClf[hardClf <= 0.5] = 0\n",
        "\n",
        "        labels = target.clone()\n",
        "        batch_size = hardClf.size(0)\n",
        "\n",
        "        # input = torch.sigmoid(input).view(batch_size, -1)\n",
        "        hardClf = hardClf.view(batch_size, -1)\n",
        "        labels = labels.contiguous().view(batch_size, -1)\n",
        "\n",
        "        inter = torch.sum(hardClf * labels, 1) + smooth\n",
        "        union = torch.sum(hardClf, 1) + torch.sum(labels, 1) + smooth\n",
        "\n",
        "        score = torch.sum(2.0 * inter / union, 0)\n",
        "        score = score / float(batch_size)\n",
        "        \n",
        "        return score\n",
        "\n",
        "class SIMMCrossEntropyLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SIMMCrossEntropyLoss, self).__init__()\n",
        "        self.BCE = nn.BCELoss()\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        t = target.float()\n",
        "        return self.BCE(input, t)\n",
        "\n",
        "class SIMMDiceAndEntropyLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SIMMDiceAndEntropyLoss, self).__init__()\n",
        "        self.diceLoss = SIMMSoftDiceLoss()\n",
        "        self.BCE = SIMMCrossEntropyLoss()\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        bceLoss = self.BCE(input, target)\n",
        "        dLoss = self.diceLoss(input, target)\n",
        "\n",
        "        combinedLoss = 0.5 * bceLoss + 0.5 * dLoss\n",
        "        return combinedLoss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyWrBfFyLM-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def json_file_to_pyobj(jsonStr):\n",
        "    def _json_object_hook(d): return collections.namedtuple('X', d.keys())(*d.values())\n",
        "    def json2obj(data): return json.loads(data, object_hook=_json_object_hook)\n",
        "    return json2obj(jsonStr)\n",
        "    \n",
        "def create_checkpoint(run_name, model, optimizer, is_best, epoch, network_options, train_loss, valid_loss, best_valid_loss):\n",
        "\n",
        "  save_dir = os.path.join(MODEL_SAVE_DIR, run_name)\n",
        "  if os.path.exists(save_dir) == False:\n",
        "    os.makedirs(save_dir)\n",
        "    print('Creating save dir: ' + save_dir)\n",
        "\n",
        "  print('Saving model checkpoint at epoch: ' + str(epoch))\n",
        "  state = {\n",
        "      'run_name': run_name,\n",
        "      'model_state': model.state_dict(),\n",
        "      'optimizer_state': optimizer.state_dict(),\n",
        "      'epoch': epoch,\n",
        "      'rng_state': torch.get_rng_state(),\n",
        "      'network_options': network_options,\n",
        "      'train_loss': train_loss,\n",
        "      'valid_loss': valid_loss,\n",
        "      'best_valid_loss': best_valid_loss\n",
        "  }\n",
        "\n",
        "  torch.save(state, os.path.join(MODEL_SAVE_DIR, run_name, 'checkpoint.pt'))\n",
        "  if is_best:\n",
        "    torch.save(state, os.path.join(MODEL_SAVE_DIR, run_name, 'checkpoint_best.pt'))\n",
        "\n",
        "def load_checkpoint(run_name, model, optimizer, load_best=False):\n",
        "  ckh_path = os.path.join(MODEL_SAVE_DIR, run_name, 'checkpoint.pt')\n",
        "  if load_best:\n",
        "    ckh_path = os.path.join(MODEL_SAVE_DIR, run_name, 'checkpoint_best.pt')\n",
        "  checkpoint = torch.load(ckh_path)\n",
        "  model.load_state_dict(checkpoint['model_state'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
        "  torch.set_rng_state(checkpoint['rng_state'])\n",
        "\n",
        "  return model, optimizer, checkpoint\n",
        "\n",
        "def print_checkpoint(checkpoint):\n",
        "  print(\"Run Name: \" + str(checkpoint['run_name']))\n",
        "  print(\"Last epoch: \" + str(checkpoint['epoch']))\n",
        "  print(\"Train Loss: \" + str(checkpoint['train_loss']))\n",
        "  print(\"Validation Loss: \" + str(checkpoint['valid_loss']))\n",
        "  print(\"Best Validation Loss: \" + str(checkpoint['best_valid_loss']))\n",
        "  print(\"Options: \" + str(checkpoint['network_options']))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD7YUvq0tLnR",
        "colab_type": "text"
      },
      "source": [
        "Transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1RkAFHbtKWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SegCompose(object):\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __call__(self, image, target):\n",
        "        for t in self.transforms:\n",
        "            image, target = t(image, target)\n",
        "        return image, target\n",
        "\n",
        "class SegRandomAffine(object):\n",
        "  def __init__(self, degrees, translate=None, scale=None, resample=False, fillcolor=0):\n",
        "    # NOTE: shear is REMOVED FOR NOW\n",
        "\n",
        "    # just to check the values using this contructor\n",
        "    self.segTransform = T.RandomAffine(degrees, translate, scale, None, resample, fillcolor)\n",
        "\n",
        "    if isinstance(degrees, numbers.Number):\n",
        "        self.degrees = (-degrees, degrees)\n",
        "    else:\n",
        "        self.degrees = degrees\n",
        "        \n",
        "    self.translate = translate\n",
        "    self.scale = scale\n",
        "    self.resample = resample\n",
        "    self.fillcolor = fillcolor\n",
        "\n",
        "  def __call__(self, image, target):\n",
        "        ret = T.RandomAffine.get_params(self.degrees, self.translate, self.scale, None, image.size)\n",
        "        image = T.functional.affine(image, *ret, resample=self.resample, fillcolor=self.fillcolor)\n",
        "        target = T.functional.affine(target, *ret, resample=self.resample, fillcolor=self.fillcolor)\n",
        "\n",
        "        return image, target\n",
        "\n",
        "class SegToTensor(object):\n",
        "  def __init__(self):\n",
        "    self.ToTensor = T.ToTensor()\n",
        "  def __call__(self, image, target):\n",
        "        image = self.ToTensor(image)\n",
        "        target = self.ToTensor(target)\n",
        "\n",
        "        return image, target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6gvdAuEhtzH",
        "colab_type": "text"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuFU4n1AXaG_",
        "colab_type": "code",
        "outputId": "7287e644-ba2b-4a18-9b7b-c3ad909edd22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "use_cuda = False\n",
        "if torch.cuda.is_available():\n",
        "  gpu_count = torch.cuda.device_count()\n",
        "  print(\"Available GPU count:\" + str(gpu_count))\n",
        "  use_cuda = True\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Available GPU count:1\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-M4zJvJh1v9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Model Hyperparameters\n",
        "\n",
        "NETWORK_OPTIONS = dict()\n",
        "NETWORK_OPTIONS['USE_CUDA'] = use_cuda\n",
        "\n",
        "# Set to false if only need to run on train dataset\n",
        "NETWORK_OPTIONS['USE_VAL_SET'] = True\n",
        "\n",
        "NETWORK_OPTIONS['LR_RATE'] = 1e-4\n",
        "NETWORK_OPTIONS['L2_REG_WEIGHT'] = 1e-6\n",
        "NETWORK_OPTIONS['DROPOUT'] = 0.2\n",
        "\n",
        "NETWORK_OPTIONS['BATCH_SIZE'] = 8\n",
        "\n",
        "# dont forget to set run_name when continue_train is true\n",
        "NETWORK_OPTIONS['CONTINUE_TRAIN'] = False\n",
        "NETWORK_OPTIONS['LOAD_BEST'] = False\n",
        "NETWORK_OPTIONS['RUN_NAME'] = '' # If CONTINUE_TRAIN, then provide name of run to continue\n",
        "NETWORK_OPTIONS['START_EPOCH'] = 0\n",
        "NETWORK_OPTIONS['NUM_EPOCHS'] = 0\n",
        "\n",
        "NETWORK_OPTIONS['DATALOADER_NUM_WORKERS'] = 1\n",
        "NETWORK_OPTIONS['DATA_DIR'] = DATA_DIR\n",
        "NETWORK_OPTIONS['TENSORBOARD_LOGS_DIR'] = TENSORBOARD_LOGS_DIR\n",
        "NETWORK_OPTIONS['MODEL_SAVE_DIR'] = MODEL_SAVE_DIR\n",
        "\n",
        "# converting dict() to python object (just for easy access)\n",
        "NETWORK_OPTIONS_OBJ = json_file_to_pyobj(json.dumps(NETWORK_OPTIONS))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SNziec4bb8n",
        "colab_type": "code",
        "outputId": "01b5b4f8-dbed-45d4-abd1-161200c469d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Defining Dataloaders\n",
        "\n",
        "rotate_val = 20.0\n",
        "translation_val = [0.1,0.1]\n",
        "scale_val = [0.7,1.3]\n",
        "\n",
        "train_transform = SegCompose([\n",
        "                              SegRandomAffine(degrees=rotate_val, translate=translation_val, scale=scale_val)\n",
        "                             ])\n",
        "# train_transform = None\n",
        "\n",
        "train_dataset = SIMMDataset(NETWORK_OPTIONS_OBJ.DATA_DIR, split='train', transform=train_transform)\n",
        "valid_dataset = SIMMDataset(NETWORK_OPTIONS_OBJ.DATA_DIR, split='validation', transform=None)\n",
        "test_dataset  = SIMMDataset(NETWORK_OPTIONS_OBJ.DATA_DIR, split='test', transform=None)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, num_workers=NETWORK_OPTIONS_OBJ.DATALOADER_NUM_WORKERS, batch_size=NETWORK_OPTIONS_OBJ.BATCH_SIZE, shuffle=True)\n",
        "valid_loader = DataLoader(dataset=valid_dataset, num_workers=NETWORK_OPTIONS_OBJ.DATALOADER_NUM_WORKERS, batch_size=NETWORK_OPTIONS_OBJ.BATCH_SIZE, shuffle=False)\n",
        "test_loader  = DataLoader(dataset=test_dataset,  num_workers=NETWORK_OPTIONS_OBJ.DATALOADER_NUM_WORKERS, batch_size=NETWORK_OPTIONS_OBJ.BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading masks from: /content/data/masks/train-rle.csv\n",
            "Reading ds from: /content/data/masks/simm_DS_train.csv\n",
            "Reading masks from: /content/data/masks/train-rle.csv\n",
            "Reading ds from: /content/data/masks/simm_DS_validation.csv\n",
            "Reading masks from: /content/data/masks/train-rle.csv\n",
            "Reading ds from: /content/data/masks/simm_DS_test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEsBmffec2SS",
        "colab_type": "code",
        "outputId": "e620df76-bb25-40ab-b05c-2ab14c5c5cf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = FCDenseNet103(in_channels=3,\n",
        "                      out_channels=1,\n",
        "                      dropout=NETWORK_OPTIONS_OBJ.DROPOUT)\n",
        "print(model)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(),\n",
        "                        lr=NETWORK_OPTIONS_OBJ.LR_RATE,\n",
        "                        betas=(0.9, 0.999),\n",
        "                        weight_decay=NETWORK_OPTIONS_OBJ.L2_REG_WEIGHT)\n",
        "\n",
        "# optimizer = optim.SGD(params,\n",
        "#                               lr=option.lr_rate,\n",
        "#                               momentum=0.9,\n",
        "#                               nesterov=True,\n",
        "#                               weight_decay=option.l2_reg_weight)\n",
        "\n",
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FCDenseNet103(\n",
            "  (features): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (down_dense): Module(\n",
            "    (block_0): DenseBlock(48, 4*16+48=112)(\n",
            "      (layer_0): DenseLayer(48, 16)(\n",
            "        (norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(48, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_1): DenseLayer(64, 16)(\n",
            "        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_2): DenseLayer(80, 16)(\n",
            "        (norm): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(80, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_3): DenseLayer(96, 16)(\n",
            "        (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(96, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (block_1): DenseBlock(112, 5*16+112=192)(\n",
            "      (layer_0): DenseLayer(112, 16)(\n",
            "        (norm): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(112, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_1): DenseLayer(128, 16)(\n",
            "        (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_2): DenseLayer(144, 16)(\n",
            "        (norm): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(144, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_3): DenseLayer(160, 16)(\n",
            "        (norm): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(160, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_4): DenseLayer(176, 16)(\n",
            "        (norm): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(176, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (block_2): DenseBlock(192, 7*16+192=304)(\n",
            "      (layer_0): DenseLayer(192, 16)(\n",
            "        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(192, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_1): DenseLayer(208, 16)(\n",
            "        (norm): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(208, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_2): DenseLayer(224, 16)(\n",
            "        (norm): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(224, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_3): DenseLayer(240, 16)(\n",
            "        (norm): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(240, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_4): DenseLayer(256, 16)(\n",
            "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_5): DenseLayer(272, 16)(\n",
            "        (norm): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(272, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_6): DenseLayer(288, 16)(\n",
            "        (norm): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(288, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (block_3): DenseBlock(304, 10*16+304=464)(\n",
            "      (layer_0): DenseLayer(304, 16)(\n",
            "        (norm): BatchNorm2d(304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(304, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_1): DenseLayer(320, 16)(\n",
            "        (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(320, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_2): DenseLayer(336, 16)(\n",
            "        (norm): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(336, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_3): DenseLayer(352, 16)(\n",
            "        (norm): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(352, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_4): DenseLayer(368, 16)(\n",
            "        (norm): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(368, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_5): DenseLayer(384, 16)(\n",
            "        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(384, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_6): DenseLayer(400, 16)(\n",
            "        (norm): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(400, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_7): DenseLayer(416, 16)(\n",
            "        (norm): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(416, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_8): DenseLayer(432, 16)(\n",
            "        (norm): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(432, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_9): DenseLayer(448, 16)(\n",
            "        (norm): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(448, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (block_4): DenseBlock(464, 12*16+464=656)(\n",
            "      (layer_0): DenseLayer(464, 16)(\n",
            "        (norm): BatchNorm2d(464, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(464, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_1): DenseLayer(480, 16)(\n",
            "        (norm): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(480, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_2): DenseLayer(496, 16)(\n",
            "        (norm): BatchNorm2d(496, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(496, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_3): DenseLayer(512, 16)(\n",
            "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_4): DenseLayer(528, 16)(\n",
            "        (norm): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(528, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_5): DenseLayer(544, 16)(\n",
            "        (norm): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(544, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_6): DenseLayer(560, 16)(\n",
            "        (norm): BatchNorm2d(560, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(560, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_7): DenseLayer(576, 16)(\n",
            "        (norm): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(576, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_8): DenseLayer(592, 16)(\n",
            "        (norm): BatchNorm2d(592, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(592, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_9): DenseLayer(608, 16)(\n",
            "        (norm): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(608, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_10): DenseLayer(624, 16)(\n",
            "        (norm): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(624, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_11): DenseLayer(640, 16)(\n",
            "        (norm): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(640, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (down_trans): Module(\n",
            "    (trans_0): TransitionDown(112, 112, dropout=0.2)(\n",
            "      (norm): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(112, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (drop): Dropout2d(p=0.2, inplace=False)\n",
            "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (trans_1): TransitionDown(192, 192, dropout=0.2)(\n",
            "      (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (drop): Dropout2d(p=0.2, inplace=False)\n",
            "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (trans_2): TransitionDown(304, 304, dropout=0.2)(\n",
            "      (norm): BatchNorm2d(304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(304, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (drop): Dropout2d(p=0.2, inplace=False)\n",
            "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (trans_3): TransitionDown(464, 464, dropout=0.2)(\n",
            "      (norm): BatchNorm2d(464, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(464, 464, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (drop): Dropout2d(p=0.2, inplace=False)\n",
            "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (trans_4): TransitionDown(656, 656, dropout=0.2)(\n",
            "      (norm): BatchNorm2d(656, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(656, 656, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (drop): Dropout2d(p=0.2, inplace=False)\n",
            "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "  )\n",
            "  (middle): DenseBlock(656, 15*16+656=896)(\n",
            "    (layer_0): DenseLayer(656, 16)(\n",
            "      (norm): BatchNorm2d(656, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(656, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (drop): Dropout2d(p=0.2, inplace=True)\n",
            "    )\n",
            "    (layer_1): DenseLayer(672, 16)(\n",
            "      (norm): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(672, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (drop): Dropout2d(p=0.2, inplace=True)\n",
            "    )\n",
            "    (layer_2): DenseLayer(688, 16)(\n",
            "      (norm): BatchNorm2d(688, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(688, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (drop): Dropout2d(p=0.2, inplace=True)\n",
            "    )\n",
            "    (layer_3): DenseLayer(704, 16)(\n",
            "      (norm): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(704, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (drop): Dropout2d(p=0.2, inplace=True)\n",
            "    )\n",
            "    (layer_4): DenseLayer(720, 16)(\n",
            "      (norm): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(720, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (drop): Dropout2d(p=0.2, inplace=True)\n",
            "    )\n",
            "    (layer_5): DenseLayer(736, 16)(\n",
            "      (norm): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(736, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (drop): Dropout2d(p=0.2, inplace=True)\n",
            "    )\n",
            "    (layer_6): DenseLayer(752, 16)(\n",
            "      (norm): BatchNorm2d(752, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(752, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (drop): Dropout2d(p=0.2, inplace=True)\n",
            "    )\n",
            "    (layer_7): DenseLayer(768, 16)(\n",
            "      (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(768, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (drop): Dropout2d(p=0.2, inplace=True)\n",
            "    )\n",
            "    (layer_8): DenseLayer(784, 16)(\n",
            "      (norm): BatchNorm2d(784, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(784, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (drop): Dropout2d(p=0.2, inplace=True)\n",
            "    )\n",
            "    (layer_9): DenseLayer(800, 16)(\n",
            "      (norm): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(800, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (drop): Dropout2d(p=0.2, inplace=True)\n",
            "    )\n",
            "    (layer_10): DenseLayer(816, 16)(\n",
            "      (norm): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(816, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (drop): Dropout2d(p=0.2, inplace=True)\n",
            "    )\n",
            "    (layer_11): DenseLayer(832, 16)(\n",
            "      (norm): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(832, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (drop): Dropout2d(p=0.2, inplace=True)\n",
            "    )\n",
            "    (layer_12): DenseLayer(848, 16)(\n",
            "      (norm): BatchNorm2d(848, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(848, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (drop): Dropout2d(p=0.2, inplace=True)\n",
            "    )\n",
            "    (layer_13): DenseLayer(864, 16)(\n",
            "      (norm): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(864, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (drop): Dropout2d(p=0.2, inplace=True)\n",
            "    )\n",
            "    (layer_14): DenseLayer(880, 16)(\n",
            "      (norm): BatchNorm2d(880, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv): Conv2d(880, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (drop): Dropout2d(p=0.2, inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (up_dense): Module(\n",
            "    (block_0): DenseBlock(1552, 12*16=192)(\n",
            "      (layer_0): DenseLayer(1552, 16)(\n",
            "        (norm): BatchNorm2d(1552, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(1552, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_1): DenseLayer(1568, 16)(\n",
            "        (norm): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(1568, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_2): DenseLayer(1584, 16)(\n",
            "        (norm): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(1584, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_3): DenseLayer(1600, 16)(\n",
            "        (norm): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(1600, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_4): DenseLayer(1616, 16)(\n",
            "        (norm): BatchNorm2d(1616, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(1616, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_5): DenseLayer(1632, 16)(\n",
            "        (norm): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(1632, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_6): DenseLayer(1648, 16)(\n",
            "        (norm): BatchNorm2d(1648, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(1648, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_7): DenseLayer(1664, 16)(\n",
            "        (norm): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(1664, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_8): DenseLayer(1680, 16)(\n",
            "        (norm): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(1680, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_9): DenseLayer(1696, 16)(\n",
            "        (norm): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(1696, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_10): DenseLayer(1712, 16)(\n",
            "        (norm): BatchNorm2d(1712, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(1712, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_11): DenseLayer(1728, 16)(\n",
            "        (norm): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(1728, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (block_1): DenseBlock(656, 10*16=160)(\n",
            "      (layer_0): DenseLayer(656, 16)(\n",
            "        (norm): BatchNorm2d(656, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(656, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_1): DenseLayer(672, 16)(\n",
            "        (norm): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(672, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_2): DenseLayer(688, 16)(\n",
            "        (norm): BatchNorm2d(688, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(688, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_3): DenseLayer(704, 16)(\n",
            "        (norm): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(704, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_4): DenseLayer(720, 16)(\n",
            "        (norm): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(720, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_5): DenseLayer(736, 16)(\n",
            "        (norm): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(736, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_6): DenseLayer(752, 16)(\n",
            "        (norm): BatchNorm2d(752, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(752, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_7): DenseLayer(768, 16)(\n",
            "        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(768, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_8): DenseLayer(784, 16)(\n",
            "        (norm): BatchNorm2d(784, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(784, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_9): DenseLayer(800, 16)(\n",
            "        (norm): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(800, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (block_2): DenseBlock(464, 7*16=112)(\n",
            "      (layer_0): DenseLayer(464, 16)(\n",
            "        (norm): BatchNorm2d(464, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(464, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_1): DenseLayer(480, 16)(\n",
            "        (norm): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(480, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_2): DenseLayer(496, 16)(\n",
            "        (norm): BatchNorm2d(496, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(496, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_3): DenseLayer(512, 16)(\n",
            "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_4): DenseLayer(528, 16)(\n",
            "        (norm): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(528, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_5): DenseLayer(544, 16)(\n",
            "        (norm): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(544, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_6): DenseLayer(560, 16)(\n",
            "        (norm): BatchNorm2d(560, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(560, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (block_3): DenseBlock(304, 5*16=80)(\n",
            "      (layer_0): DenseLayer(304, 16)(\n",
            "        (norm): BatchNorm2d(304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(304, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_1): DenseLayer(320, 16)(\n",
            "        (norm): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(320, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_2): DenseLayer(336, 16)(\n",
            "        (norm): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(336, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_3): DenseLayer(352, 16)(\n",
            "        (norm): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(352, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_4): DenseLayer(368, 16)(\n",
            "        (norm): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(368, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (block_4): DenseBlock(192, 4*16=64)(\n",
            "      (layer_0): DenseLayer(192, 16)(\n",
            "        (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(192, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_1): DenseLayer(208, 16)(\n",
            "        (norm): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(208, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_2): DenseLayer(224, 16)(\n",
            "        (norm): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(224, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "      (layer_3): DenseLayer(240, 16)(\n",
            "        (norm): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv): Conv2d(240, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (drop): Dropout2d(p=0.2, inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (up_trans): Module(\n",
            "    (trans_0): TransitionUp([896, 656] -> 1552))(\n",
            "      (upconv): ConvTranspose2d(896, 896, kernel_size=(3, 3), stride=(2, 2))\n",
            "      (concat): CenterCropConcat()\n",
            "    )\n",
            "    (trans_1): TransitionUp([192, 464] -> 656))(\n",
            "      (upconv): ConvTranspose2d(192, 192, kernel_size=(3, 3), stride=(2, 2))\n",
            "      (concat): CenterCropConcat()\n",
            "    )\n",
            "    (trans_2): TransitionUp([160, 304] -> 464))(\n",
            "      (upconv): ConvTranspose2d(160, 160, kernel_size=(3, 3), stride=(2, 2))\n",
            "      (concat): CenterCropConcat()\n",
            "    )\n",
            "    (trans_3): TransitionUp([112, 192] -> 304))(\n",
            "      (upconv): ConvTranspose2d(112, 112, kernel_size=(3, 3), stride=(2, 2))\n",
            "      (concat): CenterCropConcat()\n",
            "    )\n",
            "    (trans_4): TransitionUp([80, 112] -> 192))(\n",
            "      (upconv): ConvTranspose2d(80, 80, kernel_size=(3, 3), stride=(2, 2))\n",
            "      (concat): CenterCropConcat()\n",
            "    )\n",
            "  )\n",
            "  (final): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbF1KlBAAQGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Use this code to load weights from pytorch state file (For transfer learning)\n",
        "# checkpoint_group1 = torch.load('/content/checkpoint-tiramisu-model-state')\n",
        "# other_model_state = checkpoint_group1['model_state']\n",
        "# model.load_state_dict(other_model_state, strict=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lakj338zM-r1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "last_best_valid_loss = 100.0\n",
        "if NETWORK_OPTIONS_OBJ.CONTINUE_TRAIN == True:\n",
        "  run_name = NETWORK_OPTIONS_OBJ.RUN_NAME\n",
        "  model, optimizer, checkpoint = load_checkpoint(run_name, model, optimizer, load_best=NETWORK_OPTIONS_OBJ.LOAD_BEST)\n",
        "  last_best_valid_loss = checkpoint['best_valid_loss']\n",
        "  print_checkpoint(checkpoint)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6B2Wa5hGICt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_images_with_masks_and_prediction(images, labels, predictions):\n",
        "  # create grid of images\n",
        "  img_grid = torchvision.utils.make_grid(images.clone().cpu())\n",
        "  target_grid = torchvision.utils.make_grid(labels.clone().cpu())\n",
        "  prediction_grid = torchvision.utils.make_grid(predictions.clone().cpu())\n",
        "  # print(img_grid.shape)\n",
        "\n",
        "  img_grid = np.transpose(img_grid.numpy(), (1, 2, 0))\n",
        "  target_grid = np.transpose(target_grid.numpy(), (1, 2, 0))\n",
        "  prediction_grid = np.transpose(prediction_grid.numpy(), (1, 2, 0))\n",
        "\n",
        "\n",
        "  mask_target = (target_grid == [1.,1.,1.]).all(axis=2)\n",
        "  target_grid[mask_target] = [1, 0, 0]\n",
        "\n",
        "\n",
        "  mask_pred = (prediction_grid == [1.,1.,1.]).all(axis=2)\n",
        "  prediction_grid[mask_pred] = [0, 0, 1]\n",
        "\n",
        "  plt.figure()\n",
        "  plt.imshow(img_grid, cmap=plt.cm.bone)\n",
        "  plt.imshow(target_grid, alpha=0.3)\n",
        "  plt.imshow(prediction_grid, alpha=0.3)\n",
        "  plt.show()\n",
        "\n",
        "def show_images_with_masks(images, labels):\n",
        "  # create grid of images\n",
        "  img_grid = torchvision.utils.make_grid(images.clone().cpu())\n",
        "  target_grid = torchvision.utils.make_grid(labels.clone().cpu())\n",
        "  # print(img_grid.shape)\n",
        "\n",
        "  img_grid = np.transpose(img_grid.numpy(), (1, 2, 0))\n",
        "  target_grid = np.transpose(target_grid.numpy(), (1, 2, 0))\n",
        "\n",
        "  # print(target_grid.shape)\n",
        "  mask_target = (target_grid == [1.,1.,1.]).all(axis=2)\n",
        "  target_grid[mask_target] = [1, 0, 0]\n",
        "\n",
        "  plt.figure()\n",
        "  plt.imshow(img_grid, cmap=plt.cm.bone)\n",
        "  plt.imshow(target_grid, alpha=0.3)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR3yIAUm5yuE",
        "colab_type": "code",
        "outputId": "72221656-f602-446e-c001-da8ece746b66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "dataiter = iter(train_loader)\n",
        "sample_images, sample_labels = dataiter.next()\n",
        "\n",
        "print(sample_images.shape)\n",
        "print(sample_labels.shape)\n",
        "\n",
        "show_images_with_masks(sample_images, sample_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 3, 224, 224])\n",
            "torch.Size([8, 1, 224, 224])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAABNCAYAAACsXX8MAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxgZ+LGMZy1heo/L/A3pBR8ZLvHmnAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75Q6L1fYmt9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir=\"$NETWORK_OPTIONS_OBJ.TENSORBOARD_LOGS_DIR\"\n",
        "# %reload_ext tensorboard\n",
        "# # import time\n",
        "# # time.sleep(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyl_3nh0au9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcAflpuw--We",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = SIMMSoftDiceLoss()\n",
        "DiceScore = SIMMHardDiceScore()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFqbfplFcymv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "timestr = time.strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
        "\n",
        "run_prefix = 'fcdn103'\n",
        "run_name = timestr\n",
        "if NETWORK_OPTIONS_OBJ.CONTINUE_TRAIN == True:\n",
        "  run_name = NETWORK_OPTIONS_OBJ.RUN_NAME\n",
        "print(run_name)\n",
        "\n",
        "tb_log_dir = NETWORK_OPTIONS_OBJ.TENSORBOARD_LOGS_DIR + run_prefix + '_' + run_name\n",
        "tb = SummaryWriter(flush_secs=10, log_dir=tb_log_dir)\n",
        "\n",
        "# criterion = SIMMSoftDiceLoss()\n",
        "best_train_loss = 100.0\n",
        "best_valid_loss = 100.0\n",
        "\n",
        "if NETWORK_OPTIONS_OBJ.CONTINUE_TRAIN == False:\n",
        "  tb.add_scalar(\"learning_rate\", NETWORK_OPTIONS_OBJ.LR_RATE)\n",
        "  tb.add_scalar(\"batch_size\", NETWORK_OPTIONS_OBJ.BATCH_SIZE)\n",
        "  # tb.add_scalar(\"feature_scale\", NETWORK_OPTIONS_OBJ.FEATURE_SCALE)\n",
        "  # tb.add_image('siim_sample_images', img_grid)\n",
        "  tb.add_text('run_name', run_name)\n",
        "  tb.add_text('run_desc', 'FCDenseNet without AG')\n",
        "  # tb.add_hparams(NETWORK_OPTIONS)\n",
        "else:\n",
        "  best_valid_loss = last_best_valid_loss\n",
        "\n",
        "\n",
        "tb.add_graph(model, sample_images.float().to(device))\n",
        "\n",
        "tb.flush()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(NETWORK_OPTIONS_OBJ.START_EPOCH, NETWORK_OPTIONS_OBJ.START_EPOCH + NETWORK_OPTIONS_OBJ.NUM_EPOCHS):\n",
        "  time.sleep(0.1)\n",
        "  print('############# Running epoch: %d...\\n' % (epoch))\n",
        "\n",
        "  ## Training Iterations\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  running_loss = 0.0\n",
        "  loss_per_epoch = 0.0\n",
        "  dice_score_per_epoch = 0.0\n",
        "  epoch_batch_count = 0\n",
        "\n",
        "  total_iter = total=len(train_loader)\n",
        "  for epoch_iter, (images, labels) in tqdm(enumerate(train_loader, 1), total=total_iter):\n",
        "    # Make a training update\n",
        "    inputs = images.float().to(device)\n",
        "    masks = labels.to(device)\n",
        "    # assert input.size() == target.size()\n",
        "\n",
        "    # forward + backward + optimize\n",
        "    outputs = model(inputs)\n",
        "    # print(outputs.shape)\n",
        "    loss = criterion(outputs, masks)\n",
        "\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # calculate dice score\n",
        "    dScore = DiceScore(outputs, masks)\n",
        "\n",
        "    # update losses for epoch\n",
        "    loss_per_epoch += loss.item()\n",
        "    dice_score_per_epoch += dScore.item()\n",
        "    epoch_batch_count += 1\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    if epoch_iter % 20 == 0:\n",
        "      loss_avg = running_loss / 20\n",
        "      #print('[%d, %5d] Running loss: %.3f' % (epoch + 1, epoch_iter + 1, loss_avg))\n",
        "      # (10 * x + y) / 10\n",
        "      i_num = (epoch + 1) + ((epoch_iter + 1) / total_iter)\n",
        "      tb.add_scalar('RunningLoss', loss_avg, i_num)\n",
        "      running_loss = 0.0\n",
        "\n",
        "  loss = loss_per_epoch / epoch_batch_count\n",
        "  dice_score_per_epoch = dice_score_per_epoch / epoch_batch_count\n",
        "  tb.add_scalar('Loss', loss, epoch + 1)\n",
        "  tb.add_scalar('DiceScore', dice_score_per_epoch, epoch + 1)\n",
        "  print('*********** [%d] Loss per epoch: %.3f' %(epoch + 1, loss))\n",
        "  print('*********** [%d] Dice Score per epoch: %.3f' %(epoch + 1, dice_score_per_epoch))\n",
        "\n",
        "  if loss <= best_train_loss:\n",
        "    best_train_loss = loss\n",
        "\n",
        "  # Validation Iterations\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  running_loss_valid = 0.0\n",
        "  loss_per_epoch_valid = 0.0\n",
        "  dice_score_per_epoch_valid = 0.0\n",
        "  epoch_batch_count_valid = 0\n",
        "  loss_valid = 100\n",
        "  if NETWORK_OPTIONS_OBJ.USE_VAL_SET:\n",
        "    with torch.no_grad():\n",
        "      total_valid_iter = total=len(valid_loader)\n",
        "      for epoch_iter, (images, labels) in tqdm(enumerate(valid_loader, 1), total=total_valid_iter):\n",
        "        # get batch\n",
        "        inputs = images.float().to(device)\n",
        "        masks = labels.to(device)\n",
        "        # assert input.size() == target.size()\n",
        "\n",
        "        # forward\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, masks)\n",
        "\n",
        "        # calculate dice score\n",
        "        dScore = DiceScore(outputs, masks)\n",
        "\n",
        "        # update losses for epoch\n",
        "        loss_per_epoch_valid += loss.item()\n",
        "        dice_score_per_epoch_valid += dScore.item()\n",
        "        epoch_batch_count_valid += 1\n",
        "        running_loss_valid += loss.item()\n",
        "\n",
        "        if epoch_iter % 20 == 0:\n",
        "          loss_avg = running_loss_valid / 20\n",
        "          # print('[%d, %5d] Running loss Validation: %.3f' % (epoch + 1, epoch_iter + 1, loss_avg))\n",
        "          i_num = (epoch + 1) + ((epoch_iter + 1) / total_valid_iter)\n",
        "          tb.add_scalar('RunningLossValidation', loss_avg, i_num)\n",
        "          running_loss_valid = 0.0\n",
        "\n",
        "    loss_valid = loss_per_epoch_valid / epoch_batch_count_valid\n",
        "    dice_score_per_epoch_valid = dice_score_per_epoch_valid / epoch_batch_count_valid\n",
        "    tb.add_scalar('LossValidation', loss_valid, epoch + 1)\n",
        "    tb.add_scalar('DiceScoreValidation', dice_score_per_epoch_valid, epoch + 1)\n",
        "    print('*********** [%d] Validation Loss per epoch: %.3f' %(epoch + 1, loss_valid))\n",
        "    print('*********** [%d] Validation DiceScore per epoch: %.3f' %(epoch + 1, dice_score_per_epoch_valid))\n",
        "\n",
        "\n",
        "  is_best = False\n",
        "  if loss_valid < best_valid_loss:\n",
        "    best_valid_loss = loss_valid\n",
        "    is_best = True\n",
        "\n",
        "  create_checkpoint(run_name, model, optimizer, is_best, epoch, NETWORK_OPTIONS, loss, loss_valid, best_valid_loss)\n",
        "\n",
        "  # reset loss per epoch\n",
        "  loss_per_epoch = 0.0\n",
        "  dice_score_per_epoch = 0.0\n",
        "  epoch_batch_count = 0\n",
        "  # reset validation loss per epoch\n",
        "  loss_per_epoch_valid = 0.0\n",
        "  dice_score_per_epoch_valid = 0.0\n",
        "  epoch_batch_count_valid = 0\n",
        "  \n",
        "  tb.flush()\n",
        "\n",
        "  \n",
        "  # Update the model learning rate\n",
        "  # model.update_learning_rate()\n",
        "tb.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mYq5-Of9mvJ",
        "colab_type": "text"
      },
      "source": [
        "# Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDMAoWUJdChc",
        "colab_type": "code",
        "outputId": "7257e6d7-0fa7-40ae-9faf-8dd5a833ca5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134,
          "referenced_widgets": [
            "59580f0884c14615a1e237646dadf147",
            "929b46f3353d4c31abae1453f3d96cb9",
            "4d2715d8bc1e474e96466a6d46f65ae4",
            "e204d6281eb7481d988a81808c4bcc7f",
            "0d82dba3cee742178b7eca8fc7eaefbe",
            "dbcd730c65d64cffa319c70faee0c10b",
            "a9c22c4e4a234b3582545609ed75b3e7",
            "24af49fe009f4397a59dc115915a7bf4"
          ]
        }
      },
      "source": [
        "# Calculate loss on test set\n",
        "loss_test = 0.0\n",
        "dScore_test = 0.0\n",
        "batch_count_test = 0\n",
        "\n",
        "model.eval()\n",
        "\n",
        "loader = DataLoader(dataset=test_dataset, num_workers=NETWORK_OPTIONS_OBJ.DATALOADER_NUM_WORKERS, batch_size=NETWORK_OPTIONS_OBJ.BATCH_SIZE, shuffle=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "  for epoch_iter, (images, labels) in tqdm(enumerate(loader, 1), total=len(loader)):\n",
        "    # get batch\n",
        "    inputs = images.float().to(device)\n",
        "    masks = labels.to(device)\n",
        "    # assert input.size() == target.size()\n",
        "\n",
        "    # forward\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, masks)\n",
        "    dScore = DiceScore(outputs.clone(), masks.clone())\n",
        "\n",
        "    # # update losses for epoch\n",
        "    loss_test += loss.item()\n",
        "    dScore_test += dScore.item()\n",
        "    batch_count_test += 1\n",
        "\n",
        "    # print('\\n -- Loss on Test Set: %.3f' %(loss.item()))\n",
        "    # print('\\n -- Dice score on Test Set: %.3f' %(dScore.item()))\n",
        "\n",
        "loss_test = loss_test / batch_count_test\n",
        "dScore_test = dScore_test / batch_count_test\n",
        "# tb.add_scalar('LossTest', loss_test, loss_test)\n",
        "print('\\n Loss on Test Set: %.3f' %(loss_test))\n",
        "print('\\n Dice score on Test Set: %.3f' %(dScore_test))\n",
        "# tb.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59580f0884c14615a1e237646dadf147",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " Loss on Test Set: 0.487\n",
            "\n",
            " Dice score on Test Set: 0.513\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiCq1ACI9_E4",
        "colab_type": "text"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMVpaVfTSxzo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_heatmap(images):\n",
        "  # create grid of images\n",
        "  img_grid = torchvision.utils.make_grid(images.clone().cpu())\n",
        "  img_grid = np.transpose(img_grid.numpy(), (1, 2, 0))\n",
        "\n",
        "  plt.figure()\n",
        "  plt.imshow(img_grid)\n",
        "  # plt.colorbar()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmuYNiOHMc6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_images_with_masks_and_prediction(images, labels, predictions, file_name):\n",
        "  # create grid of images\n",
        "  img_grid = torchvision.utils.make_grid(images.clone().cpu())\n",
        "  target_grid = torchvision.utils.make_grid(labels.clone().cpu())\n",
        "  prediction_grid = torchvision.utils.make_grid(predictions.clone().cpu())\n",
        "  # print(img_grid.shape)\n",
        "\n",
        "  img_grid = np.transpose(img_grid.numpy(), (1, 2, 0))\n",
        "  target_grid = np.transpose(target_grid.numpy(), (1, 2, 0))\n",
        "  prediction_grid = np.transpose(prediction_grid.numpy(), (1, 2, 0))\n",
        "\n",
        "  mask_target = (target_grid == [1.,1.,1.]).all(axis=2)\n",
        "  target_grid[mask_target] = [1, 0, 0]\n",
        "\n",
        "  mask_pred = (prediction_grid == [1.,1.,1.]).all(axis=2)\n",
        "  prediction_grid[mask_pred] = [0, 0, 1]\n",
        "\n",
        "  plt.figure()\n",
        "  plt.imshow(img_grid, cmap=plt.cm.bone)\n",
        "  plt.imshow(target_grid, alpha=0.3)\n",
        "  plt.imshow(prediction_grid, alpha=0.3)\n",
        "  plt.savefig(file_name)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lqYDQZdMkW9",
        "colab_type": "code",
        "outputId": "4573509f-564b-44e0-835d-1bbce6e53aaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# m_name = NETWORK_OPTIONS_OBJ.RUN_NAME\n",
        "# RESULT_IMG_DIR = IMG_RESULT_SAVE_DIR + m_name\n",
        "# if os.path.exists(RESULT_IMG_DIR):\n",
        "#   shutil.rmtree(RESULT_IMG_DIR)\n",
        "#   print(\"Deleted RESULT_IMG_DIR directory: \" + RESULT_IMG_DIR)\n",
        "\n",
        "# os.makedirs(RESULT_IMG_DIR)\n",
        "# print(\"Created directory: \" + RESULT_IMG_DIR)\n",
        "# %ls '$RESULT_IMG_DIR'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created directory: /content/gdrive/My Drive/mlmi/results/imgs/2020_01_27-20_30_23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii0hDPzOMpbz",
        "colab_type": "code",
        "outputId": "4ad8b5ea-11c4-4024-d92d-25b9cb73aa54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# from IPython.display import clear_output\n",
        "\n",
        "# model.eval()\n",
        "\n",
        "# loader = DataLoader(dataset=test_dataset, num_workers=NETWORK_OPTIONS_OBJ.DATALOADER_NUM_WORKERS, batch_size=2, shuffle=False)\n",
        "\n",
        "# print(\"Red is Ground Truth.\")\n",
        "# print(\"Blue is prediction.\")\n",
        "\n",
        "# with torch.no_grad():\n",
        "#   for epoch_iter, (images, labels) in tqdm(enumerate(loader, 1), total=len(loader)):\n",
        "#     print(\"Iter: \" + str(epoch_iter))\n",
        "#     inputs = images.float().to(device)\n",
        "#     masks = labels.to(device)\n",
        "#     outputs = model(inputs)\n",
        "\n",
        "#     outputs[outputs > 0.5] = 1\n",
        "#     outputs[outputs <= 0.5] = 0\n",
        "#     fileName = RESULT_IMG_DIR + '/' + str(epoch_iter) + '_test_pred' + '.png'\n",
        "#     save_images_with_masks_and_prediction(images, labels, outputs, fileName)\n",
        "#     clear_output(wait=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwidP8oe-Cu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "\n",
        "# loader = DataLoader(dataset=train_dataset, num_workers=NETWORK_OPTIONS_OBJ.DATALOADER_NUM_WORKERS, batch_size=NETWORK_OPTIONS_OBJ.BATCH_SIZE, shuffle=False)\n",
        "# loader = valid_loader\n",
        "loader = DataLoader(dataset=test_dataset, num_workers=NETWORK_OPTIONS_OBJ.DATALOADER_NUM_WORKERS, batch_size=2, shuffle=False)\n",
        "\n",
        "max_display = 10\n",
        "display_count = 0\n",
        "\n",
        "print(\"Red is Ground Truth.\")\n",
        "print(\"Blue is prediction.\")\n",
        "\n",
        "with torch.no_grad():\n",
        "  for epoch_iter, (images, labels) in tqdm(enumerate(loader, 1), total=len(loader)):\n",
        "    print(\"Iter: \" + str(epoch_iter))\n",
        "    # get batch\n",
        "    inputs = images.float().to(device)\n",
        "    masks = labels.to(device)\n",
        "\n",
        "    # forward\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    outputs[outputs > 0.5] = 1\n",
        "    outputs[outputs <= 0.5] = 0\n",
        "\n",
        "    show_images_with_masks_and_prediction(images, labels, outputs)\n",
        "    # show_heatmap(att_coff)\n",
        "\n",
        "    display_count += 1\n",
        "    if display_count >= max_display:\n",
        "      break"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}