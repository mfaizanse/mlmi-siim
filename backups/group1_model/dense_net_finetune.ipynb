{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qsb4KzZtkrIp"
   },
   "source": [
    "### General Information regarding the use of google colab with project files located inside the google drive.\n",
    "\n",
    "*   Changes to files inside gdrive are usually not recognized -> Restart runtime.\n",
    "*   Stack traces can show a different version of a code snippet than the code that is actually executed -> Restart runtime.\n",
    "*   Change the runtime type to Python3 & GPU to increase storage space to 350gb.\n",
    "*   If custom modules are not found -> Restart runtime.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dpbf7aB9gk3c"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23706,
     "status": "ok",
     "timestamp": 1580033936369,
     "user": {
      "displayName": "Panarit Jahiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyRepiyf8dxiCFWxNWE5mKhhk_KY2eZCRB8To0=s64",
      "userId": "17560933570130372928"
     },
     "user_tz": -60
    },
    "id": "v2yyepmChsJa",
    "outputId": "18e12274-896b-476e-ede0-2c57c573975f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yHKQt7OJgk3l"
   },
   "source": [
    "\n",
    "DENSENET TRAINING\n",
    "=============================\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7289,
     "status": "ok",
     "timestamp": 1579969627170,
     "user": {
      "displayName": "Panarit Jahiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyRepiyf8dxiCFWxNWE5mKhhk_KY2eZCRB8To0=s64",
      "userId": "17560933570130372928"
     },
     "user_tz": -60
    },
    "id": "own_cfL8gk3n",
    "outputId": "daedfe95-75fd-4267-fc41-de5b5d185f6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.3.1\n",
      "Torchvision Version:  0.4.2\n",
      "/Users/faizi/git/mlmi/mlmi-simm/group1_model\r\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function \n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import csv\n",
    "import pandas as pd\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "htwEh5ydZ5F-"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'FCDenseNet103' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-825cf831b4ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheckpoint_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'checkpoint-tiramisu-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mthe_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint_best\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlmi/lib/python3.7/site-packages/torch-1.3.1-py3.7-macosx-10.7-x86_64.egg/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'encoding'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/mlmi/lib/python3.7/site-packages/torch-1.3.1-py3.7-macosx-10.7-x86_64.egg/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'FCDenseNet103' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "checkpoint_best = torch.load('checkpoint-tiramisu-1')\n",
    "the_model = checkpoint_best['model']\n",
    "print(the_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XHHuDiYXZ_U6"
   },
   "outputs": [],
   "source": [
    "true_df = pd.read_csv(\"/content/drive/My Drive/siim-acr-pneumothorax-segmentation-drive/results/true.csv\")\n",
    "pred_df = pd.read_csv(\"/content/drive/My Drive/siim-acr-pneumothorax-segmentation-drive/results/preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BTkXKi-wadGp"
   },
   "outputs": [],
   "source": [
    "def calculate_precision():\n",
    "  for column in true_df:\n",
    "    if column not in [\n",
    "        'Atelectasis',\n",
    "        'Cardiomegaly',\n",
    "        'Effusion',\n",
    "        'Infiltration',\n",
    "        'Mass',\n",
    "        'Nodule',\n",
    "        'Pneumonia',\n",
    "        'Pneumothorax',\n",
    "        'Consolidation',\n",
    "        'Edema',\n",
    "        'Emphysema',\n",
    "        'Fibrosis',\n",
    "        'Pleural_Thickening',\n",
    "            'Hernia']:\n",
    "                continue\n",
    "    actual = true_df[column]\n",
    "    pred = pred_df[\"prob_\" + column]\n",
    "    thisrow = {}\n",
    "    thisrow['label'] = column\n",
    "    thisrow['auc'] = np.nan\n",
    "    thisrow['AP'] = np.nan\n",
    "    try:\n",
    "        thisrow['auc'] = sklm.roc_auc_score(actual.as_matrix().astype(int), pred.as_matrix())\n",
    "        thisrow['AP'] = sklm.average_precision_score(actual.as_matrix().astype(int), pred.as_matrix())\n",
    "    except BaseException:\n",
    "        print(\"can't calculate auc for \" + str(column))\n",
    "    auc_df = auc_df.append(thisrow, ignore_index=True)\n",
    "\n",
    "    # if save_as_csv:\n",
    "    #     pred_df.to_csv(\"/content/drive/My Drive/nih_chestxray_implementation/results/preds.csv\", index=False)\n",
    "    #     auc_df.to_csv(\"/content/drive/My Drive/nih_chestxray_implementation/results/aucs.csv\", index=False)\n",
    "\n",
    "    return pred_df, auc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 494,
     "status": "error",
     "timestamp": 1579548343080,
     "user": {
      "displayName": "Panarit Jahiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyRepiyf8dxiCFWxNWE5mKhhk_KY2eZCRB8To0=s64",
      "userId": "17560933570130372928"
     },
     "user_tz": -60
    },
    "id": "FKojIZ2matA5",
    "outputId": "efc8ef72-e674-414a-c757-790880850380"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-cc1350da2791>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maucc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-ef432dd633bd>\u001b[0m in \u001b[0;36mcalculate_precision\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"can't calculate auc for \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mauc_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthisrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# if save_as_csv:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'auc_df' referenced before assignment"
     ]
    }
   ],
   "source": [
    "pred, aucc = calculate_precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1SRXEGSgFd1I"
   },
   "outputs": [],
   "source": [
    "#this part unzip the dataset in google colab\n",
    "import zipfile\n",
    "nih_data_path = \"drive/My Drive/NIH Dataset Small/\"\n",
    "filename = \"NIH small.zip\"\n",
    "with zipfile.ZipFile(nih_data_path + filename, 'r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8194,
     "status": "ok",
     "timestamp": 1579969937095,
     "user": {
      "displayName": "Panarit Jahiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyRepiyf8dxiCFWxNWE5mKhhk_KY2eZCRB8To0=s64",
      "userId": "17560933570130372928"
     },
     "user_tz": -60
    },
    "id": "t41JNqvkHf1c",
    "outputId": "19e6ec97-cd9f-4994-890e-ee46e751e67a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112121\n"
     ]
    }
   ],
   "source": [
    "#check how many images are after unzipping in google colab\n",
    "files_list = os.listdir('NIH small')\n",
    "print(len(files_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "4lxZVWPBgk3v"
   },
   "source": [
    "feature_extract is a boolean that defines if we are finetuning or feature extracting. If feature_extract = False, the model is finetuned and all model parameters are updated. If feature_extract = True, only the last layer parameters are updated, the others remain fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ClElg66Yj2zC"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "\n",
    "# import io\n",
    "# df2 = pd.read_csv(io.BytesIO(uploaded['nih_labels.csv']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 724,
     "status": "ok",
     "timestamp": 1579969944162,
     "user": {
      "displayName": "Panarit Jahiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyRepiyf8dxiCFWxNWE5mKhhk_KY2eZCRB8To0=s64",
      "userId": "17560933570130372928"
     },
     "user_tz": -60
    },
    "id": "XSvXNFrp2uOr",
    "outputId": "b6ff56e0-9018-4e25-d7fb-9fa707ca8b19"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAADgCAAAAAA/RjU9AABZi0lEQVR4nJ39y5IlSbIkiDGLqJqd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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=224x224 at 0x7F9FF556AFD0>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224)\n"
     ]
    }
   ],
   "source": [
    "#test if loading images works\n",
    "from PIL import Image\n",
    "# data_dir = 'images'\n",
    "# data_dir = '/content/images'\n",
    "data_dir = 'NIH small'\n",
    "# /content/drive/My Drive/siim-acr-pneumothorax-segmentation-drive\n",
    "# 00000001_000.png\n",
    "# os.chdir('/content')\n",
    "image = Image.open(data_dir + '/00000001_000.png')\n",
    "# plt.imshow(np.asarray(image))\n",
    "from IPython.display import display\n",
    "display(image)\n",
    "print(image.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6TaDWdszgk3w"
   },
   "outputs": [],
   "source": [
    "#Data directory\n",
    "# data_dir = \"dataset/images\"\n",
    "# data_dir = 'images'\n",
    "# data_dir = '/content/images'\n",
    "data_dir = 'NIH small'\n",
    "# Number of classes in the dataset\n",
    "num_classes = 14\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "# batch_size = 16\n",
    "batch_size = 32\n",
    "\n",
    "#----------best parameters for wsum\n",
    "# WEIGHT_DECAY = 1e-4\n",
    "\n",
    "# WEIGHT_DECAY = 0\n",
    "\n",
    "# LR = 0.01\n",
    "\n",
    "# LR = 0.0001\n",
    "\n",
    "# LR = 0.001\n",
    "# LR = 1e-6\n",
    "#-------\n",
    "\n",
    "#----------Learning Interpretable Features via Adversarially Robust Optimization\n",
    "# WEIGHT_DECAY = 1e-4\n",
    "WEIGHT_DECAY = 0\n",
    "# LR = 0.01\n",
    "LR = 0.001\n",
    "# LR = 0.001\n",
    "# LR = 1e-6\n",
    "#-------\n",
    "\n",
    "\n",
    "#####adam optimizer with new split and a high learning rate. Result from checkpoint5\n",
    "# LR = 0.01 \n",
    "###\n",
    "\n",
    "\n",
    "# WEIGHT_DECAY = 1e-4\n",
    "# # WEIGHT_DECAY = 0\n",
    "# # LR = 0.01\n",
    "# LR = 0.001\n",
    "# # LR = 1e-6\n",
    "\n",
    "# Number of epochs to train for \n",
    "# num_epochs = 15\n",
    "num_epochs = 100\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model, \n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gykoz5x5gk31"
   },
   "outputs": [],
   "source": [
    "def checkpoint(model, best_loss, epoch, LR):\n",
    "    \"\"\"\n",
    "    Saves checkpoint of torchvision model during training.\n",
    "\n",
    "    Args:\n",
    "        model: torchvision model to be saved\n",
    "        best_loss: best val loss achieved so far in training\n",
    "        epoch: current epoch of training\n",
    "        LR: current learning rate in training\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # os.chdir('/content/drive/My Drive/siim-acr-pneumothorax-segmentation-drive')\n",
    "    print('saving')\n",
    "    state = {\n",
    "        'model': model,\n",
    "        'best_loss': best_loss,\n",
    "        'epoch': epoch,\n",
    "        'rng_state': torch.get_rng_state(),\n",
    "        'LR': LR\n",
    "    }\n",
    "\n",
    "    torch.save(state, '/content/drive/My Drive/siim-acr-pneumothorax-segmentation-drive/results/checkpoint8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cmNxe8tSCk1s"
   },
   "outputs": [],
   "source": [
    "def pos_neg_weights_in_batch(labels_batch):\n",
    "    num_total = labels_batch.shape[0] * labels_batch.shape[1]\n",
    "    num_positives = labels_batch.sum()\n",
    "    num_negatives = num_total - num_positives\n",
    "\n",
    "    if not num_positives == 0:\n",
    "        beta_p = num_negatives / num_positives\n",
    "    else:\n",
    "        beta_p = num_negatives\n",
    "    # beta_p = torch.tensor(beta_p)\n",
    "    beta_p = beta_p.to(device)\n",
    "    beta_p = beta_p.type(torch.cuda.FloatTensor)\n",
    "\n",
    "    return beta_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RtUz-Agegk35"
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "        model,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        LR,\n",
    "        num_epochs,\n",
    "        dataloaders,\n",
    "        dataset_sizes,\n",
    "        weight_decay, stop=True, decay = True, print_time = 1000):\n",
    "    \"\"\"\n",
    "    Fine tunes torchvision model to NIH CXR data.\n",
    "\n",
    "    Args:\n",
    "        model: torchvision model to be finetuned (densenet-121 in this case)\n",
    "        criterion: loss criterion (binary cross entropy loss, BCELoss)\n",
    "        optimizer: optimizer to use in training (SGD)\n",
    "        LR: learning rate\n",
    "        num_epochs: continue training up to this many epochs\n",
    "        dataloaders: pytorch train and val dataloaders\n",
    "        dataset_sizes: length of train and val datasets\n",
    "        weight_decay: weight decay parameter we use in SGD with momentum\n",
    "    Returns:\n",
    "        model: trained torchvision model\n",
    "        best_epoch: epoch on which best model val loss was obtained\n",
    "\n",
    "    \"\"\"\n",
    "    print('Hyperparameters: ')\n",
    "    print('Learning rate:', LR)\n",
    "    print('Weight decay:', weight_decay)\n",
    "    print('Decaying:', decay)\n",
    "    print('Num of epochs:', num_epochs)\n",
    "    print(optimizer)\n",
    "    since = time.time()\n",
    "    stats = {'val_loss_history': [], 'train_loss_history': []}\n",
    "#     val_loss_history = []\n",
    "#     train_loss_history = []\n",
    "    start_epoch = 1\n",
    "    best_loss = 999999\n",
    "    best_epoch = -1\n",
    "    best_loss_train = 999999\n",
    "    best_epoch_training = -1\n",
    "    last_train_loss = -1\n",
    "\n",
    "    # iterate over epochs\n",
    "    for epoch in range(start_epoch, num_epochs + 1):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # set model to train or eval mode based on whether we are in train or\n",
    "        # val; necessary to get correct predictions given batchnorm\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train(True)\n",
    "            else:\n",
    "                model.train(False)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            # running_loss2 = 0.0\n",
    "\n",
    "            i = 0\n",
    "            total_done = 0\n",
    "            # iterate over all data in train/val dataloader:\n",
    "            for idx, data in enumerate(dataloaders[phase]):\n",
    "                i += 1\n",
    "#                 if idx > 2:\n",
    "#                     break\n",
    "                inputs, labels, _ = data\n",
    "                batch_size = inputs.shape[0]\n",
    "                inputs = Variable(inputs.to(device))\n",
    "                labels = Variable(labels.float().to(device))\n",
    "                outputs = model(inputs)\n",
    "#                 print(inputs)\n",
    "#                 print(labels)\n",
    "#                 print(_)\n",
    "#                 print('------------------')\n",
    "#                 print(inputs.size())\n",
    "#                 array = inputs[0,:,:,:]\n",
    "#                 data = np.transpose(array, (1, 2, 0))\n",
    "#                 plt.imshow(data, interpolation='nearest')\n",
    "#                 plt.show()\n",
    "#                 print(outputs)\n",
    "#                 print(outputs.size())\n",
    "\n",
    "                # calculate gradient and update parameters in train phase\n",
    "                optimizer.zero_grad()\n",
    "#                 print('-----------------------')\n",
    "#                 print('A batch')\n",
    "                # P = 0\n",
    "                # N = 0\n",
    "                # print('Outputs: ', outputs)\n",
    "                # print('Labels: ', labels)\n",
    "               \n",
    "               \n",
    "               \n",
    "#                 for idxi, label in enumerate(labels):\n",
    "# #                     print('The output', outputs[idx])\n",
    "# #                     print('The label', labels[idx])\n",
    "#                     for v in label:\n",
    "#                         if int(v) == 1:\n",
    "#                             P = P + 1\n",
    "#                         else:\n",
    "#                             N = N + 1\n",
    "#                 if P!=0 and N!=0:\n",
    "#                     BP = (P + N)/P\n",
    "#                     BN = (P + N)/N\n",
    "#                     weights = torch.tensor([BP, BN], dtype=torch.float).to(device)\n",
    "#                     # print(BP, BN)\n",
    "#                 else: weights = None\n",
    "#                 # print('beta mine', N/P)\n",
    "\n",
    "\n",
    "                beta = pos_neg_weights_in_batch(labels)\n",
    "                # print('beta2', beta)\n",
    "                criterion = nn.BCEWithLogitsLoss(pos_weight=beta)\n",
    "                # criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "#                 loss2 = criterion(outputs, labels)\n",
    "                loss  = criterion(outputs, labels)\n",
    "                # loss = weighted_BCELoss(outputs, labels, weights=weights)\n",
    "#                 print('loss: ', loss)\n",
    "#                 print('loss2: ', loss2)\n",
    "#                 print('-----------------------')\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "#                 running_loss2 += loss2.item()*batch_size\n",
    "                running_loss += loss.item() * batch_size\n",
    "\n",
    "\n",
    "                if((idx+1) % print_time == 0):\n",
    "                    print(\"Loss of iteration {} is: {}\".format(idx + 1, loss.item() * batch_size))\n",
    "\n",
    "#                     print(\"Loss2 of iteration {} is: {}\".format(idx + 1, loss2.item() * batch_size))\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            # epoch_loss2 = running_loss2 / dataset_sizes[phase]\n",
    "            if phase == 'train':\n",
    "                last_train_loss = epoch_loss\n",
    "                stats['train_loss_history'].append(epoch_loss)\n",
    "            if phase == 'val':\n",
    "                stats['val_loss_history'].append(epoch_loss)\n",
    "\n",
    "            print(phase + ' epoch {}:loss {:.4f} with data size {}'.format(\n",
    "                epoch, epoch_loss, dataset_sizes[phase]))\n",
    "            \n",
    "#             print(phase + ' epoch {}:loss {:.4f} with data size {}'.format(\n",
    "#                 epoch, epoch_loss2, dataset_sizes[phase]))\n",
    "            # decay learning rate if no val loss improvement in this epoch\n",
    "\n",
    "            if phase == 'val' and epoch_loss > best_loss and decay:\n",
    "                print(\"decay loss from \" + str(LR) + \" to \" +\n",
    "                      str(LR / 10) + \" as not seeing improvement in val loss\")\n",
    "                LR = LR / 10\n",
    "                print('The new learning rate is: ', LR)\n",
    "                # create new optimizer with lower learning rate\n",
    "                # optimizer = optim.SGD(\n",
    "                #     filter(\n",
    "                #         lambda p: p.requires_grad,\n",
    "                #         model.parameters()),\n",
    "                #     lr=LR,\n",
    "                #     momentum=0.9,\n",
    "                #     weight_decay=weight_decay)\n",
    "                optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model_ft.parameters()), lr = LR, betas = (0.9, 0.999))\n",
    "                print(\"created new optimizer with LR \" + str(LR))\n",
    "\n",
    "            # checkpoint model if has best val loss yet\n",
    "            if phase == 'train' and epoch_loss < best_loss_train:\n",
    "                best_loss_train = epoch_loss\n",
    "                best_epoch_train = epoch\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_epoch = epoch\n",
    "                checkpoint(model, best_loss, epoch, LR)\n",
    "\n",
    "#             log training and validation loss over each epoch\n",
    "            if phase == 'val':\n",
    "                with open(\"/content/drive/My Drive/siim-acr-pneumothorax-segmentation-drive/results/log_train\", 'a') as logfile:\n",
    "                    logwriter = csv.writer(logfile, delimiter=',')\n",
    "                    if(epoch == 1):\n",
    "                        logwriter.writerow([\"epoch\", \"train_loss\", \"val_loss\"])\n",
    "                    logwriter.writerow([epoch, last_train_loss, epoch_loss])\n",
    "\n",
    "        total_done += batch_size\n",
    "        if(total_done % (100 * batch_size) == 0):\n",
    "            print(\"completed \" + str(total_done) + \" so far in epoch\")\n",
    "\n",
    "        # break if no val loss improvement in 3 epochs\n",
    "        if ((epoch - best_epoch) >= 3) and stop:\n",
    "            print(\"no improvement in 3 epochs, break\")\n",
    "            break\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "#     load best model weights to return\n",
    "    checkpoint_best = torch.load('/content/drive/My Drive/siim-acr-pneumothorax-segmentation-drive/results/checkpoint8')\n",
    "    model = checkpoint_best['model']\n",
    "\n",
    "    return model, best_epoch, best_epoch_train, stats, LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uyfnx383JnQI"
   },
   "outputs": [],
   "source": [
    "def train_model2(\n",
    "        model,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        LR,\n",
    "        num_epochs,\n",
    "        dataloaders,\n",
    "        dataset_sizes,\n",
    "        weight_decay,\n",
    "        adversarial_training=None,\n",
    "        weighted_cross_entropy_batchwise=False):\n",
    "    \"\"\"\n",
    "    Fine tunes torchvision model to NIH CXR data.\n",
    "\n",
    "    Args:\n",
    "        model: torchvision model to be finetuned (densenet-121 in this case)\n",
    "        criterion: loss criterion (binary cross entropy loss, BCELoss)\n",
    "        optimizer: optimizer to use in training (SGD)\n",
    "        LR: learning rate\n",
    "        num_epochs: continue training up to this many epochs\n",
    "        dataloaders: pytorch train and val dataloaders\n",
    "        dataset_sizes: length of train and val datasets\n",
    "        weight_decay: weight decay parameter we use in SGD with momentum\n",
    "    Returns:\n",
    "        model: trained torchvision model\n",
    "        best_epoch: epoch on which best model val loss was obtained\n",
    "    \"\"\"\n",
    "    since = time.time()\n",
    "\n",
    "    start_epoch = 1\n",
    "    best_loss = 999999\n",
    "    best_epoch = -1\n",
    "    last_train_loss = -1\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # tensorboard_writer_train = SummaryWriter('runs/loss/train_loss')\n",
    "    # tensorboard_writer_val = SummaryWriter('runs/loss/val_loss')\n",
    "\n",
    "    PRED_LABEL = [\n",
    "        'Atelectasis',\n",
    "        'Cardiomegaly',\n",
    "        'Effusion',\n",
    "        'Infiltration',\n",
    "        'Mass',\n",
    "        'Nodule',\n",
    "        'Pneumonia',\n",
    "        'Pneumothorax',\n",
    "        'Consolidation',\n",
    "        'Edema',\n",
    "        'Emphysema',\n",
    "        'Fibrosis',\n",
    "        'Pleural_Thickening',\n",
    "        'Hernia']\n",
    "    # tensorboard_writer_auc = {}\n",
    "    # tensorboard_writer_AP = {}\n",
    "    # for label in PRED_LABEL:\n",
    "    #     tensorboard_writer_auc[label] = SummaryWriter('runs/auc/'+label)\n",
    "    #     tensorboard_writer_AP[label] = SummaryWriter('runs/ap/' + label)\n",
    "    # iterate over epochs\n",
    "    for epoch in range(start_epoch, num_epochs + 1):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # set model to train or eval mode based on whether we are in train or\n",
    "        # val; necessary to get correct predictions given batchnorm\n",
    "        for phase in ['train', 'val']:\n",
    "            print('We are at phase: ' + phase)\n",
    "            if phase == 'train':\n",
    "                model.train(True)\n",
    "            else:\n",
    "                model.train(False)\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            total_done = 0\n",
    "            counting_iterations = 0\n",
    "            for data in dataloaders[phase]:\n",
    "                inputs, labels, the_names = data\n",
    "                batch_size = inputs.shape[0]\n",
    "                inputs = inputs.to(device)\n",
    "                labels = (labels.to(device)).float()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "\n",
    "                    if adversarial_training:\n",
    "                        if phase == 'train':\n",
    "                            delta = fgsm(model, inputs, labels, epsilon=adversarial_training)\n",
    "                            outputs = model(inputs + delta)\n",
    "\n",
    "                        if phase == 'val':\n",
    "                            outputs = model(inputs)\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        # if phase == 'val':\n",
    "                        #   if counting_iterations == len(dataloaders['val']) - 1:\n",
    "                        #     very_important_tensor.append(outputs)\n",
    "                        #     very_important_tensor.append(labels)\n",
    "                        #     very_important_tensor.append(the_names)\n",
    "\n",
    "                        # print(\"Outside: input size\", inputs.size(), \"output_size\", outputs.size())\n",
    "\n",
    "                    # calculate gradient and update parameters in train phase\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    if weighted_cross_entropy_batchwise:\n",
    "                        beta = pos_neg_weights_in_batch(labels)\n",
    "                        criterion = nn.BCEWithLogitsLoss(pos_weight=beta)\n",
    "\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    running_loss += loss.item() * batch_size\n",
    "\n",
    "                    if((counting_iterations+1) % 100 == 0):\n",
    "                      print(\"Loss of iteration {} is: {}\".format(counting_iterations  + 1, loss.item() * batch_size))\n",
    "                      # print(inputs.size())\n",
    "                      # print(outputs.size())\n",
    "                      # print(labels.size())\n",
    "                      # print('beta', beta)\n",
    "                    counting_iterations = counting_iterations + 1\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "\n",
    "            if phase == 'train':\n",
    "                # tensorboard_writer_train.add_scalar('Loss', epoch_loss, epoch)\n",
    "                last_train_loss = epoch_loss\n",
    "            \n",
    "            \n",
    "            # elif phase == 'val':\n",
    "                # tensorboard_writer_val.add_scalar('Loss', epoch_loss, epoch)\n",
    "\n",
    "                # preds, aucs = E.make_pred_multilabel(dataloaders['val'], model, save_as_csv=False)\n",
    "                # aucs.set_index('label', inplace=True)\n",
    "                # print(aucs)\n",
    "                # for label in PRED_LABEL:\n",
    "                #     tensorboard_writer_auc[label].add_scalar('AUC', aucs.loc[label, 'auc'], epoch)\n",
    "                #     tensorboard_writer_AP[label].add_scalar('AP', aucs.loc[label, 'AP'], epoch)\n",
    "\n",
    "            print(phase + ' epoch {}:loss {:.4f} with data size {}'.format(\n",
    "                epoch, epoch_loss, dataset_sizes[phase]))\n",
    "\n",
    "            # decay learning rate if no val loss improvement in this epoch\n",
    "            if phase == 'val' and epoch_loss > best_loss:\n",
    "                print(\"decay loss from \" + str(LR) + \" to \" +\n",
    "                      str(LR / 10) + \" as not seeing improvement in val loss\")\n",
    "                LR = LR / 10\n",
    "                print('The new learning rate is: ', LR)\n",
    "\n",
    "                # create new optimizer with lower learning rate\n",
    "                optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr = LR, betas = (0.9, 0.999))\n",
    "\n",
    "                print(\"created new optimizer with LR \" + str(LR))\n",
    "            #\n",
    "            #     checkpoint_best = torch.load('results/checkpoint_best')\n",
    "            #     model = checkpoint_best['model']\n",
    "\n",
    "            # checkpoint model if has best val loss yet\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_epoch = epoch\n",
    "                checkpoint(model, best_loss, epoch, LR, filename='checkpoint_best3')\n",
    "\n",
    "        # log training and validation loss over each epoch\n",
    "        with open(\"/content/drive/My Drive/siim-acr-pneumothorax-segmentation-drive/results/log_train\", 'a') as logfile:\n",
    "            logwriter = csv.writer(logfile, delimiter=',')\n",
    "            if epoch == 1:\n",
    "                logwriter.writerow([\"epoch\", \"train_loss\", \"val_loss\"])\n",
    "            logwriter.writerow([epoch, last_train_loss, epoch_loss])\n",
    "\n",
    "        # Save model after each epoch\n",
    "        checkpoint(model, best_loss, epoch, LR, filename='checkpoint3')\n",
    "\n",
    "        total_done += batch_size\n",
    "        if total_done % (100 * batch_size) == 0:\n",
    "            print(\"completed \" + str(total_done) + \" so far in epoch\")\n",
    "\n",
    "        # print elapsed time from the beginning after each epoch\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "            (time.time() - since) // 60, (time.time() - since) % 60))\n",
    "\n",
    "    # total time\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    # load best model weights to return\n",
    "    checkpoint_best = torch.load('/content/drive/My Drive/siim-acr-pneumothorax-segmentation-drive/results/checkpoint_best3')\n",
    "    model = checkpoint_best['model']\n",
    "\n",
    "    return model, best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nd_9jtTEgk3-"
   },
   "outputs": [],
   "source": [
    "def visualize_loss(stats):\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(stats['train_loss_history'], label='train')\n",
    "    plt.plot(stats['val_loss_history'], label='val')\n",
    "    plt.title('Train and validation loss history')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3u1m4e2Rgk4C"
   },
   "source": [
    "Set Model Parameters’ .requires_grad attribute\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "This helper function sets the ``.requires_grad`` attribute of the\n",
    "parameters in the model to False when we are feature extracting. By\n",
    "default, when we load a pretrained model all of the parameters have\n",
    "``.requires_grad=True``, which is fine if we are training from scratch\n",
    "or finetuning. However, if we are feature extracting and only want to\n",
    "compute gradients for the newly initialized layer then we want all of\n",
    "the other parameters to not require gradients. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MGBbbkoDgk4F"
   },
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 720,
     "status": "ok",
     "timestamp": 1579899267587,
     "user": {
      "displayName": "Panarit Jahiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyRepiyf8dxiCFWxNWE5mKhhk_KY2eZCRB8To0=s64",
      "userId": "17560933570130372928"
     },
     "user_tz": -60
    },
    "id": "8QZLzJvVgk4J",
    "outputId": "4ddc7b63-d861-4d11-c30a-deb52795cecb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_ftrs 1024\n",
      "DenseNet(\n",
      "  (features): Sequential(\n",
      "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu0): ReLU(inplace=True)\n",
      "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (denseblock1): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition1): _Transition(\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock2): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition2): _Transition(\n",
      "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock3): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition3): _Transition(\n",
      "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock4): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace=True)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=1024, out_features=14, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def initialize_model(num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    \"\"\" Densenet\n",
    "        \"\"\"\n",
    "    model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "    set_parameter_requires_grad(model_ft, feature_extract)\n",
    "    num_ftrs = model_ft.classifier.in_features\n",
    "    print('num_ftrs', num_ftrs)\n",
    "    model_ft.classifier = nn.Linear(num_ftrs, num_classes) \n",
    "    # model_ft.classifier = nn.Sequential(nn.Linear(num_ftrs, num_classes), nn.Sigmoid())\n",
    "    # model_ft.classifier = nn.Sequential(nn.Linear(num_ftrs, num_classes))\n",
    "    input_size = 224\n",
    "\n",
    "    # model_ft.features.denseblock4 = nn.Sequential()\n",
    "    # model_ft.features.transition3 = nn.Sequential()\n",
    "\n",
    "    # model_ft.features.transition2 = nn.Sequential()\n",
    "    # model_ft.features.denseblock3 = nn.Sequential()\n",
    "\n",
    "    # model_ft.features.norm5 = nn.BatchNorm2d(512)\n",
    "    # model_ft.classifier = nn.Linear(512, num_classes)\n",
    "\n",
    "\n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DSga8d8agk4U"
   },
   "source": [
    "Load Data\n",
    "---------\n",
    "\n",
    "Now that we know what the input size must be, we can initialize the data\n",
    "transforms, image datasets, and the dataloaders. Notice, the models were\n",
    "pretrained with the hard-coded normalization values, as described\n",
    "`here <https://pytorch.org/docs/master/torchvision/models.html>`__.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1648,
     "status": "ok",
     "timestamp": 1579529591977,
     "user": {
      "displayName": "Panarit Jahiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyRepiyf8dxiCFWxNWE5mKhhk_KY2eZCRB8To0=s64",
      "userId": "17560933570130372928"
     },
     "user_tz": -60
    },
    "id": "8oeTXZea5m-z",
    "outputId": "47bf0c54-fb26-41d2-9d9f-c79565e749d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/siim-acr-pneumothorax-segmentation-drive\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/content/drive/My Drive/siim-acr-pneumothorax-segmentation-drive')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "joAneb5iLNGr"
   },
   "source": [
    "**Load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 759,
     "status": "ok",
     "timestamp": 1579899272306,
     "user": {
      "displayName": "Panarit Jahiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyRepiyf8dxiCFWxNWE5mKhhk_KY2eZCRB8To0=s64",
      "userId": "17560933570130372928"
     },
     "user_tz": -60
    },
    "id": "FlGIiBNlgk4V",
    "outputId": "03703eda-cc9d-4bdb-f930-b7216e4a0414"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/content/drive/My Drive/siim-acr-pneumothorax-segmentation-drive')\n",
    "import cxr_dataset as CXR\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "    \n",
    "data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            # transforms.RandomHorizontalFlip(),\n",
    "            # transforms.Resize(224),\n",
    "            # because scale doesn't always give 224 x 224, this ensures 224 x\n",
    "            # 224\n",
    "            # transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            # transforms.Resize(224),\n",
    "            # transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {}\n",
    "image_datasets['train'] = CXR.CXRDataset(\n",
    "    path_to_images=data_dir,\n",
    "    fold='train',\n",
    "    # sample = 32,\n",
    "    transform=data_transforms['train'])\n",
    "image_datasets['val'] = CXR.CXRDataset(\n",
    "    path_to_images=data_dir,\n",
    "    fold='val',\n",
    "    # sample = 32,\n",
    "    transform=data_transforms['val'])\n",
    "# image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {}\n",
    "dataloaders_dict['train'] = torch.utils.data.DataLoader(\n",
    "    image_datasets['train'],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8)\n",
    "dataloaders_dict['val'] = torch.utils.data.DataLoader(\n",
    "    image_datasets['val'],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8)\n",
    "# dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "os.chdir('/content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1455,
     "status": "ok",
     "timestamp": 1579204003968,
     "user": {
      "displayName": "Panarit Jahiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyRepiyf8dxiCFWxNWE5mKhhk_KY2eZCRB8To0=s64",
      "userId": "17560933570130372928"
     },
     "user_tz": -60
    },
    "id": "snKY633nS5ny",
    "outputId": "306aecb2-f6a6-48c9-e904-8a28758d51b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/content')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9pYeCrHrLcAr"
   },
   "source": [
    "**Check if the dataset is loading correctly**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 666,
     "status": "ok",
     "timestamp": 1579888541532,
     "user": {
      "displayName": "Panarit Jahiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyRepiyf8dxiCFWxNWE5mKhhk_KY2eZCRB8To0=s64",
      "userId": "17560933570130372928"
     },
     "user_tz": -60
    },
    "id": "3f6qfoZPLT_2",
    "outputId": "8c1378a3-7777-45db-b71e-aca9d01b3113"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 76195, 'val': 10329}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Effusion</th>\n",
       "      <th>Infiltration</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Nodule</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Emphysema</th>\n",
       "      <th>Fibrosis</th>\n",
       "      <th>Pleural_Thickening</th>\n",
       "      <th>Hernia</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00000004_000.png</th>\n",
       "      <td>Mass|Nodule</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000010_000.png</th>\n",
       "      <td>Infiltration</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000011_002.png</th>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000014_000.png</th>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00000028_000.png</th>\n",
       "      <td>Pleural_Thickening</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00030720_003.png</th>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00030726_000.png</th>\n",
       "      <td>Nodule</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00030754_000.png</th>\n",
       "      <td>Infiltration</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00030786_001.png</th>\n",
       "      <td>Effusion|Emphysema|Pneumothorax</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00030795_000.png</th>\n",
       "      <td>Pleural_Thickening</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10329 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Finding Labels  Atelectasis  ...  Hernia  fold\n",
       "Image Index                                                     ...              \n",
       "00000004_000.png                      Mass|Nodule            0  ...       0   val\n",
       "00000010_000.png                     Infiltration            0  ...       0   val\n",
       "00000011_002.png                       No Finding            0  ...       0   val\n",
       "00000014_000.png                       No Finding            0  ...       0   val\n",
       "00000028_000.png               Pleural_Thickening            0  ...       0   val\n",
       "...                                           ...          ...  ...     ...   ...\n",
       "00030720_003.png                       No Finding            0  ...       0   val\n",
       "00030726_000.png                           Nodule            0  ...       0   val\n",
       "00030754_000.png                     Infiltration            0  ...       0   val\n",
       "00030786_001.png  Effusion|Emphysema|Pneumothorax            0  ...       0   val\n",
       "00030795_000.png               Pleural_Thickening            0  ...       0   val\n",
       "\n",
       "[10329 rows x 16 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for idx, data in enumerate(dataloaders_dict['train']):\n",
    "#   print(data[0].size())\n",
    "#   print(idx)\n",
    "#   break\n",
    "print(dataset_sizes)\n",
    "image_datasets['val'].df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 620,
     "status": "ok",
     "timestamp": 1579899276289,
     "user": {
      "displayName": "Panarit Jahiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyRepiyf8dxiCFWxNWE5mKhhk_KY2eZCRB8To0=s64",
      "userId": "17560933570130372928"
     },
     "user_tz": -60
    },
    "id": "GkBx1_0dgk4n",
    "outputId": "7beb902c-1abb-4291-d3ee-44972c130b2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t features.conv0.weight\n",
      "\t features.norm0.weight\n",
      "\t features.norm0.bias\n",
      "\t features.denseblock1.denselayer1.norm1.weight\n",
      "\t features.denseblock1.denselayer1.norm1.bias\n",
      "\t features.denseblock1.denselayer1.conv1.weight\n",
      "\t features.denseblock1.denselayer1.norm2.weight\n",
      "\t features.denseblock1.denselayer1.norm2.bias\n",
      "\t features.denseblock1.denselayer1.conv2.weight\n",
      "\t features.denseblock1.denselayer2.norm1.weight\n",
      "\t features.denseblock1.denselayer2.norm1.bias\n",
      "\t features.denseblock1.denselayer2.conv1.weight\n",
      "\t features.denseblock1.denselayer2.norm2.weight\n",
      "\t features.denseblock1.denselayer2.norm2.bias\n",
      "\t features.denseblock1.denselayer2.conv2.weight\n",
      "\t features.denseblock1.denselayer3.norm1.weight\n",
      "\t features.denseblock1.denselayer3.norm1.bias\n",
      "\t features.denseblock1.denselayer3.conv1.weight\n",
      "\t features.denseblock1.denselayer3.norm2.weight\n",
      "\t features.denseblock1.denselayer3.norm2.bias\n",
      "\t features.denseblock1.denselayer3.conv2.weight\n",
      "\t features.denseblock1.denselayer4.norm1.weight\n",
      "\t features.denseblock1.denselayer4.norm1.bias\n",
      "\t features.denseblock1.denselayer4.conv1.weight\n",
      "\t features.denseblock1.denselayer4.norm2.weight\n",
      "\t features.denseblock1.denselayer4.norm2.bias\n",
      "\t features.denseblock1.denselayer4.conv2.weight\n",
      "\t features.denseblock1.denselayer5.norm1.weight\n",
      "\t features.denseblock1.denselayer5.norm1.bias\n",
      "\t features.denseblock1.denselayer5.conv1.weight\n",
      "\t features.denseblock1.denselayer5.norm2.weight\n",
      "\t features.denseblock1.denselayer5.norm2.bias\n",
      "\t features.denseblock1.denselayer5.conv2.weight\n",
      "\t features.denseblock1.denselayer6.norm1.weight\n",
      "\t features.denseblock1.denselayer6.norm1.bias\n",
      "\t features.denseblock1.denselayer6.conv1.weight\n",
      "\t features.denseblock1.denselayer6.norm2.weight\n",
      "\t features.denseblock1.denselayer6.norm2.bias\n",
      "\t features.denseblock1.denselayer6.conv2.weight\n",
      "\t features.transition1.norm.weight\n",
      "\t features.transition1.norm.bias\n",
      "\t features.transition1.conv.weight\n",
      "\t features.denseblock2.denselayer1.norm1.weight\n",
      "\t features.denseblock2.denselayer1.norm1.bias\n",
      "\t features.denseblock2.denselayer1.conv1.weight\n",
      "\t features.denseblock2.denselayer1.norm2.weight\n",
      "\t features.denseblock2.denselayer1.norm2.bias\n",
      "\t features.denseblock2.denselayer1.conv2.weight\n",
      "\t features.denseblock2.denselayer2.norm1.weight\n",
      "\t features.denseblock2.denselayer2.norm1.bias\n",
      "\t features.denseblock2.denselayer2.conv1.weight\n",
      "\t features.denseblock2.denselayer2.norm2.weight\n",
      "\t features.denseblock2.denselayer2.norm2.bias\n",
      "\t features.denseblock2.denselayer2.conv2.weight\n",
      "\t features.denseblock2.denselayer3.norm1.weight\n",
      "\t features.denseblock2.denselayer3.norm1.bias\n",
      "\t features.denseblock2.denselayer3.conv1.weight\n",
      "\t features.denseblock2.denselayer3.norm2.weight\n",
      "\t features.denseblock2.denselayer3.norm2.bias\n",
      "\t features.denseblock2.denselayer3.conv2.weight\n",
      "\t features.denseblock2.denselayer4.norm1.weight\n",
      "\t features.denseblock2.denselayer4.norm1.bias\n",
      "\t features.denseblock2.denselayer4.conv1.weight\n",
      "\t features.denseblock2.denselayer4.norm2.weight\n",
      "\t features.denseblock2.denselayer4.norm2.bias\n",
      "\t features.denseblock2.denselayer4.conv2.weight\n",
      "\t features.denseblock2.denselayer5.norm1.weight\n",
      "\t features.denseblock2.denselayer5.norm1.bias\n",
      "\t features.denseblock2.denselayer5.conv1.weight\n",
      "\t features.denseblock2.denselayer5.norm2.weight\n",
      "\t features.denseblock2.denselayer5.norm2.bias\n",
      "\t features.denseblock2.denselayer5.conv2.weight\n",
      "\t features.denseblock2.denselayer6.norm1.weight\n",
      "\t features.denseblock2.denselayer6.norm1.bias\n",
      "\t features.denseblock2.denselayer6.conv1.weight\n",
      "\t features.denseblock2.denselayer6.norm2.weight\n",
      "\t features.denseblock2.denselayer6.norm2.bias\n",
      "\t features.denseblock2.denselayer6.conv2.weight\n",
      "\t features.denseblock2.denselayer7.norm1.weight\n",
      "\t features.denseblock2.denselayer7.norm1.bias\n",
      "\t features.denseblock2.denselayer7.conv1.weight\n",
      "\t features.denseblock2.denselayer7.norm2.weight\n",
      "\t features.denseblock2.denselayer7.norm2.bias\n",
      "\t features.denseblock2.denselayer7.conv2.weight\n",
      "\t features.denseblock2.denselayer8.norm1.weight\n",
      "\t features.denseblock2.denselayer8.norm1.bias\n",
      "\t features.denseblock2.denselayer8.conv1.weight\n",
      "\t features.denseblock2.denselayer8.norm2.weight\n",
      "\t features.denseblock2.denselayer8.norm2.bias\n",
      "\t features.denseblock2.denselayer8.conv2.weight\n",
      "\t features.denseblock2.denselayer9.norm1.weight\n",
      "\t features.denseblock2.denselayer9.norm1.bias\n",
      "\t features.denseblock2.denselayer9.conv1.weight\n",
      "\t features.denseblock2.denselayer9.norm2.weight\n",
      "\t features.denseblock2.denselayer9.norm2.bias\n",
      "\t features.denseblock2.denselayer9.conv2.weight\n",
      "\t features.denseblock2.denselayer10.norm1.weight\n",
      "\t features.denseblock2.denselayer10.norm1.bias\n",
      "\t features.denseblock2.denselayer10.conv1.weight\n",
      "\t features.denseblock2.denselayer10.norm2.weight\n",
      "\t features.denseblock2.denselayer10.norm2.bias\n",
      "\t features.denseblock2.denselayer10.conv2.weight\n",
      "\t features.denseblock2.denselayer11.norm1.weight\n",
      "\t features.denseblock2.denselayer11.norm1.bias\n",
      "\t features.denseblock2.denselayer11.conv1.weight\n",
      "\t features.denseblock2.denselayer11.norm2.weight\n",
      "\t features.denseblock2.denselayer11.norm2.bias\n",
      "\t features.denseblock2.denselayer11.conv2.weight\n",
      "\t features.denseblock2.denselayer12.norm1.weight\n",
      "\t features.denseblock2.denselayer12.norm1.bias\n",
      "\t features.denseblock2.denselayer12.conv1.weight\n",
      "\t features.denseblock2.denselayer12.norm2.weight\n",
      "\t features.denseblock2.denselayer12.norm2.bias\n",
      "\t features.denseblock2.denselayer12.conv2.weight\n",
      "\t features.transition2.norm.weight\n",
      "\t features.transition2.norm.bias\n",
      "\t features.transition2.conv.weight\n",
      "\t features.denseblock3.denselayer1.norm1.weight\n",
      "\t features.denseblock3.denselayer1.norm1.bias\n",
      "\t features.denseblock3.denselayer1.conv1.weight\n",
      "\t features.denseblock3.denselayer1.norm2.weight\n",
      "\t features.denseblock3.denselayer1.norm2.bias\n",
      "\t features.denseblock3.denselayer1.conv2.weight\n",
      "\t features.denseblock3.denselayer2.norm1.weight\n",
      "\t features.denseblock3.denselayer2.norm1.bias\n",
      "\t features.denseblock3.denselayer2.conv1.weight\n",
      "\t features.denseblock3.denselayer2.norm2.weight\n",
      "\t features.denseblock3.denselayer2.norm2.bias\n",
      "\t features.denseblock3.denselayer2.conv2.weight\n",
      "\t features.denseblock3.denselayer3.norm1.weight\n",
      "\t features.denseblock3.denselayer3.norm1.bias\n",
      "\t features.denseblock3.denselayer3.conv1.weight\n",
      "\t features.denseblock3.denselayer3.norm2.weight\n",
      "\t features.denseblock3.denselayer3.norm2.bias\n",
      "\t features.denseblock3.denselayer3.conv2.weight\n",
      "\t features.denseblock3.denselayer4.norm1.weight\n",
      "\t features.denseblock3.denselayer4.norm1.bias\n",
      "\t features.denseblock3.denselayer4.conv1.weight\n",
      "\t features.denseblock3.denselayer4.norm2.weight\n",
      "\t features.denseblock3.denselayer4.norm2.bias\n",
      "\t features.denseblock3.denselayer4.conv2.weight\n",
      "\t features.denseblock3.denselayer5.norm1.weight\n",
      "\t features.denseblock3.denselayer5.norm1.bias\n",
      "\t features.denseblock3.denselayer5.conv1.weight\n",
      "\t features.denseblock3.denselayer5.norm2.weight\n",
      "\t features.denseblock3.denselayer5.norm2.bias\n",
      "\t features.denseblock3.denselayer5.conv2.weight\n",
      "\t features.denseblock3.denselayer6.norm1.weight\n",
      "\t features.denseblock3.denselayer6.norm1.bias\n",
      "\t features.denseblock3.denselayer6.conv1.weight\n",
      "\t features.denseblock3.denselayer6.norm2.weight\n",
      "\t features.denseblock3.denselayer6.norm2.bias\n",
      "\t features.denseblock3.denselayer6.conv2.weight\n",
      "\t features.denseblock3.denselayer7.norm1.weight\n",
      "\t features.denseblock3.denselayer7.norm1.bias\n",
      "\t features.denseblock3.denselayer7.conv1.weight\n",
      "\t features.denseblock3.denselayer7.norm2.weight\n",
      "\t features.denseblock3.denselayer7.norm2.bias\n",
      "\t features.denseblock3.denselayer7.conv2.weight\n",
      "\t features.denseblock3.denselayer8.norm1.weight\n",
      "\t features.denseblock3.denselayer8.norm1.bias\n",
      "\t features.denseblock3.denselayer8.conv1.weight\n",
      "\t features.denseblock3.denselayer8.norm2.weight\n",
      "\t features.denseblock3.denselayer8.norm2.bias\n",
      "\t features.denseblock3.denselayer8.conv2.weight\n",
      "\t features.denseblock3.denselayer9.norm1.weight\n",
      "\t features.denseblock3.denselayer9.norm1.bias\n",
      "\t features.denseblock3.denselayer9.conv1.weight\n",
      "\t features.denseblock3.denselayer9.norm2.weight\n",
      "\t features.denseblock3.denselayer9.norm2.bias\n",
      "\t features.denseblock3.denselayer9.conv2.weight\n",
      "\t features.denseblock3.denselayer10.norm1.weight\n",
      "\t features.denseblock3.denselayer10.norm1.bias\n",
      "\t features.denseblock3.denselayer10.conv1.weight\n",
      "\t features.denseblock3.denselayer10.norm2.weight\n",
      "\t features.denseblock3.denselayer10.norm2.bias\n",
      "\t features.denseblock3.denselayer10.conv2.weight\n",
      "\t features.denseblock3.denselayer11.norm1.weight\n",
      "\t features.denseblock3.denselayer11.norm1.bias\n",
      "\t features.denseblock3.denselayer11.conv1.weight\n",
      "\t features.denseblock3.denselayer11.norm2.weight\n",
      "\t features.denseblock3.denselayer11.norm2.bias\n",
      "\t features.denseblock3.denselayer11.conv2.weight\n",
      "\t features.denseblock3.denselayer12.norm1.weight\n",
      "\t features.denseblock3.denselayer12.norm1.bias\n",
      "\t features.denseblock3.denselayer12.conv1.weight\n",
      "\t features.denseblock3.denselayer12.norm2.weight\n",
      "\t features.denseblock3.denselayer12.norm2.bias\n",
      "\t features.denseblock3.denselayer12.conv2.weight\n",
      "\t features.denseblock3.denselayer13.norm1.weight\n",
      "\t features.denseblock3.denselayer13.norm1.bias\n",
      "\t features.denseblock3.denselayer13.conv1.weight\n",
      "\t features.denseblock3.denselayer13.norm2.weight\n",
      "\t features.denseblock3.denselayer13.norm2.bias\n",
      "\t features.denseblock3.denselayer13.conv2.weight\n",
      "\t features.denseblock3.denselayer14.norm1.weight\n",
      "\t features.denseblock3.denselayer14.norm1.bias\n",
      "\t features.denseblock3.denselayer14.conv1.weight\n",
      "\t features.denseblock3.denselayer14.norm2.weight\n",
      "\t features.denseblock3.denselayer14.norm2.bias\n",
      "\t features.denseblock3.denselayer14.conv2.weight\n",
      "\t features.denseblock3.denselayer15.norm1.weight\n",
      "\t features.denseblock3.denselayer15.norm1.bias\n",
      "\t features.denseblock3.denselayer15.conv1.weight\n",
      "\t features.denseblock3.denselayer15.norm2.weight\n",
      "\t features.denseblock3.denselayer15.norm2.bias\n",
      "\t features.denseblock3.denselayer15.conv2.weight\n",
      "\t features.denseblock3.denselayer16.norm1.weight\n",
      "\t features.denseblock3.denselayer16.norm1.bias\n",
      "\t features.denseblock3.denselayer16.conv1.weight\n",
      "\t features.denseblock3.denselayer16.norm2.weight\n",
      "\t features.denseblock3.denselayer16.norm2.bias\n",
      "\t features.denseblock3.denselayer16.conv2.weight\n",
      "\t features.denseblock3.denselayer17.norm1.weight\n",
      "\t features.denseblock3.denselayer17.norm1.bias\n",
      "\t features.denseblock3.denselayer17.conv1.weight\n",
      "\t features.denseblock3.denselayer17.norm2.weight\n",
      "\t features.denseblock3.denselayer17.norm2.bias\n",
      "\t features.denseblock3.denselayer17.conv2.weight\n",
      "\t features.denseblock3.denselayer18.norm1.weight\n",
      "\t features.denseblock3.denselayer18.norm1.bias\n",
      "\t features.denseblock3.denselayer18.conv1.weight\n",
      "\t features.denseblock3.denselayer18.norm2.weight\n",
      "\t features.denseblock3.denselayer18.norm2.bias\n",
      "\t features.denseblock3.denselayer18.conv2.weight\n",
      "\t features.denseblock3.denselayer19.norm1.weight\n",
      "\t features.denseblock3.denselayer19.norm1.bias\n",
      "\t features.denseblock3.denselayer19.conv1.weight\n",
      "\t features.denseblock3.denselayer19.norm2.weight\n",
      "\t features.denseblock3.denselayer19.norm2.bias\n",
      "\t features.denseblock3.denselayer19.conv2.weight\n",
      "\t features.denseblock3.denselayer20.norm1.weight\n",
      "\t features.denseblock3.denselayer20.norm1.bias\n",
      "\t features.denseblock3.denselayer20.conv1.weight\n",
      "\t features.denseblock3.denselayer20.norm2.weight\n",
      "\t features.denseblock3.denselayer20.norm2.bias\n",
      "\t features.denseblock3.denselayer20.conv2.weight\n",
      "\t features.denseblock3.denselayer21.norm1.weight\n",
      "\t features.denseblock3.denselayer21.norm1.bias\n",
      "\t features.denseblock3.denselayer21.conv1.weight\n",
      "\t features.denseblock3.denselayer21.norm2.weight\n",
      "\t features.denseblock3.denselayer21.norm2.bias\n",
      "\t features.denseblock3.denselayer21.conv2.weight\n",
      "\t features.denseblock3.denselayer22.norm1.weight\n",
      "\t features.denseblock3.denselayer22.norm1.bias\n",
      "\t features.denseblock3.denselayer22.conv1.weight\n",
      "\t features.denseblock3.denselayer22.norm2.weight\n",
      "\t features.denseblock3.denselayer22.norm2.bias\n",
      "\t features.denseblock3.denselayer22.conv2.weight\n",
      "\t features.denseblock3.denselayer23.norm1.weight\n",
      "\t features.denseblock3.denselayer23.norm1.bias\n",
      "\t features.denseblock3.denselayer23.conv1.weight\n",
      "\t features.denseblock3.denselayer23.norm2.weight\n",
      "\t features.denseblock3.denselayer23.norm2.bias\n",
      "\t features.denseblock3.denselayer23.conv2.weight\n",
      "\t features.denseblock3.denselayer24.norm1.weight\n",
      "\t features.denseblock3.denselayer24.norm1.bias\n",
      "\t features.denseblock3.denselayer24.conv1.weight\n",
      "\t features.denseblock3.denselayer24.norm2.weight\n",
      "\t features.denseblock3.denselayer24.norm2.bias\n",
      "\t features.denseblock3.denselayer24.conv2.weight\n",
      "\t features.transition3.norm.weight\n",
      "\t features.transition3.norm.bias\n",
      "\t features.transition3.conv.weight\n",
      "\t features.denseblock4.denselayer1.norm1.weight\n",
      "\t features.denseblock4.denselayer1.norm1.bias\n",
      "\t features.denseblock4.denselayer1.conv1.weight\n",
      "\t features.denseblock4.denselayer1.norm2.weight\n",
      "\t features.denseblock4.denselayer1.norm2.bias\n",
      "\t features.denseblock4.denselayer1.conv2.weight\n",
      "\t features.denseblock4.denselayer2.norm1.weight\n",
      "\t features.denseblock4.denselayer2.norm1.bias\n",
      "\t features.denseblock4.denselayer2.conv1.weight\n",
      "\t features.denseblock4.denselayer2.norm2.weight\n",
      "\t features.denseblock4.denselayer2.norm2.bias\n",
      "\t features.denseblock4.denselayer2.conv2.weight\n",
      "\t features.denseblock4.denselayer3.norm1.weight\n",
      "\t features.denseblock4.denselayer3.norm1.bias\n",
      "\t features.denseblock4.denselayer3.conv1.weight\n",
      "\t features.denseblock4.denselayer3.norm2.weight\n",
      "\t features.denseblock4.denselayer3.norm2.bias\n",
      "\t features.denseblock4.denselayer3.conv2.weight\n",
      "\t features.denseblock4.denselayer4.norm1.weight\n",
      "\t features.denseblock4.denselayer4.norm1.bias\n",
      "\t features.denseblock4.denselayer4.conv1.weight\n",
      "\t features.denseblock4.denselayer4.norm2.weight\n",
      "\t features.denseblock4.denselayer4.norm2.bias\n",
      "\t features.denseblock4.denselayer4.conv2.weight\n",
      "\t features.denseblock4.denselayer5.norm1.weight\n",
      "\t features.denseblock4.denselayer5.norm1.bias\n",
      "\t features.denseblock4.denselayer5.conv1.weight\n",
      "\t features.denseblock4.denselayer5.norm2.weight\n",
      "\t features.denseblock4.denselayer5.norm2.bias\n",
      "\t features.denseblock4.denselayer5.conv2.weight\n",
      "\t features.denseblock4.denselayer6.norm1.weight\n",
      "\t features.denseblock4.denselayer6.norm1.bias\n",
      "\t features.denseblock4.denselayer6.conv1.weight\n",
      "\t features.denseblock4.denselayer6.norm2.weight\n",
      "\t features.denseblock4.denselayer6.norm2.bias\n",
      "\t features.denseblock4.denselayer6.conv2.weight\n",
      "\t features.denseblock4.denselayer7.norm1.weight\n",
      "\t features.denseblock4.denselayer7.norm1.bias\n",
      "\t features.denseblock4.denselayer7.conv1.weight\n",
      "\t features.denseblock4.denselayer7.norm2.weight\n",
      "\t features.denseblock4.denselayer7.norm2.bias\n",
      "\t features.denseblock4.denselayer7.conv2.weight\n",
      "\t features.denseblock4.denselayer8.norm1.weight\n",
      "\t features.denseblock4.denselayer8.norm1.bias\n",
      "\t features.denseblock4.denselayer8.conv1.weight\n",
      "\t features.denseblock4.denselayer8.norm2.weight\n",
      "\t features.denseblock4.denselayer8.norm2.bias\n",
      "\t features.denseblock4.denselayer8.conv2.weight\n",
      "\t features.denseblock4.denselayer9.norm1.weight\n",
      "\t features.denseblock4.denselayer9.norm1.bias\n",
      "\t features.denseblock4.denselayer9.conv1.weight\n",
      "\t features.denseblock4.denselayer9.norm2.weight\n",
      "\t features.denseblock4.denselayer9.norm2.bias\n",
      "\t features.denseblock4.denselayer9.conv2.weight\n",
      "\t features.denseblock4.denselayer10.norm1.weight\n",
      "\t features.denseblock4.denselayer10.norm1.bias\n",
      "\t features.denseblock4.denselayer10.conv1.weight\n",
      "\t features.denseblock4.denselayer10.norm2.weight\n",
      "\t features.denseblock4.denselayer10.norm2.bias\n",
      "\t features.denseblock4.denselayer10.conv2.weight\n",
      "\t features.denseblock4.denselayer11.norm1.weight\n",
      "\t features.denseblock4.denselayer11.norm1.bias\n",
      "\t features.denseblock4.denselayer11.conv1.weight\n",
      "\t features.denseblock4.denselayer11.norm2.weight\n",
      "\t features.denseblock4.denselayer11.norm2.bias\n",
      "\t features.denseblock4.denselayer11.conv2.weight\n",
      "\t features.denseblock4.denselayer12.norm1.weight\n",
      "\t features.denseblock4.denselayer12.norm1.bias\n",
      "\t features.denseblock4.denselayer12.conv1.weight\n",
      "\t features.denseblock4.denselayer12.norm2.weight\n",
      "\t features.denseblock4.denselayer12.norm2.bias\n",
      "\t features.denseblock4.denselayer12.conv2.weight\n",
      "\t features.denseblock4.denselayer13.norm1.weight\n",
      "\t features.denseblock4.denselayer13.norm1.bias\n",
      "\t features.denseblock4.denselayer13.conv1.weight\n",
      "\t features.denseblock4.denselayer13.norm2.weight\n",
      "\t features.denseblock4.denselayer13.norm2.bias\n",
      "\t features.denseblock4.denselayer13.conv2.weight\n",
      "\t features.denseblock4.denselayer14.norm1.weight\n",
      "\t features.denseblock4.denselayer14.norm1.bias\n",
      "\t features.denseblock4.denselayer14.conv1.weight\n",
      "\t features.denseblock4.denselayer14.norm2.weight\n",
      "\t features.denseblock4.denselayer14.norm2.bias\n",
      "\t features.denseblock4.denselayer14.conv2.weight\n",
      "\t features.denseblock4.denselayer15.norm1.weight\n",
      "\t features.denseblock4.denselayer15.norm1.bias\n",
      "\t features.denseblock4.denselayer15.conv1.weight\n",
      "\t features.denseblock4.denselayer15.norm2.weight\n",
      "\t features.denseblock4.denselayer15.norm2.bias\n",
      "\t features.denseblock4.denselayer15.conv2.weight\n",
      "\t features.denseblock4.denselayer16.norm1.weight\n",
      "\t features.denseblock4.denselayer16.norm1.bias\n",
      "\t features.denseblock4.denselayer16.conv1.weight\n",
      "\t features.denseblock4.denselayer16.norm2.weight\n",
      "\t features.denseblock4.denselayer16.norm2.bias\n",
      "\t features.denseblock4.denselayer16.conv2.weight\n",
      "\t features.norm5.weight\n",
      "\t features.norm5.bias\n",
      "\t classifier.weight\n",
      "\t classifier.bias\n",
      "Number of parameters: 364\n"
     ]
    }
   ],
   "source": [
    "#check number of parameters\n",
    "num_parameter_to_learn = 0\n",
    "for name,param in model_ft.named_parameters():\n",
    "  if param.requires_grad == True:\n",
    "    num_parameter_to_learn = num_parameter_to_learn + 1\n",
    "    print(\"\\t\",name)\n",
    "print('Number of parameters: ' + str(num_parameter_to_learn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_-D3mpoggk4y"
   },
   "source": [
    "Create the Optimizer\n",
    "--------------------\n",
    "\n",
    "Now that the model structure is correct, the final step for finetuning\n",
    "and feature extracting is to create an optimizer that only updates the\n",
    "desired parameters. Recall that after loading the pretrained model, but\n",
    "before reshaping, if ``feature_extract=True`` we manually set all of the\n",
    "parameter’s ``.requires_grad`` attributes to False. Then the\n",
    "reinitialized layer’s parameters have ``.requires_grad=True`` by\n",
    "default. So now we know that *all parameters that have\n",
    ".requires_grad=True should be optimized.* Next, we make a list of such\n",
    "parameters and input this list to the SGD algorithm constructor.\n",
    "\n",
    "To verify this, check out the printed parameters to learn. When\n",
    "finetuning, this list should be long and include all of the model\n",
    "parameters. However, when feature extracting this list should be short\n",
    "and only include the weights and biases of the reshaped layers.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 523,
     "status": "ok",
     "timestamp": 1579899293541,
     "user": {
      "displayName": "Panarit Jahiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyRepiyf8dxiCFWxNWE5mKhhk_KY2eZCRB8To0=s64",
      "userId": "17560933570130372928"
     },
     "user_tz": -60
    },
    "id": "GoMm3qRGgk4z",
    "outputId": "4821bbc3-31c2-46ae-8db9-5f3bbffa53dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "Number of parameters: 364\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are \n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            # print(\"\\t\",name)\n",
    "else:\n",
    "    num_parameter_to_learn = 0\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            num_parameter_to_learn = num_parameter_to_learn + 1\n",
    "            # print(\"\\t\",name)\n",
    "    print('Number of parameters: ' + str(num_parameter_to_learn))\n",
    "# Observe that all parameters are being optimized\n",
    "# optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "\n",
    "# optimizer_ft = optim.SGD(\n",
    "#         filter(lambda p: p.requires_grad, model_ft.parameters()),\n",
    "#         lr=LR,\n",
    "#         momentum=0.9,\n",
    "#         weight_decay=WEIGHT_DECAY)\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model_ft.parameters()), lr = LR, betas = (0.9, 0.999))\n",
    "# optimizer_ft = optim.SGD(model_ft.parameters(), lr=LR, weight_decay=WEIGHT_DECAY, momentum=0.9)\n",
    "print(optimizer_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1463,
     "status": "ok",
     "timestamp": 1579530003241,
     "user": {
      "displayName": "Panarit Jahiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyRepiyf8dxiCFWxNWE5mKhhk_KY2eZCRB8To0=s64",
      "userId": "17560933570130372928"
     },
     "user_tz": -60
    },
    "id": "CNJ2LhDx4EWM",
    "outputId": "95526d08-c5d5-40d3-9990-07a5ded63c3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# iterate over dataloader, just for testing\n",
    "for idx, data in enumerate(dataloaders_dict['train']):\n",
    "    inputs, labels, _ = data\n",
    "#         inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "    inputs = Variable(inputs.to(device))\n",
    "    labels = Variable(labels.float().to(device))\n",
    "    outputs = model_ft(inputs)\n",
    "    # print(torch.max(outputs))\n",
    "    print(inputs.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "volCaB6Kgk5C"
   },
   "source": [
    "Run Training and Validation Step\n",
    "--------------------------------\n",
    "\n",
    "Finally, the last step is to setup the loss for the model, then run the\n",
    "training and validation function for the set number of epochs. Notice,\n",
    "depending on the number of epochs this step may take a while on a CPU.\n",
    "Also, the default learning rate is not optimal for all of the models, so\n",
    "to achieve maximum accuracy it would be necessary to tune for each model\n",
    "separately.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1611,
     "status": "ok",
     "timestamp": 1579182971783,
     "user": {
      "displayName": "Panarit Jahiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyRepiyf8dxiCFWxNWE5mKhhk_KY2eZCRB8To0=s64",
      "userId": "17560933570130372928"
     },
     "user_tz": -60
    },
    "id": "b2G_ITCpQp3L",
    "outputId": "a8828e38-e8b8-4f43-a73c-d8e6e6b8fdf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2989369,
     "status": "ok",
     "timestamp": 1579906914126,
     "user": {
      "displayName": "Panarit Jahiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyRepiyf8dxiCFWxNWE5mKhhk_KY2eZCRB8To0=s64",
      "userId": "17560933570130372928"
     },
     "user_tz": -60
    },
    "id": "1VXRCrecgk5H",
    "outputId": "c635c2a1-7459-4d4b-f28d-29ac78025703",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: \n",
      "Learning rate: 0.001\n",
      "Weight decay: 0\n",
      "Decaying: False\n",
      "Num of epochs: 100\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 1/100\n",
      "----------\n",
      "Loss of iteration 100 is: 31.59890365600586\n",
      "Loss of iteration 200 is: 32.23783874511719\n",
      "Loss of iteration 300 is: 33.208740234375\n",
      "Loss of iteration 400 is: 32.266090393066406\n",
      "Loss of iteration 500 is: 31.544246673583984\n",
      "Loss of iteration 600 is: 28.400928497314453\n",
      "Loss of iteration 700 is: 31.855567932128906\n",
      "Loss of iteration 800 is: 43.8364143371582\n",
      "Loss of iteration 900 is: 31.15204429626465\n",
      "Loss of iteration 1000 is: 29.749685287475586\n",
      "Loss of iteration 1100 is: 29.533992767333984\n",
      "Loss of iteration 1200 is: 33.20410919189453\n",
      "Loss of iteration 1300 is: 32.3964958190918\n",
      "Loss of iteration 1400 is: 37.30888366699219\n",
      "Loss of iteration 1500 is: 35.16665267944336\n",
      "Loss of iteration 1600 is: 35.299564361572266\n",
      "Loss of iteration 1700 is: 32.837135314941406\n",
      "Loss of iteration 1800 is: 40.04609298706055\n",
      "Loss of iteration 1900 is: 29.91036605834961\n",
      "Loss of iteration 2000 is: 30.928911209106445\n",
      "Loss of iteration 2100 is: 32.12664031982422\n",
      "Loss of iteration 2200 is: 30.143136978149414\n",
      "Loss of iteration 2300 is: 30.42247772216797\n",
      "train epoch 1:loss 1.0302 with data size 76195\n",
      "Loss of iteration 100 is: 29.39512825012207\n",
      "Loss of iteration 200 is: 30.316753387451172\n",
      "Loss of iteration 300 is: 31.786325454711914\n",
      "val epoch 1:loss 0.9974 with data size 10329\n",
      "saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DenseNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type _DenseBlock. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type _DenseLayer. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type _Transition. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AvgPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "----------\n",
      "Loss of iteration 100 is: 25.157453536987305\n",
      "Loss of iteration 200 is: 29.651470184326172\n",
      "Loss of iteration 300 is: 28.488290786743164\n",
      "Loss of iteration 400 is: 29.47282600402832\n",
      "Loss of iteration 500 is: 25.180097579956055\n",
      "Loss of iteration 600 is: 30.087875366210938\n",
      "Loss of iteration 700 is: 32.82411193847656\n",
      "Loss of iteration 800 is: 34.27602767944336\n",
      "Loss of iteration 900 is: 31.057819366455078\n",
      "Loss of iteration 1000 is: 32.1849479675293\n",
      "Loss of iteration 1100 is: 31.452306747436523\n",
      "Loss of iteration 1200 is: 40.883235931396484\n",
      "Loss of iteration 1300 is: 33.08598709106445\n",
      "Loss of iteration 1400 is: 27.212255477905273\n",
      "Loss of iteration 1500 is: 27.048358917236328\n",
      "Loss of iteration 1600 is: 27.128135681152344\n",
      "Loss of iteration 1700 is: 31.684083938598633\n",
      "Loss of iteration 1800 is: 22.424116134643555\n",
      "Loss of iteration 1900 is: 28.751544952392578\n",
      "Loss of iteration 2000 is: 33.60124969482422\n",
      "Loss of iteration 2100 is: 30.26462745666504\n",
      "Loss of iteration 2200 is: 28.430871963500977\n",
      "Loss of iteration 2300 is: 32.51778030395508\n",
      "train epoch 2:loss 0.9538 with data size 76195\n",
      "Loss of iteration 100 is: 30.512760162353516\n",
      "Loss of iteration 200 is: 42.24482727050781\n",
      "Loss of iteration 300 is: 35.44766616821289\n",
      "val epoch 2:loss 1.1035 with data size 10329\n",
      "Epoch 3/100\n",
      "----------\n",
      "Loss of iteration 100 is: 32.842044830322266\n",
      "Loss of iteration 200 is: 34.5523567199707\n",
      "Loss of iteration 300 is: 26.08113670349121\n",
      "Loss of iteration 400 is: 30.68071746826172\n",
      "Loss of iteration 500 is: 36.112693786621094\n",
      "Loss of iteration 600 is: 35.96558380126953\n",
      "Loss of iteration 700 is: 31.29197120666504\n",
      "Loss of iteration 800 is: 25.236019134521484\n",
      "Loss of iteration 900 is: 27.743852615356445\n",
      "Loss of iteration 1000 is: 25.459888458251953\n",
      "Loss of iteration 1100 is: 32.15693664550781\n",
      "Loss of iteration 1200 is: 28.300949096679688\n",
      "Loss of iteration 1300 is: 25.93987274169922\n",
      "Loss of iteration 1400 is: 27.037057876586914\n",
      "Loss of iteration 1500 is: 24.67506980895996\n",
      "Loss of iteration 1600 is: 28.367082595825195\n",
      "Loss of iteration 1700 is: 26.609121322631836\n",
      "Loss of iteration 1800 is: 29.309101104736328\n",
      "Loss of iteration 1900 is: 25.75486183166504\n",
      "Loss of iteration 2000 is: 31.21695899963379\n",
      "Loss of iteration 2100 is: 30.33907127380371\n",
      "Loss of iteration 2200 is: 30.806991577148438\n",
      "Loss of iteration 2300 is: 34.35558319091797\n",
      "train epoch 3:loss 0.9257 with data size 76195\n",
      "Loss of iteration 100 is: 23.662691116333008\n",
      "Loss of iteration 200 is: 32.09521484375\n",
      "Loss of iteration 300 is: 30.164562225341797\n",
      "val epoch 3:loss 0.9328 with data size 10329\n",
      "saving\n",
      "Epoch 4/100\n",
      "----------\n",
      "Loss of iteration 100 is: 36.67601013183594\n",
      "Loss of iteration 200 is: 33.76311111450195\n",
      "Loss of iteration 300 is: 26.89785385131836\n",
      "Loss of iteration 400 is: 29.317947387695312\n",
      "Loss of iteration 500 is: 29.35455894470215\n",
      "Loss of iteration 600 is: 30.145830154418945\n",
      "Loss of iteration 700 is: 24.52897071838379\n",
      "Loss of iteration 800 is: 28.52756118774414\n",
      "Loss of iteration 900 is: 29.493289947509766\n",
      "Loss of iteration 1000 is: 29.855989456176758\n",
      "Loss of iteration 1100 is: 26.213911056518555\n",
      "Loss of iteration 1200 is: 28.345401763916016\n",
      "Loss of iteration 1300 is: 27.80206871032715\n",
      "Loss of iteration 1400 is: 27.58487892150879\n",
      "Loss of iteration 1500 is: 27.07897186279297\n",
      "Loss of iteration 1600 is: 24.609346389770508\n",
      "Loss of iteration 1700 is: 26.07221031188965\n",
      "Loss of iteration 1800 is: 32.49960708618164\n",
      "Loss of iteration 1900 is: 30.31821632385254\n",
      "Loss of iteration 2000 is: 38.770790100097656\n",
      "Loss of iteration 2100 is: 31.067628860473633\n",
      "Loss of iteration 2200 is: 24.42799186706543\n",
      "Loss of iteration 2300 is: 28.32973289489746\n",
      "train epoch 4:loss 0.9015 with data size 76195\n",
      "Loss of iteration 100 is: 34.412933349609375\n",
      "Loss of iteration 200 is: 25.90780258178711\n",
      "Loss of iteration 300 is: 31.154399871826172\n",
      "val epoch 4:loss 0.9331 with data size 10329\n",
      "Epoch 5/100\n",
      "----------\n",
      "Loss of iteration 100 is: 25.14655876159668\n",
      "Loss of iteration 200 is: 30.21255111694336\n",
      "Loss of iteration 300 is: 28.008682250976562\n",
      "Loss of iteration 400 is: 27.39696502685547\n",
      "Loss of iteration 500 is: 29.06295394897461\n",
      "Loss of iteration 600 is: 31.703655242919922\n",
      "Loss of iteration 700 is: 29.067520141601562\n",
      "Loss of iteration 800 is: 26.845905303955078\n",
      "Loss of iteration 900 is: 28.254613876342773\n",
      "Loss of iteration 1000 is: 30.19285774230957\n",
      "Loss of iteration 1100 is: 41.26207733154297\n",
      "Loss of iteration 1200 is: 33.4033088684082\n",
      "Loss of iteration 1300 is: 21.83060646057129\n",
      "Loss of iteration 1400 is: 33.6004638671875\n",
      "Loss of iteration 1500 is: 32.63153076171875\n",
      "Loss of iteration 1600 is: 26.13114356994629\n",
      "Loss of iteration 1700 is: 29.83950424194336\n",
      "Loss of iteration 1800 is: 24.595760345458984\n",
      "Loss of iteration 1900 is: 35.13856506347656\n",
      "Loss of iteration 2000 is: 25.92347526550293\n",
      "Loss of iteration 2100 is: 25.533971786499023\n",
      "Loss of iteration 2200 is: 25.813560485839844\n",
      "Loss of iteration 2300 is: 24.370059967041016\n",
      "train epoch 5:loss 0.8850 with data size 76195\n",
      "Loss of iteration 100 is: 24.814119338989258\n",
      "Loss of iteration 200 is: 20.61928367614746\n",
      "Loss of iteration 300 is: 30.952028274536133\n",
      "val epoch 5:loss 0.9115 with data size 10329\n",
      "saving\n",
      "Epoch 6/100\n",
      "----------\n",
      "Loss of iteration 100 is: 31.564767837524414\n",
      "Loss of iteration 200 is: 31.105182647705078\n",
      "Loss of iteration 300 is: 26.859712600708008\n",
      "Loss of iteration 400 is: 33.22096252441406\n",
      "Loss of iteration 500 is: 28.133689880371094\n",
      "Loss of iteration 600 is: 23.20636558532715\n",
      "Loss of iteration 700 is: 28.781768798828125\n",
      "Loss of iteration 800 is: 27.319068908691406\n",
      "Loss of iteration 900 is: 22.37862205505371\n",
      "Loss of iteration 1000 is: 24.0507869720459\n",
      "Loss of iteration 1100 is: 29.248783111572266\n",
      "Loss of iteration 1200 is: 25.079561233520508\n",
      "Loss of iteration 1300 is: 20.48261833190918\n",
      "Loss of iteration 1400 is: 32.97576141357422\n",
      "Loss of iteration 1500 is: 31.6114559173584\n",
      "Loss of iteration 1600 is: 18.386043548583984\n",
      "Loss of iteration 1700 is: 25.99396324157715\n",
      "Loss of iteration 1800 is: 32.80259704589844\n",
      "Loss of iteration 1900 is: 33.376670837402344\n",
      "Loss of iteration 2000 is: 27.96987533569336\n",
      "Loss of iteration 2100 is: 24.131593704223633\n",
      "Loss of iteration 2200 is: 24.779207229614258\n",
      "Loss of iteration 2300 is: 25.845434188842773\n",
      "train epoch 6:loss 0.8681 with data size 76195\n",
      "Loss of iteration 100 is: 28.520584106445312\n",
      "Loss of iteration 200 is: 27.688533782958984\n",
      "Loss of iteration 300 is: 27.121212005615234\n",
      "val epoch 6:loss 0.9313 with data size 10329\n",
      "Epoch 7/100\n",
      "----------\n",
      "Loss of iteration 100 is: 28.276844024658203\n",
      "Loss of iteration 200 is: 26.318288803100586\n",
      "Loss of iteration 300 is: 28.191421508789062\n",
      "Loss of iteration 400 is: 27.989025115966797\n",
      "Loss of iteration 500 is: 23.633039474487305\n",
      "Loss of iteration 600 is: 30.170578002929688\n",
      "Loss of iteration 700 is: 26.4807186126709\n",
      "Loss of iteration 800 is: 31.62688446044922\n",
      "Loss of iteration 900 is: 21.185468673706055\n",
      "Loss of iteration 1000 is: 24.81488800048828\n",
      "Loss of iteration 1100 is: 22.18743133544922\n",
      "Loss of iteration 1200 is: 22.71178436279297\n",
      "Loss of iteration 1300 is: 32.68836975097656\n",
      "Loss of iteration 1400 is: 28.179340362548828\n",
      "Loss of iteration 1500 is: 23.102779388427734\n",
      "Loss of iteration 1600 is: 33.728118896484375\n",
      "Loss of iteration 1700 is: 27.129207611083984\n",
      "Loss of iteration 1800 is: 31.341318130493164\n",
      "Loss of iteration 1900 is: 27.401012420654297\n",
      "Loss of iteration 2000 is: 22.0345516204834\n",
      "Loss of iteration 2100 is: 39.04510498046875\n",
      "Loss of iteration 2200 is: 26.580522537231445\n",
      "Loss of iteration 2300 is: 24.813899993896484\n",
      "train epoch 7:loss 0.8510 with data size 76195\n",
      "Loss of iteration 100 is: 30.045068740844727\n",
      "Loss of iteration 200 is: 26.70054817199707\n",
      "Loss of iteration 300 is: 33.74408721923828\n",
      "val epoch 7:loss 0.9207 with data size 10329\n",
      "Epoch 8/100\n",
      "----------\n",
      "Loss of iteration 100 is: 29.501869201660156\n",
      "Loss of iteration 200 is: 35.43257522583008\n",
      "Loss of iteration 300 is: 23.2108211517334\n",
      "Loss of iteration 400 is: 28.149507522583008\n",
      "Loss of iteration 500 is: 30.276050567626953\n",
      "Loss of iteration 600 is: 40.41807556152344\n",
      "Loss of iteration 700 is: 24.267520904541016\n",
      "Loss of iteration 800 is: 31.432668685913086\n",
      "Loss of iteration 900 is: 35.52031326293945\n",
      "Loss of iteration 1000 is: 28.403797149658203\n",
      "Loss of iteration 1100 is: 24.643627166748047\n",
      "Loss of iteration 1200 is: 30.58371353149414\n",
      "Loss of iteration 1300 is: 23.37355613708496\n",
      "Loss of iteration 1400 is: 24.048053741455078\n",
      "Loss of iteration 1500 is: 24.841915130615234\n",
      "Loss of iteration 1600 is: 23.356754302978516\n",
      "Loss of iteration 1700 is: 24.479337692260742\n",
      "Loss of iteration 1800 is: 37.49544143676758\n",
      "Loss of iteration 1900 is: 30.691024780273438\n",
      "Loss of iteration 2000 is: 26.72822380065918\n",
      "Loss of iteration 2100 is: 19.83069610595703\n",
      "Loss of iteration 2200 is: 26.680727005004883\n",
      "Loss of iteration 2300 is: 23.757352828979492\n",
      "train epoch 8:loss 0.8393 with data size 76195\n",
      "Loss of iteration 100 is: 26.61122703552246\n",
      "Loss of iteration 200 is: 26.8185977935791\n",
      "Loss of iteration 300 is: 24.65627670288086\n",
      "val epoch 8:loss 0.8927 with data size 10329\n",
      "saving\n",
      "Epoch 9/100\n",
      "----------\n",
      "Loss of iteration 100 is: 23.62954330444336\n",
      "Loss of iteration 200 is: 24.767602920532227\n",
      "Loss of iteration 300 is: 21.427629470825195\n",
      "Loss of iteration 400 is: 24.842273712158203\n",
      "Loss of iteration 500 is: 28.17209815979004\n",
      "Loss of iteration 600 is: 24.65938949584961\n",
      "Loss of iteration 700 is: 28.07005500793457\n",
      "Loss of iteration 800 is: 33.29289245605469\n",
      "Loss of iteration 900 is: 26.927295684814453\n",
      "Loss of iteration 1000 is: 22.936153411865234\n",
      "Loss of iteration 1100 is: 23.047727584838867\n",
      "Loss of iteration 1200 is: 37.014549255371094\n",
      "Loss of iteration 1300 is: 25.14965057373047\n",
      "Loss of iteration 1400 is: 27.680500030517578\n",
      "Loss of iteration 1500 is: 24.077842712402344\n",
      "Loss of iteration 1600 is: 26.146493911743164\n",
      "Loss of iteration 1700 is: 21.910737991333008\n",
      "Loss of iteration 1800 is: 26.365556716918945\n",
      "Loss of iteration 1900 is: 31.125585556030273\n",
      "Loss of iteration 2000 is: 20.26626968383789\n",
      "Loss of iteration 2100 is: 26.978939056396484\n",
      "Loss of iteration 2200 is: 22.17927360534668\n",
      "Loss of iteration 2300 is: 26.881099700927734\n",
      "train epoch 9:loss 0.8249 with data size 76195\n",
      "Loss of iteration 100 is: 25.154394149780273\n",
      "Loss of iteration 200 is: 24.960065841674805\n",
      "Loss of iteration 300 is: 27.16733741760254\n",
      "val epoch 9:loss 0.8916 with data size 10329\n",
      "saving\n",
      "Epoch 10/100\n",
      "----------\n",
      "Loss of iteration 100 is: 23.1987361907959\n",
      "Loss of iteration 200 is: 29.911216735839844\n",
      "Loss of iteration 300 is: 23.35186195373535\n",
      "Loss of iteration 400 is: 26.939075469970703\n",
      "Loss of iteration 500 is: 25.168209075927734\n",
      "Loss of iteration 600 is: 22.47772979736328\n",
      "Loss of iteration 700 is: 19.916208267211914\n",
      "Loss of iteration 800 is: 25.213319778442383\n",
      "Loss of iteration 900 is: 28.372655868530273\n",
      "Loss of iteration 1000 is: 25.242969512939453\n",
      "Loss of iteration 1100 is: 29.276033401489258\n",
      "Loss of iteration 1200 is: 21.202991485595703\n",
      "Loss of iteration 1300 is: 24.62626075744629\n",
      "Loss of iteration 1400 is: 23.30432891845703\n",
      "Loss of iteration 1500 is: 31.622516632080078\n",
      "Loss of iteration 1600 is: 27.155662536621094\n",
      "Loss of iteration 1700 is: 22.097028732299805\n",
      "Loss of iteration 1800 is: 20.757184982299805\n",
      "Loss of iteration 1900 is: 23.72132110595703\n",
      "Loss of iteration 2000 is: 20.132991790771484\n",
      "Loss of iteration 2100 is: 18.61970329284668\n",
      "Loss of iteration 2200 is: 24.864301681518555\n",
      "Loss of iteration 2300 is: 32.01115798950195\n",
      "train epoch 10:loss 0.8062 with data size 76195\n",
      "Loss of iteration 100 is: 32.6199951171875\n",
      "Loss of iteration 200 is: 29.217531204223633\n",
      "Loss of iteration 300 is: 21.352800369262695\n",
      "val epoch 10:loss 0.8829 with data size 10329\n",
      "saving\n",
      "Epoch 11/100\n",
      "----------\n",
      "Loss of iteration 100 is: 21.92697525024414\n",
      "Loss of iteration 200 is: 22.361719131469727\n",
      "Loss of iteration 300 is: 27.613845825195312\n",
      "Loss of iteration 400 is: 26.912647247314453\n",
      "Loss of iteration 500 is: 37.09105682373047\n",
      "Loss of iteration 600 is: 24.625694274902344\n",
      "Loss of iteration 700 is: 26.10347557067871\n",
      "Loss of iteration 800 is: 27.459924697875977\n",
      "Loss of iteration 900 is: 24.55255889892578\n",
      "Loss of iteration 1000 is: 24.815082550048828\n",
      "Loss of iteration 1100 is: 26.51267433166504\n",
      "Loss of iteration 1200 is: 22.367830276489258\n",
      "Loss of iteration 1300 is: 24.18988800048828\n",
      "Loss of iteration 1400 is: 27.324460983276367\n",
      "Loss of iteration 1500 is: 31.679208755493164\n",
      "Loss of iteration 1600 is: 22.6362247467041\n",
      "Loss of iteration 1700 is: 22.658992767333984\n",
      "Loss of iteration 1800 is: 27.275440216064453\n",
      "Loss of iteration 1900 is: 23.61648941040039\n",
      "Loss of iteration 2000 is: 25.756467819213867\n",
      "Loss of iteration 2100 is: 19.202733993530273\n",
      "Loss of iteration 2200 is: 24.3803768157959\n",
      "Loss of iteration 2300 is: 29.975631713867188\n",
      "train epoch 11:loss 0.7890 with data size 76195\n",
      "Loss of iteration 100 is: 34.29207992553711\n",
      "Loss of iteration 200 is: 33.404075622558594\n",
      "Loss of iteration 300 is: 19.39376449584961\n",
      "val epoch 11:loss 0.9064 with data size 10329\n",
      "Epoch 12/100\n",
      "----------\n",
      "Loss of iteration 100 is: 21.079452514648438\n",
      "Loss of iteration 200 is: 19.704715728759766\n",
      "Loss of iteration 300 is: 27.20655632019043\n",
      "Loss of iteration 400 is: 21.461597442626953\n",
      "Loss of iteration 500 is: 20.436885833740234\n",
      "Loss of iteration 600 is: 19.329524993896484\n",
      "Loss of iteration 700 is: 19.893369674682617\n",
      "Loss of iteration 800 is: 23.069561004638672\n",
      "Loss of iteration 900 is: 25.911075592041016\n",
      "Loss of iteration 1000 is: 24.46750831604004\n",
      "Loss of iteration 1100 is: 30.786962509155273\n",
      "Loss of iteration 1200 is: 21.923683166503906\n",
      "Loss of iteration 1300 is: 26.238216400146484\n",
      "Loss of iteration 1400 is: 31.33382225036621\n",
      "Loss of iteration 1500 is: 26.4460506439209\n",
      "Loss of iteration 1600 is: 23.75461196899414\n",
      "Loss of iteration 1700 is: 22.565547943115234\n",
      "Loss of iteration 1800 is: 24.670940399169922\n",
      "Loss of iteration 1900 is: 29.800369262695312\n",
      "Loss of iteration 2000 is: 29.26527976989746\n",
      "Loss of iteration 2100 is: 24.327411651611328\n",
      "Loss of iteration 2200 is: 23.604602813720703\n",
      "Loss of iteration 2300 is: 24.082387924194336\n",
      "train epoch 12:loss 0.7680 with data size 76195\n",
      "Loss of iteration 100 is: 30.27728843688965\n",
      "Loss of iteration 200 is: 29.998241424560547\n",
      "Loss of iteration 300 is: 25.303707122802734\n",
      "val epoch 12:loss 0.8933 with data size 10329\n",
      "Epoch 13/100\n",
      "----------\n",
      "Loss of iteration 100 is: 21.332242965698242\n",
      "Loss of iteration 200 is: 27.71570587158203\n",
      "Loss of iteration 300 is: 25.45201873779297\n",
      "Loss of iteration 400 is: 19.784446716308594\n",
      "Loss of iteration 500 is: 23.023042678833008\n",
      "Loss of iteration 600 is: 18.366413116455078\n",
      "Loss of iteration 700 is: 22.151268005371094\n",
      "Loss of iteration 800 is: 21.61367416381836\n",
      "Loss of iteration 900 is: 18.700332641601562\n",
      "Loss of iteration 1000 is: 17.774206161499023\n",
      "Loss of iteration 1100 is: 21.31235694885254\n",
      "Loss of iteration 1200 is: 23.093772888183594\n",
      "Loss of iteration 1300 is: 31.883193969726562\n",
      "Loss of iteration 1400 is: 25.00543975830078\n",
      "Loss of iteration 1500 is: 22.754549026489258\n",
      "Loss of iteration 1600 is: 20.20491600036621\n",
      "Loss of iteration 1700 is: 21.560054779052734\n",
      "Loss of iteration 1800 is: 30.824359893798828\n",
      "Loss of iteration 1900 is: 24.28676986694336\n",
      "Loss of iteration 2000 is: 25.186119079589844\n",
      "Loss of iteration 2100 is: 29.30215072631836\n",
      "Loss of iteration 2200 is: 22.924659729003906\n",
      "Loss of iteration 2300 is: 28.260868072509766\n",
      "train epoch 13:loss 0.7421 with data size 76195\n",
      "Loss of iteration 100 is: 34.78309631347656\n",
      "Loss of iteration 200 is: 22.651691436767578\n",
      "Loss of iteration 300 is: 25.871540069580078\n",
      "val epoch 13:loss 0.9254 with data size 10329\n",
      "no improvement in 3 epochs, break\n",
      "Training complete in 126m 57s\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "# criterion = nn.BCELoss()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# def weighted_BCELoss(output, target, weights=None):\n",
    "#     output = output.clamp(min=1e-5, max=1-1e-5)\n",
    "#     target = target.float()\n",
    "#     if weights is not None:\n",
    "#         assert len(weights) == 2\n",
    "\n",
    "#         loss = -weights[0] * (target * torch.log(output)) - weights[1] * ((1 - target) * torch.log(1 - output))\n",
    "#     else:\n",
    "#         loss = -target * torch.log(output) - (1 - target) * torch.log(1 - output)\n",
    "\n",
    "#     return torch.sum(loss)\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, best_epoch, best_epoch_train, stats, LR = train_model(model_ft, criterion, optimizer_ft, LR, num_epochs,  dataloaders_dict, dataset_sizes, WEIGHT_DECAY, decay=False, print_time=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 938,
     "status": "ok",
     "timestamp": 1579886929051,
     "user": {
      "displayName": "Panarit Jahiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyRepiyf8dxiCFWxNWE5mKhhk_KY2eZCRB8To0=s64",
      "userId": "17560933570130372928"
     },
     "user_tz": -60
    },
    "id": "TMK2a4dCgk5O",
    "outputId": "f05cc458-ad21-440c-a57b-fb57e33cdd8b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAACgCAYAAAAB6WsAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXxU9bnH8c+TfYdsgJBAwLCDguyi\niIr7Wq1ad21rN2u1tbe19t7W29vF28Xb2rpUq1VbQS3WitSlakVqZZFFNlkCAkmAkAUSErInz/3j\nd5IMgSyEmUySed6vV16ZmXPmzHOGMN/5LeccUVWMMcaErrBgF2CMMSa4LAiMMSbEWRAYY0yIsyAw\nxpgQZ0FgjDEhzoLAGGNCnAWBaZOIhItIhYgM7QG1fCAitwVgu/kiMte7/V8i8nhn1u3C68wVkU1d\nq7Ld7WaLSLfNAW/vPQjUPprAiwh2AcZ/RKTC524cUAM0ePe/rKrPH8/2VLUBSPBTeT2eqv6PP7Yj\nIhFAHTBcVXd5214CjPfH9nuqzu6jiPwYyFDV2wJdk+kcC4I+RFWbP7RFZBfwRVV9p631RSRCVeu7\nozZj/MX+bv3PuoZCiIj8WEReFJEFIlIO3CQis0RkuYiUisg+EXlYRCK99SNEREUky7v/Z2/5GyJS\nLiLLRGR4G68VJiILRaTA2/YSERnrs7zdbYnIhSKyVUTKROQ3gLTxOpkiUiUi/XwemyYihV79I0Xk\nPRE5ICLFIvIn33WP8f4843P/NhHZ7T3vvlbrtvm+AUu935u8rrWrRWSeF85Nzx8vIu97z98gIpd0\n9r1pj4hkiMhib39zROTzPstmisgaETkkIvtF5Bfe43EiMl9ESrx6VopIWjsvc5pXc5n3txTtbaf1\nPt4vInu919vidR1dCnwHuNF7b1Z3ou7Wf7ffFZFKEenvs85072/Nvtx2gQVB6PkMMB/oB7wI1AN3\nA2nAbOBC4MvtPP8G4L+AFCAXaK87ZTEwEhgEbAT+1JlticgAYCFwn1dXPjDjWC+gqnnAR8BVrbb7\nkvetUYAfezWMA0Z4r9kuEZkI/M7b1hBgsLeNJu29b3O83+NVNUFVX2617Sjce/N3IB34JvCiiGS3\n2ofOvs++XgR2evVeB/xcRM7ylv0W+IWqJgHZuPcY4HZcV2IGkAp8Dahu5zWuBc7DvZdTgJtbryAi\n43Hvx2ne610E5KrqYuDnwPPeezOlE3XDkX+3DwEfANf4LL8ZWGAtha6xIAg9H6jqa6raqKpVqvqR\nqq5Q1XpV/RR4AjirnecvVNVVqloHPA9MOtZK3vafUdVyVa0GHgCmiEh8J7Z1KfCxqr7iLfsVUNRO\nTfOB68G1RHAfJPO9Orap6ruqWquqhcD/dbB/Ta4B/qaq/1bVGuB+fFolXXjffM0GonAfynVe990b\nwOd81unU++zLazVMB+5T1WpVXQP8kZYP6jpgpIikev8uK3weTwOyVbXBe92Ko16gxa9VtUBVS3CB\ndqza6oEYYLy4rpyd3vvUlbqh1d8t8Cxwk/f8CNx71/qLhukkC4LQk+d7R0TGiMjfvWb1IeBHuA+F\nthT43K6kjcFkcTOOfi4in3rb3e4t8t12W9sa7FunqjbiWgVt+QtwpogMBM4GqlX1Q6+OQSLykojs\n8ep4poP9a9K6hgrggM/+He/71nrbuXrkGR9341oeTTr1Ph9ju8WqeriN7d6OaxVt9bp/LvYefwZ4\nB2h6nx7soIulw9pUdStwL+59KfS6dQa1Xq+TdUOrv1vgFeBUcTPaLgQKvQAxXWBBEHpaTzX8Pa7b\nJttrwv+ANvrjj9MtwMXAObjmfFO3R2e2vQ/IbLrjfcvPaGtl75vpP3Hf4m8AFvgs/l/c7KmJ3v7d\n1sUaEnDdNE3ae986ms65F8gUEd86hgJ7OlFXR9tNa9Xqat6uqm5V1c8BA3CtrJdFJMZrLT2gqmOB\nM3DdMDeeYC2o6p9VdTYwHAgHfta06HjqPtZzVLUSeNmr82asNXBCLAhMIlAGHBY3mNve+MDxbrcG\nKMH1P//kOJ67GJgkIld4A7DfxPWlt2c+cCturGB+qzoOA2Uikgl8u5M1/AW4whsUjsaNM/h+GLX5\nvnnTbktwfejH8iGu6+ReEYkUkXNwofliJ2s7JlXdCawCfioi0SIyCdcK+DOAiNwsImleC6vM259G\nETlHRCZ4gXsI11XUeCK1iMhYETnbe++qvJ+mbe4HspqCsKO62/Ec8Hngkk6sa9phQWDuxX2AluO+\n5Z7Qh5GPP+K+6e0FNuE+/DpFVffj+vl/ARTjvh2uaPdJ8Ddct0euqvoe1PRDXP9zGbAI9y2yMzWs\nxw0Gv4T7ZlrAkV0iHb1vPwTme7NwfAey8cYcLgOu8PbvYeAGVc3pTG0duA43QF+AGwy+35vfDy5s\nNnszb34JXKeqtbiumb/iQmATrptoPicmGjcoXOzVkgx831v2Im6M5ICIrOxE3W1ZipsCv0JV2+s6\nNB0QuzCNMaa3EpGlwNOq+kywa+nNLAiMMb2SiMwEXgcyWw00m+NkXUPGmF5HRJ4H3gTuthA4cdYi\nMMaYEGctAmOMCXEWBMYYE+J63Qma0tLSNCsrK9hlGGNMr7J69epiVT3m8Ti9LgiysrJYtWpVsMsw\nxpheRUR2t7XMuoaMMSbEhUwQlFfX8damgo5XNMaYEBMyQfD4+zv48p9W8/C7OdiUWWOMadHrxgi6\n6u5zR7GvtJqH3t5G3oFKfnrVRCLDQyYHjQl5dXV15OfnU13d3jV3er+YmBgyMjKIjIzseGVPyARB\nVEQYv7r2VDJS4nj43Rz2lVXz6E2nkRTT+TfLGNN75efnk5iYSFZWFkeeAbzvUFVKSkrIz89n+PBO\nXd0UCKGuIQAR4VvnjeIXnz2F5Z+WcM1jy9hbWhXssowx3aC6uprU1NQ+GwLgPuNSU1OPu9UTUkHQ\n5JqpmTxz+3T2llZx5SP/ZuOesmCXZIzpBn05BJp0ZR9DMggAzhiZxl++OouIMOG63y/jva2FwS7J\nGNOHlZaW8uijjx738y6++GJKS0sDUFGLkA0CgDGDknjlztlkpcXzxWdX8fyKNo+3MMaYE9JWENTX\n17f7vNdff53+/fsHqiwglIKgoR6OMW10YFIML315FnNGpvH9Vzby4BtbaGy06aXGGP+677772LFj\nB5MmTWLatGmceeaZXH755YwbNw6AK6+8kilTpjB+/HieeOKJ5udlZWVRXFzMrl27GDt2LHfccQfj\nx4/n/PPPp6rKP2OcITNriHULYOnPYdwVMO5KGDIFvL60+OgInrxlKj9YtInH399B/sFKfnnNqcRE\nhge5aGNMIPz3a5v4ZO8hv25z3OAkfnjZ+DaXP/jgg2zcuJGPP/6YJUuWcMkll7Bx48bm2T1PP/00\nKSkpVFVVMW3aNK6++mpSU1OP2EZOTg4LFizgySef5Nprr+Xll1/mpptuOuHaQycI+mVA+hhY/jh8\n+FtIyoBxl7tgyJhORHgYP7lyAkNT4njwjS3sP1TNEzdPJTk+KtiVG2P6oOnTpx8xxfPhhx/mlVde\nASAvL4+cnJyjgmD48OFMmjQJgClTprBr1y6/1BI6QXDy2e6nqhS2vQmfvAofPQXLH4WEQTDucmTc\nFXzlzFlkJMfyrZfWcdVjH/LM7dMYlhof7OqNMX7U3jf37hIf3/K5smTJEt555x2WLVtGXFwcc+fO\nPeYU0Ojo6Obb4eHhfusaCp0xgiax/eHUz8H1C+A/tsPVT0HmNFjzHDxzCfxqNJfm/oJFF9dz6HAV\nn3n0Q9bkHgx21caYXi4xMZHy8vJjLisrKyM5OZm4uDi2bNnC8uXLu7W20GkRHEtMEkz8rPupqYDt\nb7uWwroXGFP3NCtjknmjfiqPPLmaa6+5gQtOGRrsio0xvVRqaiqzZ89mwoQJxMbGMnDgwOZlF154\nIY8//jhjx45l9OjRzJw5s1tr63XXLJ46daoG/HoEtZWw41345FUat75BWG0FpRpP4eBzGTn3RuTk\nsyEiuuPtGGN6jM2bNzN27Nhgl9EtjrWvIrJaVacea/3QbhG0JSoOxl4GYy8jrK6a2m3vsuXNZxi3\n9x1kwSI0OgkZfZEbaD75HIiMDXbFxhjTZRYEHYmMIWr8JUwfezH/+/f1bF22mC8krOeMnH8g61+E\nqAQYdYELhezzXIgYY0wvYkHQSWFhwvcuO5Xn0vpx66JJnDr4q/zx4mr673wdtiyGjS9DZByMPM+F\nwsgLIDoh2GUbY0yHLAiO0y2zshjcL5a7Fqzlkr9H8eznf0L2JQ/B7n+7gebNr7nfETEuEM78NqSP\nCnbZxhjTptCbPuoH88YN5MUvz6SmvpGrHv2QD3eVwoiz4NKH4N4tcNvrMPkmFwqPTIeXvwhFW4Nd\ntjHGHJMFQRedktGfV752OgOSYrj16ZW8sjbfLQgLh6zZcMmv4O71MPsbsOV1eGQGLPw8FG4JbuHG\nGNOKBcEJyEyJ4+WvnM6UYcl888V1R18POSEdzvsR3LMezrgHtr0Fj86Ev9wG+z8JWt3GmJ4vIaH7\nxhgtCE5Qv7hInvv8DK6aPISH3t7Gdxaup66h8ciV4tNg3gOuhXDGNyHnbXhsFrx0C+zfFIyyjTGm\nmQ0W+0Hz9ZCTY3n4n9vbvh5yfCrM+yGcfhcsewRW/N4NLI+9HM76LgyaEJwdMMYE3H333UdmZiZ3\n3nknAA888AARERG89957HDx4kLq6On784x9zxRVXdHttdmSxn720Ko/7/7qB7AEJPHXbNIb0b+dg\ns8oDsPwxWPE41ByCMZe6QDjplO4r2JgQccTRtm/cBwUb/PsCgybCRQ+2uXjt2rXcc889vP/++wCM\nGzeOt956i379+pGUlERxcTEzZ84kJycHESEhIYGKiooulXK8RxZb15CfXetdD3nPwSou+vVSXliZ\nS5thG5cC53zfjSGc9V3Y+S/4/Zmw4AbYt657CzfGBNTkyZMpLCxk7969rFu3juTkZAYNGsT999/P\nKaecwrx589izZw/79+/v9tqsRRAgO4sPc9/L61mx8wAzhqfws6smMiK9g8GfqlLXOlj+KFSXweiL\n4azvwODJ3VO0MX1YTzjX0A9+8APS0tIoKChg0KBBJCUl8cYbb/DnP/+ZyMhIsrKyWLJkCVlZWX2j\nRSAiT4tIoYhsbGO5iMjDIrJdRNaLyGmBqiUYhqfFs+COmTx41UQ27zvEhb/5F7/7Zw619Y1tPym2\nP8y9D+7ZAGd/3x2k9sRcmH8d7FnTbbUbYwLjuuuu44UXXmDhwoVcc801lJWVMWDAACIjI3nvvffY\nvTs4100PZNfQM8CF7Sy/CBjp/XwJeCyAtQRFWJjwuelDeefeszhv7EB++Y9tXPbbD1jb0fUNYvq5\nlsA9G+Ds/4Tc5fDk2fD8NZC/unuKN8b43fjx4ykvL2fIkCGcdNJJ3HjjjaxatYqJEyfy3HPPMWbM\nmKDUFdCuIRHJAhar6lHTYUTk98ASVV3g3d8KzFXVfe1ts7d0DR3LO5/s579e3UjBoWpunZXFty8Y\nTUJ0JyZuVR+ClU/Ast9B1UHIngdn3ecuqGOM6ZSe0DXUXXpM11AnDAHyfO7ne4/1WfPGDeQf35zD\nLTOH8eyyXZz/0Pu8u7kTA0MxSTDn266FcO4PXTfRU/PgT1dB3sqA122M6dt6xawhEfmSiKwSkVVF\nRUXBLueEJMZE8t9XTGDhV04nISaCLzy7ijvnr6GovKbjJ0cnwpnfcoEw779h38fw1Hnw3JWu+8gY\nY7ogmEGwB8j0uZ/hPXYUVX1CVaeq6tT09PRuKS7QpgxLZvFdZ3LveaN4e9N+5j30Pi99lNf2VFNf\n0QnulBV3r3ensCjYAE9f4E5dUdG7g9IY0/2CGQSLgFu82UMzgbKOxgf6mqiIMO46dyRv3HMmowcl\n8p2X13PDkyvYWXy4cxuIToDZd7vjEObeD1v+7s52uv4l6GXTgo3pDr1tunxXdGUfAzl9dAGwDBgt\nIvki8gUR+YqIfMVb5XXgU2A78CTwtUDV0tOdnJ7AC3fM5GdXTWTj3jIu+PVSHnlv+9HnLGpLVDzM\n/S58+V+QMgL+eoebclqWH9jCjelFYmJiKCkp6dNhoKqUlJQQExNzXM+zA8p6mMJD1Tzw2iZe31DA\nmEGJPHj1KUzK7N/5DTQ2uIPS3v0fCIuA838Ep90GYb1iOMiYgKmrqyM/P5/q6upglxJQMTExZGRk\nEBl55LnO2ps1ZEHQQ/1jUwE/eHUT+8urue30LL59/mjiOzPVtMmBnfDaN2DnUsg6Ey77DaSeHLiC\njTE9Wk+dPmracf74Qbz9rTncNGMYz3y4i/P/bynvbSns/AZShsMti1wA7FsHj82GD3/rWgzGGOOj\nU0EgIieLSLR3e66IfENEjqO/wnRFYkwk/3PlBBZ+ZRZxUeHc/sxH3LVgLcUVnZhqCiACU26DO1fA\niLnwj/90003tojjGGB+dbRG8DDSISDbwBG7a5/yAVWWOMGVYCou/cQbfnDeKtzYWcO6v3uelVZ2c\nagqQNBiuXwBXPwUHd8Hv58CSB6G+NqB1G2N6h84GQaOq1gOfAX6rqv8BnBS4skxr0RHh3D1vJK/f\nfQajBibwnYXruempFezq7FRTEZj4WbhzJYy7Apb8DJ44C/bYuYuMCXWdDYI6EbkeuBVY7D0W2c76\nJkCyByTy4pdm8ZPPTGB9nptq+tiSHZ2fahqfBp99Cq5/wZ236A/zXJdRbWVgCzfG9FidDYLbgVnA\nT1R1p4gMB/4UuLJMe8LChBtnDOOde8/i7NED+N83t3D57/7NW5sKqO9sIIy+CL62HCbf7AaRH58N\nuz4IbOHGmB7puKePikgykKmq6wNTUvtCZfro8XhrUwE/eu0T9pRWMTApmuumZnLd9KHtXybT16fv\nw6K7oHQ3TP28O49RTFJgizbGdKsTPo5ARJYAl+Mudr8aKAT+rarf8mOdnWJBcGz1DY28t7WI+St2\ns2RbEQKcPXoAN84cylmjBhAeJu1voPYw/PMn7upoSUPg0v+DUed3S+3GmMDzRxCsVdXJIvJFXGvg\nhyKyXlW7/SrrFgQdyztQyYsf5fHiqjyKymsY0j+Wz03L5LppmQxI6uDQ87yPYNHXoWgLnHIdXPig\nu7ayMaZX80cQbADOB54Fvq+qH1kQ9Hx1DY2888l+nl+RywfbiwkPE84bO5AbZgzljOw0wtpqJdTX\nwNJfwgcPQUx/uPgXMP4zbuaRMaZX8kcQXAP8F6476KsiMgL4hape7d9SO2ZB0DW7ig+zYGUuf1md\nz4HDtQxNieP66UO5ZmoGaQnRx35SwQZ49evuugdjLoVLfgWJg7q3cGOMX9i5hkyzmvoG3txYwPwV\nuazYeYDIcOGC8YO4YcZQZo1IRVp/62+od5fIfO+nEBkDF/wUJt1orQNjehl/tAgygN8Cs72H/gXc\nrardfp5jCwL/2V5YzvwVeby8Jp+yqjpGpMdzw/ShXH1aBsnxUUeuXLzdjR3kLoMRZ7vuooSBLhAk\nDJBWt8Na7ltoGBN0/giCt3GnlGg6duAm4EZVPc9vVXaSBYH/Vdc18Pf1+5i/MpfVuw8SFRHGJRNP\n4sYZQ5kyLLmlldDYCKuegncegNqK43yVNoKidWg0r9dq3ZThrntq7GXutjHmuPgjCD5W1UkdPdYd\nLAgCa0vBIeavyOWVNXsor6ln1MAEbpwxjCsnD6FfrHcweWmeuxpaY513JTQFbXS3tdG7r8e439i1\ndRsbYO9aKPAOXRk40QXC2MtgwFhrcRjTCf4IgneBPwILvIeuB25X1XP9VmUnWRB0j8rael5bt5fn\nV+SyPr+MmMgwLj91MDfMGMapGf2OHkvoDgd3webFsPk1yFsBKKSc7IXC5TB4sl2Ax5g2+CMIhuHG\nCGYBCnwI3KWqef4stDMsCLrfhvwy5q/czasf76WytoFxJyVx7dQMZoxIZdTAxI4PVguE8gLXKtmy\n2F18p7HeHQg35lIYeykMPR3Cj+NCPsb0cQGZNSQi96jqr0+osi6wIAie8uo6/vbxXuavyGXzvkMA\nxEeFc0pGfyYP7c/koclMHtq/7emogVJ1ELa95VoK29+B+mqITYExF7uWwoi5ENHNNRnTwwQqCHJV\ndegJVdYFFgTBp6rkHqhkbW4pa3MPsjavlE/2HqK+0f0tZabEMjkzuTkcxp2URFREN3XZ1B52YbD5\nNRcONYcgKtGdLmPsZZB9HkQndE8tPVFZPoRHQ0J6sCsx3SxQQZCnqpknVFkXWBD0TNV1DWzcU+bC\nIe8ga3NL2VfmLhIeFRHGhMFJzS2GyUOTGdwvJvDjDPU1rtto8yLXjVRZ4j4Es891oTDqwtA4fUZx\nDnzyqnsf9q2DsEiYcBXM/BoM7vb5HiZIrEVggmJfWRUf55ayNs+1HNbnl1FT706TPSAxuqU7KbM/\nEzP6ERcVwD79xgZ3DMTm19zPoT0g4TD8TBcKYy7tO0dNq8L+Te6D/5NFULTZPT5kqtvX8gJY+yc3\nBXjYbJj5VRh9MYSFB7duE1BdDgIRKccNDh+1CIhV1W4fjbMg6L3qGhrZsq+8ucWwNvcgu0rcBXHC\nw4QxgxJdOHjdSsPT4gPTalCFvWtaQqFkOyCQOb1lsDllhP9fN5Ca9umTRS4ADnwKCAw73Y2TjL0U\n+mW0rF9dBmv+BCt+D2W5kJwFM74Ck2+C6MRg7YUJIDvFhOmxSipqWJdf6gVDKR/nlVJRUw9A/7hI\nJmW6YJg2PJmpw1L8P9agCkVbvVBY1HKsQtIQGHIaDD7N+z0ZYvr597VPVGOjm0a7eZGrvyzPa+XM\ngXGXu1BLGND+Nhrq3cyr5Y9B3nKIToLTboHpX4LkYd2zH6ZbWBCYXqOhUdlRVOEGob1w2FZYjirE\nRYVz+smpzBmVzpyR6WSlxfu/gIO7YOubkP+R+4Z94NOWZakjYcgUFwxDpsDACe78S92poR52f+C+\n+W9ZDBX7ITwKTj7HffMffVHXxz3yV7vrUXzyN3cg35hLYdadkDnDDtrrAywITK92qLqO5TtKWJpT\nxPvbisg7UAXAsNQ45oxM56xR6cw6OZX46AD0VFYecEc171njgmHPavfhC27QdeD4lmAYfBqkj/Z/\nX3t9jbuK3OZXYcvrUHUAIuMgex6MuwJGnu/fK8qV7YGVT8DqZ6C61O3XrDvda4Xbpcp7KwsC02eo\nKrtKKlm6zYXCsh0lVNU1EBkuTBmWzJxRLhjGnZQUuPGFQ3tdIDQFw96P3TRVgMh4NxPHt1up/7Dj\n/0ZdWwk73nXf/Le96bYfnQSjLnDf/LPnQVSc//fviBoOw7oFrtuoZDskDobpd8CU20JjtlUfY0Fg\n+qya+gZW7zrI+14wbCkoByAtIZo5o9I4a1Q6Z2SnkRrIg9waG+HADhcKe7xwKNgADTVueVyqFwpT\nWgLiWPP4a8q9A+MWQc7bUFcJsckw5pLgHhjX2Ajb34Zlj8DO911r5NTr3WyjtJHdX09bDpdARYGr\nLzoRouIhIsa6tTwWBCZk7D9UzdJtRSzNKeaDnCIOVtYhAhOH9GPOyHTmjEpn8tD+RIYH+AC3+loo\n3OQFg9etVLTFO5ke0G+o16V0mrsK3NY3YMc/XXgkDHT98+Muh2Fn9KxTZRRsdC2EDS9BQ63rlpr5\nNRdS3fGBW1flxm2Kc1wrxfen6uDR60u4O4AwKtH7neACIjrR3W56rHlZQvvrR0T32mCxIDAhqaFR\n2bCnzAXDtiLW5B6kUSExOoLTs1sGnTNTAtzF0qSmwh3Q1dSltGcNlO52y5Iy3Af/2MvdNNaePqe/\nohBWPQ0f/QEOF8GA8a6FMPGaEx9Ab2xwM6BKtrvrYPh+2Je1Or1Z4mBIy4bUbDeYn3SSC4uaCnec\nRG1Fy+2acp/7h6G2vGVZQ23naguL8MLCa3FExbsWSEQMRMa625ExPo/FeY/73I6IPXrdyNiW9QMU\nNkELAhG5EPgNEA78QVUfbLV8GPA0kA4cAG7q6GI3FgSmq8qq6vhwezHve8Gw1zvyeUR6vBt0Hp3O\nzOGpxEZ144fw4WL3QZo+pnd+06yrho0LYdmjrgUUlwbTvgDTvtj+1FVVNxBf4n2zb/6Gv8N942/q\nVgM3NpKa7bqhUrMh9WT3oZ8ywn+nC6mv9QmLw8cIDp/7tYe9x8rdWE5dFdRXud91le49abqtDV0o\nRryg8A0N7+f0b7hjQrqy1WAEgYiEA9uA84B84CPgelX9xGedvwCLVfVZETkHd2rrm9vbrgWB8QdV\nN011yVbXjbTi0xJq6huJighjelYKp2b2Y/SgJMYOSmR4WjwRge5K6u1U3ek8lj/qBrfDo1zrYPod\nbnZVic8HfdOHfnVpy/PDIt0He9MHffOH/kiIT+udIQnQUOcTDq1Dw+fnqCBpWtfndl2VdxT4RV0q\nJVhBMAt4QFUv8O5/D0BVf+azzibgQlXNEzfFo0xV250HZ0FgAqG6roEVOw+wdFsR/95eTE5hBQ3e\nSfSiwsPIHpDAmEGJjB6UyJiTkhgzKJEBidHBuS5DT1e8HVY8Bh/Pdx9ivpKGtHyjT/W6dNKy3ZhJ\nTxoL6YPaC4JAvvNDAN8OvXxgRqt11gFX4bqPPgMkikiqqpYEsC5jjhITGc5Z3tRTcLORdhQeZkvB\nIbYWlLOloJx/7yjmr2v3ND8nOS7SBcOgpOaQGD0oMbDnTOoN0rLhkl/BOf/ppr9GJ7Z8048KwEGA\n5oQF+y/228DvROQ2YCmwBziqU01EvgR8CWDo0G4/z50JQdER4YwbnMS4wUc2UA8ermVLQTlbCw6x\ndX85m/eV89KqPCpr3Z+tCAxNifOCwXUtjR6UyLDU+OBcwCeYYpNhyq3BrsJ0QlC7hlqtnwBsUdWM\nYy1vYl1DpqdpbFTyDlZ6AVHOloJDbCkoZ1fxYbzeJWIiwxg1MJHRA1u6lsYMSgzs8Q3G+AhW19BH\nwEgRGY77pv854IZWhaUBB1S1EfgebgaRMb1KWJgwLDWeYanxXDC+5VTW1XUN5OyvaA6GrQXlvLe1\niL+sbpkYl5YQTfaAeFLjo+kXF0lyXCT9Y6PoHxdJ/7god9+73S82MvDHP5iQFLAgUNV6Efk68BZu\n+ujTqrpJRH4ErFLVRcBc4CPyWgEAAAkuSURBVGcioriuoTsDVY8x3S0mMpyJGf2YmHHkWUuLK2rY\nWlDO5n1u/GFnsRuLKK2so7SqrnmQ+lgSoyO8wGgVFrHudn9vWfM6sZEkxUaGXreUOS52QJkxPYiq\nUl5TT1llHQcrayn1+d10u6zK97FaDlbWcai6jrb+K4tAUoxrbfSLiyIzOZZTMvoxYYj7SYqxE8mF\ngmB1DRljjpOIkBQTSVJM5HEd8dzQqByqci2Kg5W1RwRJU1iUVrnba3NLWbx+X/Nzs1LjmJjRn4lD\nkiwcQpQFgTF9QHiYkBwfRXJ8FMPpeIpmSUUNG/ceYkN+KRv2lLFm90FeW7e3ebmFQ2ixIDAmBKUm\nRB9x3ARYOIQyCwJjDNC1cBieFs+EIf0sHHo5CwJjTJvaCocNe8rYuKesU+FwcnoC6QnRhNnMpR7L\ngsAYc1xSE6KZO3oAc0e3nF20o3CIjggjMyWOod7Pkbdj7bQcQWbvvjHmhLUVDpv2HmJ3yWFyD1R6\nP1Ws3HmAipr6I56flhDN0JTYo4MiNY6BiTHWmggwCwJjTECkJkQzZ1Q67nIjLVSVg5V1zeGQd6CS\n3BJ3+6NdB1m0bi++x9RFhYeR4RMSvkGRmRJHQrR9jJ0oeweNMd1KREiJjyIlPopJmf2PWl5b38je\n0qojg8L7Wb3rIOWtWhOp8VHNwTAsNY7sAQmMHJDIiPR4YiJ7+JXeeggLAmNMjxIVEUZWWjxZaUcf\nD6GqlFXV+XQ1uaDIO1DFx3ml/H3DvuZTdIR5Z4IdOTCRkQMSGDnQBcTJ6QndexW6XsCCwBjTa4iI\nd06lKE7JOLo1UVPfwK7iSnIKy9m2v4LtheXk7K/gvS2F1HsBIQKZyXGMHJBAthcOIwckkD0ggfgQ\n7WYKzb02xvRJ0RHhzRcI8lXX0MjuksNs219Bzv4KcgrL2V5Ywb9yiqltaGxeb0j/WK/l4AXEQBcQ\niX382AgLAmNMnxcZHkb2gESyByTCxJbH6xsa2X2gkpym1kOhC4plO9w1rJuc1C+meexh1EDXzZSd\nnki/uL4REBYExpiQFREexsnpCZycngC0XEuioVHJO1DpgqGwnO37K8gprGDBylyq6louotgvNpK0\nhCjSE6NJS4hu+e17OzGa1ISoHn0tCQsCY4xpJTxMmgeszxs3sPnxxkZlT2lV8xjE3tIqiitqKCp3\nx0wUldccdYxEk/5xkaQnuHBIS3RhkZYY5f1uCY+U+O4PDQsCY4zppLAwIdM7fuGcMQOPuU51XQNF\n5TUUVdRQ3Py7tjkwiitq2JBfSlF5DYdrj7pEOwAp8VGkJUQd0cpI80730fo62v5gQWCMMX4UExne\nHBYdqaytp7i81oWFT1C03HbXjyiuqKGytoHkuEgLAmOM6UvioiIYmhrB0NSOQ+NwTT1hEphTbVgQ\nGGNMLxDIYxx67jC2McaYbmFBYIwxIU5UteO1ehARKQJ2d/HpaUCxH8vpafry/tm+9V59ef96074N\nU9X0Yy3odUFwIkRklapODXYdgdKX98/2rffqy/vXV/bNuoaMMSbEWRAYY0yIC7UgeCLYBQRYX94/\n27feqy/vX5/Yt5AaIzDGGHO0UGsRGGOMaSVkgkBELhSRrSKyXUTuC3Y9/iIimSLynoh8IiKbROTu\nYNfkbyISLiJrRWRxsGvxNxHpLyILRWSLiGwWkVnBrslfROSb3t/kRhFZICIxwa7pRIjI0yJSKCIb\nfR5LEZG3RSTH+50czBq7KiSCQETCgUeAi4BxwPUiMi64VflNPXCvqo4DZgJ39qF9a3I3sDnYRQTI\nb4A3VXUMcCp9ZD9FZAjwDWCqqk4AwoHPBbeqE/YMcGGrx+4D3lXVkcC73v1eJySCAJgObFfVT1W1\nFngBuCLINfmFqu5T1TXe7XLcB8mQ4FblPyKSAVwC/CHYtfibiPQD5gBPAahqraqWBrcqv4oAYkUk\nAogD9ga5nhOiqkuBA60evgJ41rv9LHBltxblJ6ESBEOAPJ/7+fShD8smIpIFTAZWBLcSv/o18B2g\nsaMVe6HhQBHwR6/r6w8iEh/sovxBVfcAvwRygX1Amar+I7hVBcRAVd3n3S4Ajn2Rgh4uVIKgzxOR\nBOBl4B5VPRTsevxBRC4FClV1dbBrCZAI4DTgMVWdDByml3YttOb1lV+BC7vBQLyI3BTcqgJL3RTM\nXjkNM1SCYA+Q6XM/w3usTxCRSFwIPK+qfw12PX40G7hcRHbhuvPOEZE/B7ckv8oH8lW1qQW3EBcM\nfcE8YKeqFqlqHfBX4PQg1xQI+0XkJADvd2GQ6+mSUAmCj4CRIjJcRKJwg1aLglyTX4iI4PqYN6vq\nQ8Gux59U9XuqmqGqWbh/s3+qap/5VqmqBUCeiIz2HjoX+CSIJflTLjBTROK8v9Fz6SMD4a0sAm71\nbt8KvBrEWrosJC5Mo6r1IvJ14C3c7IWnVXVTkMvyl9nAzcAGEfnYe+x+VX09iDWZzrsLeN77gvIp\ncHuQ6/ELVV0hIguBNbiZbWvp5UfhisgCYC6QJiL5wA+BB4GXROQLuLMiXxu8CrvOjiw2xpgQFypd\nQ8YYY9pgQWCMMSHOgsAYY0KcBYExxoQ4CwJjjAlxFgTGtCIiDSLysc+P3472FZEs37NXGtMThMRx\nBMYcpypVnRTsIozpLtYiMKaTRGSXiPxcRDaIyEoRyfYezxKRf4rIehF5V0SGeo8PFJFXRGSd99N0\nioVwEXnSO1f/P0QkNmg7ZQwWBMYcS2yrrqHrfJaVqepE4He4M6MC/BZ4VlVPAZ4HHvYefxh4X1VP\nxZ1DqOlo9pHAI6o6HigFrg7w/hjTLjuy2JhWRKRCVROO8fgu4BxV/dQ70V+BqqaKSDFwkqrWeY/v\nU9U0ESkCMlS1xmcbWcDb3oVMEJHvApGq+uPA75kxx2YtAmOOj7Zx+3jU+NxuwMbqTJBZEBhzfK7z\n+b3Mu/0hLZdhvBH4l3f7XeCr0Hzd5X7dVaQxx8O+iRhztFifM7mCu6Zw0xTSZBFZj/tWf7332F24\nq4z9B+6KY01nEL0beMI7M2UDLhT2YUwPY2MExnSSN0YwVVWLg12LMf5kXUPGGBPirEVgjDEhzloE\nxhgT4iwIjDEmxFkQGGNMiLMgMMaYEGdBYIwxIc6CwBhjQtz/A7TG1gRGdyf8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_loss(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10645,
     "status": "ok",
     "timestamp": 1579969996433,
     "user": {
      "displayName": "Panarit Jahiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyRepiyf8dxiCFWxNWE5mKhhk_KY2eZCRB8To0=s64",
      "userId": "17560933570130372928"
     },
     "user_tz": -60
    },
    "id": "mmLOKhBpDzlf",
    "outputId": "4faa0a9d-a86a-44bf-f9be-e4ede0cad2ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8828966713376377\n"
     ]
    }
   ],
   "source": [
    "checkpoint_best = torch.load('/content/drive/My Drive/siim-acr-pneumothorax-segmentation-drive/results/checkpoint8')\n",
    "lrr = checkpoint_best['best_loss']\n",
    "print(lrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r2lxzVW3gk5Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 594,
     "status": "ok",
     "timestamp": 1579970004848,
     "user": {
      "displayName": "Panarit Jahiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyRepiyf8dxiCFWxNWE5mKhhk_KY2eZCRB8To0=s64",
      "userId": "17560933570130372928"
     },
     "user_tz": -60
    },
    "id": "xKhAElBpgk5p",
    "outputId": "c92d922a-a22c-4dae-abb3-c2a3390475a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function print>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "    \n",
    "data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            # transforms.Resize(224),\n",
    "            # because scale doesn't always give 224 x 224, this ensures 224 x\n",
    "            # 224\n",
    "            # transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            # transforms.Resize(224),\n",
    "            # transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ]),\n",
    "    }\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3096,
     "status": "ok",
     "timestamp": 1579863333972,
     "user": {
      "displayName": "Panarit Jahiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyRepiyf8dxiCFWxNWE5mKhhk_KY2eZCRB8To0=s64",
      "userId": "17560933570130372928"
     },
     "user_tz": -60
    },
    "id": "XvrpgwcTvYgy",
    "outputId": "4812a57c-c857-41d5-8212-902d2375998e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/siim-acr-pneumothorax-segmentation-drive\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/content/drive/My Drive/siim-acr-pneumothorax-segmentation-drive')\n",
    "!pwd\n",
    "import sys\n",
    "# sys.path.append('/content/drive/My Drive/siim-acr-pneumothorax-segmentation-drive')\n",
    "# sys.path.insert(1, '/path/to/application/app/folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "At-kS7cMgk5u"
   },
   "outputs": [],
   "source": [
    "os.chdir('/content/drive/My Drive/siim-acr-pneumothorax-segmentation-drive')\n",
    "import torch\n",
    "import pandas as pd\n",
    "import cxr_dataset as CXR\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import sklearn\n",
    "import sklearn.metrics as sklm\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def make_pred_multilabel(data_transforms, model, PATH_TO_IMAGES):\n",
    "    \"\"\"\n",
    "    Gives predictions for test fold and calculates AUCs using previously trained model\n",
    "\n",
    "    Args:\n",
    "        data_transforms: torchvision transforms to preprocess raw images; same as validation transforms\n",
    "        model: densenet-121 from torchvision previously fine tuned to training data\n",
    "        PATH_TO_IMAGES: path at which NIH images can be found\n",
    "    Returns:\n",
    "        pred_df: dataframe containing individual predictions and ground truth for each test image\n",
    "        auc_df: dataframe containing aggregate AUCs by train/test tuples\n",
    "    \"\"\"\n",
    "\n",
    "    # calc preds in batches of 16, can reduce if your GPU has less RAM\n",
    "    BATCH_SIZE = 16\n",
    "\n",
    "    # set model to eval mode; required for proper predictions given use of batchnorm\n",
    "    model.train(False)\n",
    "\n",
    "    # create dataloader\n",
    "    dataset = CXR.CXRDataset(\n",
    "        path_to_images=PATH_TO_IMAGES,\n",
    "        fold=\"test\",\n",
    "        # sample = 200,\n",
    "        transform=data_transforms['val'])\n",
    "    os.chdir('/content')\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "    size = len(dataset)\n",
    "    print(size)\n",
    "    # print('datasetsize', dataset_sizes)\n",
    "    print(dataset.df)\n",
    "\n",
    "    # create empty dfs\n",
    "    pred_df = pd.DataFrame(columns=[\"Image Index\"])\n",
    "    true_df = pd.DataFrame(columns=[\"Image Index\"])\n",
    "\n",
    "    #these lists will save values for the second way of calculating the scores\n",
    "    outputList = []\n",
    "    labelList = []\n",
    "\n",
    "    # iterate over dataloader\n",
    "    for idx, data in enumerate(dataloader):\n",
    "\n",
    "        inputs, labels, _ = data\n",
    "#         inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        inputs = Variable(inputs.to(device))\n",
    "        labels = Variable(labels.float().to(device))\n",
    "\n",
    "        true_labels = labels.cpu().data.numpy()\n",
    "        batch_size = true_labels.shape\n",
    "        # print('batch_size: ' + str(batch_size))\n",
    "        outputs = model(inputs)\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        probs = outputs.cpu().data.numpy()\n",
    "        # print('----------------')\n",
    "        # print(labels[0])\n",
    "        # print(outputs[0])\n",
    "        # print('----------------')\n",
    "        \n",
    "        for i in range(outputs.shape[0]):\n",
    "            outputList.append(outputs[i].tolist())\n",
    "            labelList.append(labels[i].tolist())\n",
    "\n",
    "        # get predictions and true values for each item in batch\n",
    "        # here the dataframe 'true' and 'preds' are created by adding rows into them respectively\n",
    "        for j in range(0, batch_size[0]):\n",
    "            thisrow = {}\n",
    "            truerow = {}\n",
    "            thisrow[\"Image Index\"] = dataset.df.index[BATCH_SIZE * idx + j]\n",
    "            truerow[\"Image Index\"] = dataset.df.index[BATCH_SIZE * idx + j]\n",
    "\n",
    "            # iterate over each entry in prediction vector; each corresponds to\n",
    "            # individual label\n",
    "            for k in range(len(dataset.PRED_LABEL)):\n",
    "                thisrow[\"prob_\" + dataset.PRED_LABEL[k]] = probs[j, k]\n",
    "                truerow[dataset.PRED_LABEL[k]] = true_labels[j, k]\n",
    "                # print('---------------')\n",
    "                # print(dataset.df.index[BATCH_SIZE * idx + j])\n",
    "                # print(probs[j])\n",
    "                # print(true_labels[j])\n",
    "                # print('---------------')\n",
    "            pred_df = pred_df.append(thisrow, ignore_index=True)\n",
    "            true_df = true_df.append(truerow, ignore_index=True)\n",
    "            # print(pred_df)\n",
    "            # print(head(true_df))\n",
    "        if(idx % 100 == 0):\n",
    "            print(str(idx * BATCH_SIZE))\n",
    "            \n",
    "    print('Scores - Method2 -----------------------')        \n",
    "    epoch_auc_ave = sklm.roc_auc_score(np.array(labelList), np.array(outputList))\n",
    "    epoch_auc = sklm.roc_auc_score(np.array(labelList), np.array(outputList), average=None)\n",
    "    for i, c in enumerate(dataset.PRED_LABEL):\n",
    "        fpr, tpr, _ = sklm.roc_curve(np.array(labelList)[:, i], np.array(outputList)[:, i])\n",
    "        plt.plot(fpr, tpr, label=c)\n",
    "        print('{}: {:.4f} '.format(c, epoch_auc[i]))\n",
    "    print('Scores - Method2 -----------------------')\n",
    "    \n",
    "    \n",
    "\n",
    "    #here the auc scores are calculated and the 'auc' table is created    \n",
    "    auc_df = pd.DataFrame(columns=[\"label\", \"auc\"])\n",
    "\n",
    "    # calc AUCs\n",
    "    for column in true_df:\n",
    "\n",
    "        if column not in [\n",
    "            'Atelectasis',\n",
    "            'Cardiomegaly',\n",
    "            'Effusion',\n",
    "            'Infiltration',\n",
    "            'Mass',\n",
    "            'Nodule',\n",
    "            'Pneumonia',\n",
    "            'Pneumothorax',\n",
    "            'Consolidation',\n",
    "            'Edema',\n",
    "            'Emphysema',\n",
    "            'Fibrosis',\n",
    "            'Pleural_Thickening',\n",
    "                'Hernia']:\n",
    "                    continue\n",
    "        actual = true_df[column]\n",
    "        pred = pred_df[\"prob_\" + column]\n",
    "        thisrow = {}\n",
    "        thisrow['label'] = column\n",
    "        thisrow['auc'] = np.nan\n",
    "        try:\n",
    "            thisrow['auc'] = sklm.roc_auc_score(\n",
    "                actual.values.astype(int), pred.values)\n",
    "        except BaseException as e:\n",
    "            print('-------------------')\n",
    "            print(e)\n",
    "            print(actual.values)\n",
    "            print(pred.values)\n",
    "            print('-------------------')\n",
    "#             print(\"can't calculate auc for \" + str(column))\n",
    "            \n",
    "        auc_df = auc_df.append(thisrow, ignore_index=True)\n",
    "\n",
    "    pred_df.to_csv(\"/content/drive/My Drive/siim-acr-pneumothorax-segmentation-drive/results/preds8.csv\", index=False)\n",
    "    auc_df.to_csv(\"/content/drive/My Drive/siim-acr-pneumothorax-segmentation-drive/results/aucs8.csv\", index=False)\n",
    "    true_df.to_csv('/content/drive/My Drive/siim-acr-pneumothorax-segmentation-drive/results/true8.csv', index = False)\n",
    "    return pred_df, auc_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3783,
     "status": "ok",
     "timestamp": 1579434543328,
     "user": {
      "displayName": "Panarit Jahiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyRepiyf8dxiCFWxNWE5mKhhk_KY2eZCRB8To0=s64",
      "userId": "17560933570130372928"
     },
     "user_tz": -60
    },
    "id": "Yy5w4o3VvSVB",
    "outputId": "911a0b6c-992c-436f-a9c6-f81bfd29482c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/siim-acr-pneumothorax-segmentation-drive\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 354543,
     "status": "ok",
     "timestamp": 1579970383878,
     "user": {
      "displayName": "Panarit Jahiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyRepiyf8dxiCFWxNWE5mKhhk_KY2eZCRB8To0=s64",
      "userId": "17560933570130372928"
     },
     "user_tz": -60
    },
    "id": "l2rn1mkjgk5x",
    "outputId": "1194f3bc-3180-412e-fff9-09a61e504fda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8828966713376377\n",
      "25596\n",
      "                       Finding Labels  Atelectasis  ...  Hernia  fold\n",
      "Image Index                                         ...              \n",
      "00000003_000.png               Hernia            0  ...       1  test\n",
      "00000003_001.png               Hernia            0  ...       1  test\n",
      "00000003_002.png               Hernia            0  ...       1  test\n",
      "00000003_003.png  Hernia|Infiltration            0  ...       1  test\n",
      "00000003_004.png               Hernia            0  ...       1  test\n",
      "...                               ...          ...  ...     ...   ...\n",
      "00030800_000.png           No Finding            0  ...       0  test\n",
      "00030802_000.png           No Finding            0  ...       0  test\n",
      "00030803_000.png           No Finding            0  ...       0  test\n",
      "00030804_000.png           No Finding            0  ...       0  test\n",
      "00030805_000.png           No Finding            0  ...       0  test\n",
      "\n",
      "[25596 rows x 16 columns]\n",
      "0\n",
      "1600\n",
      "3200\n",
      "4800\n",
      "6400\n",
      "8000\n",
      "9600\n",
      "11200\n",
      "12800\n",
      "14400\n",
      "16000\n",
      "17600\n",
      "19200\n",
      "20800\n",
      "22400\n",
      "24000\n",
      "Scores - Method2 -----------------------\n",
      "Atelectasis: 0.7328 \n",
      "Cardiomegaly: 0.8885 \n",
      "Effusion: 0.8044 \n",
      "Infiltration: 0.6902 \n",
      "Mass: 0.7769 \n",
      "Nodule: 0.7100 \n",
      "Pneumonia: 0.6726 \n",
      "Pneumothorax: 0.8217 \n",
      "Consolidation: 0.7232 \n",
      "Edema: 0.8180 \n",
      "Emphysema: 0.8408 \n",
      "Fibrosis: 0.7909 \n",
      "Pleural_Thickening: 0.7437 \n",
      "Hernia: 0.8770 \n",
      "Scores - Method2 -----------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRqNpIPw/8YI9Be5EzakAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint = torch.load('/content/drive/My Drive/siim-acr-pneumothorax-segmentation-drive/results/checkpoint8', map_location=lambda storage, loc: storage)\n",
    "model = checkpoint['model']\n",
    "epoch = checkpoint['best_loss']\n",
    "print(epoch)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "preds, aucs = make_pred_multilabel(data_transforms, model, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 563,
     "status": "ok",
     "timestamp": 1579970602367,
     "user": {
      "displayName": "Panarit Jahiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyRepiyf8dxiCFWxNWE5mKhhk_KY2eZCRB8To0=s64",
      "userId": "17560933570130372928"
     },
     "user_tz": -60
    },
    "id": "e4L-t5RhYDkT",
    "outputId": "5d8971d8-0dff-4dd2-d1a1-820436d48a3e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Atelectasis</td>\n",
       "      <td>0.732793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cardiomegaly</td>\n",
       "      <td>0.888495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Consolidation</td>\n",
       "      <td>0.723238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Edema</td>\n",
       "      <td>0.817958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Effusion</td>\n",
       "      <td>0.804407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Emphysema</td>\n",
       "      <td>0.840801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fibrosis</td>\n",
       "      <td>0.790863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hernia</td>\n",
       "      <td>0.876953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Infiltration</td>\n",
       "      <td>0.690151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mass</td>\n",
       "      <td>0.776861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Nodule</td>\n",
       "      <td>0.710021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pleural_Thickening</td>\n",
       "      <td>0.743658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pneumonia</td>\n",
       "      <td>0.672586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Pneumothorax</td>\n",
       "      <td>0.821651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 label       auc\n",
       "0          Atelectasis  0.732793\n",
       "1         Cardiomegaly  0.888495\n",
       "2        Consolidation  0.723238\n",
       "3                Edema  0.817958\n",
       "4             Effusion  0.804407\n",
       "5            Emphysema  0.840801\n",
       "6             Fibrosis  0.790863\n",
       "7               Hernia  0.876953\n",
       "8         Infiltration  0.690151\n",
       "9                 Mass  0.776861\n",
       "10              Nodule  0.710021\n",
       "11  Pleural_Thickening  0.743658\n",
       "12           Pneumonia  0.672586\n",
       "13        Pneumothorax  0.821651"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Me6e6XGcgk53"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def make_pred_multilabel2(data_transforms, model, PATH_TO_IMAGES,save_as_csv=True):\n",
    "    \"\"\"\n",
    "    Gives predictions for test fold and calculates AUCs using previously trained model\n",
    "\n",
    "    Args:\n",
    "        data_transforms: torchvision transforms to preprocess raw images; same as validation transforms\n",
    "        model: densenet-121 from torchvision previously fine tuned to training data\n",
    "        PATH_TO_IMAGES: path at which NIH images can be found\n",
    "    Returns:\n",
    "        pred_df: dataframe containing individual predictions and ground truth for each test image\n",
    "        auc_df: dataframe containing aggregate AUCs by train/test tuples\n",
    "    \"\"\"\n",
    "    os.chdir('/content/drive/My Drive/siim-acr-pneumothorax-segmentation-drive')\n",
    "\n",
    "\n",
    "    # calc preds in batches of 16, can reduce if your GPU has less RAM\n",
    "    BATCH_SIZE = 32\n",
    "    # batch_size = dataloader.batch_size\n",
    "\n",
    "    \n",
    "    # set model to eval mode; required for proper predictions given use of batchnorm\n",
    "    model.train(False)\n",
    "\n",
    "    # # create dataloader\n",
    "    dataset = CXR.CXRDataset(\n",
    "        path_to_images=PATH_TO_IMAGES,\n",
    "        fold='test',\n",
    "        transform=data_transforms['val'])\n",
    "    os.chdir('/content')\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "    size = len(dataset)\n",
    "    print(size)\n",
    "  \n",
    "    # create empty dfs\n",
    "    pred_df = pd.DataFrame(columns=[\"Image Index\"])\n",
    "    true_df = pd.DataFrame(columns=[\"Image Index\"])\n",
    "\n",
    "    # iterate over dataloader\n",
    "    for i, data in enumerate(dataloader):\n",
    "\n",
    "        inputs, labels, _ = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        true_labels = labels.cpu().data.numpy()\n",
    "        # batch_size = true_labels.shape\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        probs = outputs.cpu().data.numpy()\n",
    "\n",
    "        # get predictions and true values for each item in batch\n",
    "        for j in range(0, true_labels.shape[0]):\n",
    "            thisrow = {}\n",
    "            truerow = {}\n",
    "            thisrow[\"Image Index\"] = dataloader.dataset.df.index[batch_size * i + j]\n",
    "            truerow[\"Image Index\"] = dataloader.dataset.df.index[batch_size * i + j]\n",
    "\n",
    "            # iterate over each entry in prediction vector; each corresponds to\n",
    "            # individual label\n",
    "            for k in range(len(dataloader.dataset.PRED_LABEL)):\n",
    "                thisrow[\"prob_\" + dataloader.dataset.PRED_LABEL[k]] = probs[j, k]\n",
    "                truerow[dataloader.dataset.PRED_LABEL[k]] = true_labels[j, k]\n",
    "\n",
    "            pred_df = pred_df.append(thisrow, ignore_index=True)\n",
    "            true_df = true_df.append(truerow, ignore_index=True)\n",
    "\n",
    "        # if(i % 10 == 0):\n",
    "        #     print(str(i * BATCH_SIZE))\n",
    "\n",
    "    auc_df = pd.DataFrame(columns=[\"label\", \"auc\"])\n",
    "\n",
    "    # calc AUCs\n",
    "    for column in true_df:\n",
    "\n",
    "        if column not in [\n",
    "            'Atelectasis',\n",
    "            'Cardiomegaly',\n",
    "            'Effusion',\n",
    "            'Infiltration',\n",
    "            'Mass',\n",
    "            'Nodule',\n",
    "            'Pneumonia',\n",
    "            'Pneumothorax',\n",
    "            'Consolidation',\n",
    "            'Edema',\n",
    "            'Emphysema',\n",
    "            'Fibrosis',\n",
    "            'Pleural_Thickening',\n",
    "                'Hernia']:\n",
    "                    continue\n",
    "        actual = true_df[column]\n",
    "        pred = pred_df[\"prob_\" + column]\n",
    "        thisrow = {}\n",
    "        thisrow['label'] = column\n",
    "        thisrow['auc'] = np.nan\n",
    "        thisrow['AP'] = np.nan\n",
    "        try:\n",
    "            thisrow['auc'] = sklm.roc_auc_score(actual.as_matrix().astype(int), pred.as_matrix())\n",
    "            thisrow['AP'] = sklm.average_precision_score(actual.as_matrix().astype(int), pred.as_matrix())\n",
    "        except BaseException:\n",
    "            print(\"can't calculate auc for \" + str(column))\n",
    "        auc_df = auc_df.append(thisrow, ignore_index=True)\n",
    "\n",
    "    if save_as_csv:\n",
    "        pred_df.to_csv(\"/content/drive/My Drive/siim-acr-pneumothorax-segmentation-drive/results/preds2.csv\", index=False)\n",
    "        auc_df.to_csv(\"/content/drive/My Drive/siim-acr-pneumothorax-segmentation-drive/results/aucs2.csv\", index=False)\n",
    "\n",
    "    return pred_df, auc_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 300928,
     "status": "ok",
     "timestamp": 1579548967206,
     "user": {
      "displayName": "Panarit Jahiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyRepiyf8dxiCFWxNWE5mKhhk_KY2eZCRB8To0=s64",
      "userId": "17560933570130372928"
     },
     "user_tz": -60
    },
    "id": "V0ye6Q_pgk59",
    "outputId": "2d1e1fbf-ff82-43d9-f0a9-fa36dc35a585"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8419709692436216\n",
      "25596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:101: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:102: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:101: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:102: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:101: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:102: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:101: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:102: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:101: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:102: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:101: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:102: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:101: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:102: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:101: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:102: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:101: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:102: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:101: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:102: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:101: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:102: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:101: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:102: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:101: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:102: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:101: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:102: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('/content/drive/My Drive/siim-acr-pneumothorax-segmentation-drive/results/checkpoint', map_location=lambda storage, loc: storage)\n",
    "model = checkpoint['model']\n",
    "epoch = checkpoint['best_loss']\n",
    "print(epoch)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "preds, aucs = make_pred_multilabel2(data_transforms, model, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1579549178286,
     "user": {
      "displayName": "Panarit Jahiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAyRepiyf8dxiCFWxNWE5mKhhk_KY2eZCRB8To0=s64",
      "userId": "17560933570130372928"
     },
     "user_tz": -60
    },
    "id": "jhQumHCrd6rw",
    "outputId": "49351bcb-d79e-4a7a-b523-d129a63dd74a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>auc</th>\n",
       "      <th>AP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Atelectasis</td>\n",
       "      <td>0.763973</td>\n",
       "      <td>0.336430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cardiomegaly</td>\n",
       "      <td>0.889995</td>\n",
       "      <td>0.329240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Consolidation</td>\n",
       "      <td>0.746076</td>\n",
       "      <td>0.161652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Edema</td>\n",
       "      <td>0.842836</td>\n",
       "      <td>0.167865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Effusion</td>\n",
       "      <td>0.819168</td>\n",
       "      <td>0.489979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Emphysema</td>\n",
       "      <td>0.912577</td>\n",
       "      <td>0.387910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fibrosis</td>\n",
       "      <td>0.815104</td>\n",
       "      <td>0.094127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hernia</td>\n",
       "      <td>0.903022</td>\n",
       "      <td>0.346265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Infiltration</td>\n",
       "      <td>0.679279</td>\n",
       "      <td>0.381657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mass</td>\n",
       "      <td>0.815691</td>\n",
       "      <td>0.290571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Nodule</td>\n",
       "      <td>0.759527</td>\n",
       "      <td>0.229689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pleural_Thickening</td>\n",
       "      <td>0.766826</td>\n",
       "      <td>0.136005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pneumonia</td>\n",
       "      <td>0.717415</td>\n",
       "      <td>0.051556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Pneumothorax</td>\n",
       "      <td>0.852656</td>\n",
       "      <td>0.387476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 label       auc        AP\n",
       "0          Atelectasis  0.763973  0.336430\n",
       "1         Cardiomegaly  0.889995  0.329240\n",
       "2        Consolidation  0.746076  0.161652\n",
       "3                Edema  0.842836  0.167865\n",
       "4             Effusion  0.819168  0.489979\n",
       "5            Emphysema  0.912577  0.387910\n",
       "6             Fibrosis  0.815104  0.094127\n",
       "7               Hernia  0.903022  0.346265\n",
       "8         Infiltration  0.679279  0.381657\n",
       "9                 Mass  0.815691  0.290571\n",
       "10              Nodule  0.759527  0.229689\n",
       "11  Pleural_Thickening  0.766826  0.136005\n",
       "12           Pneumonia  0.717415  0.051556\n",
       "13        Pneumothorax  0.852656  0.387476"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "dense_net_finetune.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
