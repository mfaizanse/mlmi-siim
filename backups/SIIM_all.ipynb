{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SIIM_all.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7gsu-kmmD3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg8ThUO3mJhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd \"/content/\"\n",
        "%mkdir data\n",
        "%cd data\n",
        "!unzip \"/content/gdrive/My Drive/mlmi/input.zip\"\n",
        "!unzip \"/content/gdrive/My Drive/mlmi/masks.zip\"\n",
        "%ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u92getfvZrFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install numpy\n",
        "!pip install torch\n",
        "!pip install matplotlib\n",
        "!pip install scipy\n",
        "!pip install torchvision\n",
        "!pip install tqdm\n",
        "!pip install visdom\n",
        "!pip install nibabel\n",
        "!pip install scikit-image\n",
        "!pip install h5py\n",
        "!pip install pandas\n",
        "!pip install dominate\n",
        "!pip install pydicom\n",
        "!pip install opencv-python\n",
        "!pip install scikit-learn\n",
        "!pip install https://github.com/ozan-oktay/torchsample/tarball/master#egg=torchsample-0.1.3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DNU07IQTLwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pydicom\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIc_BA88VzQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_weights(net, init_type='normal'):\n",
        "    #print('initialization method [%s]' % init_type)\n",
        "    if init_type == 'normal':\n",
        "        net.apply(weights_init_normal)\n",
        "    elif init_type == 'xavier':\n",
        "        net.apply(weights_init_xavier)\n",
        "    elif init_type == 'kaiming':\n",
        "        net.apply(weights_init_kaiming)\n",
        "    elif init_type == 'orthogonal':\n",
        "        net.apply(weights_init_orthogonal)\n",
        "    else:\n",
        "        raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
        "\n",
        "def weights_init_kaiming(m):\n",
        "    classname = m.__class__.__name__\n",
        "    #print(classname)\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n",
        "    elif classname.find('Linear') != -1:\n",
        "        nn.init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant(m.bias.data, 0.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdZCyDaITnn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class unetConv2(nn.Module):\n",
        "    def __init__(self, in_size, out_size, is_batchnorm, n=2, ks=3, stride=1, padding=1):\n",
        "        super(unetConv2, self).__init__()\n",
        "        self.n = n\n",
        "        self.ks = ks\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        s = stride\n",
        "        p = padding\n",
        "        if is_batchnorm:\n",
        "            for i in range(1, n+1):\n",
        "                conv = nn.Sequential(nn.Conv2d(in_size, out_size, ks, s, p),\n",
        "                                     nn.BatchNorm2d(out_size),\n",
        "                                     nn.ReLU(inplace=True),)\n",
        "                setattr(self, 'conv%d'%i, conv)\n",
        "                in_size = out_size\n",
        "\n",
        "        else:\n",
        "            for i in range(1, n+1):\n",
        "                conv = nn.Sequential(nn.Conv2d(in_size, out_size, ks, s, p),\n",
        "                                     nn.ReLU(inplace=True),)\n",
        "                setattr(self, 'conv%d'%i, conv)\n",
        "                in_size = out_size\n",
        "\n",
        "        # initialise the blocks\n",
        "        for m in self.children():\n",
        "            init_weights(m, init_type='kaiming')\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = inputs\n",
        "        for i in range(1, self.n+1):\n",
        "            conv = getattr(self, 'conv%d'%i)\n",
        "            x = conv(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class unetUp2(nn.Module):\n",
        "    def __init__(self, in_size, out_size, is_deconv, is_batchnorm=True):\n",
        "        super(unetUp2, self).__init__()\n",
        "        self.conv = unetConv2(in_size + out_size, out_size, is_batchnorm)\n",
        "        if is_deconv:\n",
        "            self.up = nn.ConvTranspose2d(in_size, out_size, kernel_size=4, stride=2, padding=1)\n",
        "        else:\n",
        "            self.up = nn.UpsamplingBilinear2d(scale_factor=2)\n",
        "\n",
        "        # initialise the blocks\n",
        "        for m in self.children():\n",
        "            if m.__class__.__name__.find('unetConv2') != -1: continue\n",
        "            init_weights(m, init_type='kaiming')\n",
        "\n",
        "    def forward(self, inputs1, inputs2):\n",
        "        outputs2 = self.up(inputs2)\n",
        "        # offset = outputs2.size()[1] - inputs1.size()[1]\n",
        "        # padding = [0, 0, 0, 0, offset // 2, offset // 2]\n",
        "        # outputs1 = F.pad(inputs1, padding)\n",
        "        outputs1 = inputs1\n",
        "        cat = torch.cat([outputs1, outputs2], 1)\n",
        "        return self.conv(cat)\n",
        "\n",
        "class UnetGridGatingSignal2(nn.Module):\n",
        "    def __init__(self, in_size, out_size, ks=1, is_batchnorm=True):\n",
        "        super(UnetGridGatingSignal2, self).__init__()\n",
        "\n",
        "        if is_batchnorm:\n",
        "            self.conv1 = nn.Sequential(nn.Conv2d(in_size, out_size, ks),\n",
        "                                       nn.BatchNorm2d(out_size),\n",
        "                                       nn.ReLU(inplace=True),\n",
        "                                       )\n",
        "        else:\n",
        "            self.conv1 = nn.Sequential(nn.Conv2d(in_size, out_size, ks),\n",
        "                                       nn.ReLU(inplace=True),\n",
        "                                       )\n",
        "\n",
        "        # initialise the blocks\n",
        "        for m in self.children():\n",
        "            init_weights(m, init_type='kaiming')\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        outputs = self.conv1(inputs)\n",
        "        return outputs\n",
        "\n",
        "class UnetDsv2(nn.Module):\n",
        "    def __init__(self, in_size, out_size, scale_factor):\n",
        "        super(UnetDsv2, self).__init__()\n",
        "        self.dsv = nn.Sequential(nn.Conv2d(in_size, out_size, kernel_size=1, stride=1, padding=0),\n",
        "                                 nn.Upsample(scale_factor=scale_factor, mode='bilinear'), )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.dsv(input)\n",
        "\n",
        "class _GridAttentionBlockND(nn.Module):\n",
        "    def __init__(self, in_channels, gating_channels, inter_channels=None, dimension=3, mode='concatenation',\n",
        "                 sub_sample_factor=(2,2,2)):\n",
        "        super(_GridAttentionBlockND, self).__init__()\n",
        "\n",
        "        assert dimension in [2, 3]\n",
        "        assert mode in ['concatenation', 'concatenation_debug', 'concatenation_residual']\n",
        "\n",
        "        # Downsampling rate for the input featuremap\n",
        "        if isinstance(sub_sample_factor, tuple): self.sub_sample_factor = sub_sample_factor\n",
        "        elif isinstance(sub_sample_factor, list): self.sub_sample_factor = tuple(sub_sample_factor)\n",
        "        else: self.sub_sample_factor = tuple([sub_sample_factor]) * dimension\n",
        "\n",
        "        # Default parameter set\n",
        "        self.mode = mode\n",
        "        self.dimension = dimension\n",
        "        self.sub_sample_kernel_size = self.sub_sample_factor\n",
        "\n",
        "        # Number of channels (pixel dimensions)\n",
        "        self.in_channels = in_channels\n",
        "        self.gating_channels = gating_channels\n",
        "        self.inter_channels = inter_channels\n",
        "\n",
        "        if self.inter_channels is None:\n",
        "            self.inter_channels = in_channels // 2\n",
        "            if self.inter_channels == 0:\n",
        "                self.inter_channels = 1\n",
        "\n",
        "        if dimension == 3:\n",
        "            conv_nd = nn.Conv3d\n",
        "            bn = nn.BatchNorm3d\n",
        "            self.upsample_mode = 'trilinear'\n",
        "        elif dimension == 2:\n",
        "            conv_nd = nn.Conv2d\n",
        "            bn = nn.BatchNorm2d\n",
        "            self.upsample_mode = 'bilinear'\n",
        "        else:\n",
        "            raise NotImplemented\n",
        "\n",
        "        # Output transform\n",
        "        self.W = nn.Sequential(\n",
        "            conv_nd(in_channels=self.in_channels, out_channels=self.in_channels, kernel_size=1, stride=1, padding=0),\n",
        "            bn(self.in_channels),\n",
        "        )\n",
        "\n",
        "        # Theta^T * x_ij + Phi^T * gating_signal + bias\n",
        "        self.theta = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
        "                             kernel_size=self.sub_sample_kernel_size, stride=self.sub_sample_factor, padding=0, bias=False)\n",
        "        self.phi = conv_nd(in_channels=self.gating_channels, out_channels=self.inter_channels,\n",
        "                           kernel_size=1, stride=1, padding=0, bias=True)\n",
        "        self.psi = conv_nd(in_channels=self.inter_channels, out_channels=1, kernel_size=1, stride=1, padding=0, bias=True)\n",
        "\n",
        "        # Initialise weights\n",
        "        for m in self.children():\n",
        "            init_weights(m, init_type='kaiming')\n",
        "\n",
        "        # Define the operation\n",
        "        if mode == 'concatenation':\n",
        "            self.operation_function = self._concatenation\n",
        "        elif mode == 'concatenation_debug':\n",
        "            self.operation_function = self._concatenation_debug\n",
        "        elif mode == 'concatenation_residual':\n",
        "            self.operation_function = self._concatenation_residual\n",
        "        else:\n",
        "            raise NotImplementedError('Unknown operation function.')\n",
        "\n",
        "\n",
        "    def forward(self, x, g):\n",
        "        '''\n",
        "        :param x: (b, c, t, h, w)\n",
        "        :param g: (b, g_d)\n",
        "        :return:\n",
        "        '''\n",
        "\n",
        "        output = self.operation_function(x, g)\n",
        "        return output\n",
        "\n",
        "    def _concatenation(self, x, g):\n",
        "        input_size = x.size()\n",
        "        batch_size = input_size[0]\n",
        "        assert batch_size == g.size(0)\n",
        "\n",
        "        # theta => (b, c, t, h, w) -> (b, i_c, t, h, w) -> (b, i_c, thw)\n",
        "        # phi   => (b, g_d) -> (b, i_c)\n",
        "        theta_x = self.theta(x)\n",
        "        theta_x_size = theta_x.size()\n",
        "\n",
        "        # g (b, c, t', h', w') -> phi_g (b, i_c, t', h', w')\n",
        "        #  Relu(theta_x + phi_g + bias) -> f = (b, i_c, thw) -> (b, i_c, t/s1, h/s2, w/s3)\n",
        "        phi_g = F.interpolate(self.phi(g), size=theta_x_size[2:], mode=self.upsample_mode)\n",
        "        f = F.relu(theta_x + phi_g, inplace=True)\n",
        "\n",
        "        #  psi^T * f -> (b, psi_i_c, t/s1, h/s2, w/s3)\n",
        "        sigm_psi_f = torch.sigmoid(self.psi(f))\n",
        "\n",
        "        # upsample the attentions and multiply\n",
        "        sigm_psi_f = F.interpolate(sigm_psi_f, size=input_size[2:], mode=self.upsample_mode)\n",
        "        y = sigm_psi_f.expand_as(x) * x\n",
        "        W_y = self.W(y)\n",
        "\n",
        "        return W_y, sigm_psi_f\n",
        "\n",
        "class GridAttentionBlock2D(_GridAttentionBlockND):\n",
        "    def __init__(self, in_channels, gating_channels, inter_channels=None, mode='concatenation',\n",
        "                 sub_sample_factor=(2,2,2)):\n",
        "        super(GridAttentionBlock2D, self).__init__(in_channels,\n",
        "                                                   inter_channels=inter_channels,\n",
        "                                                   gating_channels=gating_channels,\n",
        "                                                   dimension=2, mode=mode,\n",
        "                                                   sub_sample_factor=sub_sample_factor\n",
        "                                                   )\n",
        "\n",
        "\n",
        "class MultiAttentionBlock(nn.Module):\n",
        "    def __init__(self, in_size, gate_size, inter_size, nonlocal_mode, sub_sample_factor):\n",
        "        super(MultiAttentionBlock, self).__init__()\n",
        "        self.gate_block_1 = GridAttentionBlock2D(in_channels=in_size, gating_channels=gate_size,\n",
        "                                                 inter_channels=inter_size, mode=nonlocal_mode,\n",
        "                                                 sub_sample_factor= sub_sample_factor)\n",
        "        self.combine_gates = nn.Sequential(nn.Conv2d(in_size, in_size, kernel_size=1, stride=1, padding=0),\n",
        "                                           nn.BatchNorm2d(in_size),\n",
        "                                           nn.ReLU(inplace=True)\n",
        "                                           )\n",
        "\n",
        "        # initialise the blocks\n",
        "        for m in self.children():\n",
        "            if m.__class__.__name__.find('GridAttentionBlock2D') != -1: continue\n",
        "            init_weights(m, init_type='kaiming')\n",
        "\n",
        "    def forward(self, input, gating_signal):\n",
        "        gate_1, attention_1 = self.gate_block_1(input, gating_signal)\n",
        "        return self.combine_gates(gate_1), attention_1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD7Tm0ZQTdac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class unet_simm(nn.Module):\n",
        "\n",
        "    def __init__(self, feature_scale, n_classes, is_deconv, in_channels,\n",
        "                 nonlocal_mode, attention_dsample, is_batchnorm):\n",
        "        super(unet_simm, self).__init__()\n",
        "        self.is_deconv = is_deconv\n",
        "        self.in_channels = in_channels\n",
        "        self.is_batchnorm = is_batchnorm\n",
        "        self.feature_scale = feature_scale\n",
        "        # self.use_cuda = Config.use_cuda\n",
        "\n",
        "        filters = [64, 128, 256, 512, 1024]\n",
        "        filters = [int(x / self.feature_scale) for x in filters]\n",
        "        # filter [16, 32, 64, 128, 256]\n",
        "\n",
        "        # downsampling\n",
        "        self.conv1 = unetConv2(self.in_channels, filters[0], self.is_batchnorm, ks=3)\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.conv2 = unetConv2(filters[0], filters[1], self.is_batchnorm, ks=3)\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.conv3 = unetConv2(filters[1], filters[2], self.is_batchnorm, ks=3)\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.conv4 = unetConv2(filters[2], filters[3], self.is_batchnorm, ks=3)\n",
        "        self.maxpool4 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.center = unetConv2(filters[3], filters[4], self.is_batchnorm, ks=3)\n",
        "        self.gating = UnetGridGatingSignal2(filters[4], filters[4], ks=1, is_batchnorm=self.is_batchnorm)\n",
        "\n",
        "        # attention blocks\n",
        "        self.attentionblock2 = MultiAttentionBlock(in_size=filters[1], gate_size=filters[2], inter_size=filters[1],\n",
        "                                                   nonlocal_mode=nonlocal_mode, sub_sample_factor= attention_dsample)\n",
        "        self.attentionblock3 = MultiAttentionBlock(in_size=filters[2], gate_size=filters[3], inter_size=filters[2],\n",
        "                                                   nonlocal_mode=nonlocal_mode, sub_sample_factor= attention_dsample)\n",
        "        self.attentionblock4 = MultiAttentionBlock(in_size=filters[3], gate_size=filters[4], inter_size=filters[3],\n",
        "                                                   nonlocal_mode=nonlocal_mode, sub_sample_factor= attention_dsample)\n",
        "\n",
        "        # upsampling\n",
        "        self.up_concat4 = unetUp2(filters[4], filters[3], False, is_batchnorm)\n",
        "        # self.up_concat4 = unetUp2(512, filters[3], False, is_batchnorm)\n",
        "        self.up_concat3 = unetUp2(filters[3], filters[2], False, is_batchnorm)\n",
        "        self.up_concat2 = unetUp2(filters[2], filters[1], False, is_batchnorm)\n",
        "        self.up_concat1 = unetUp2(filters[1], filters[0], False, is_batchnorm)\n",
        "\n",
        "        # deep supervision\n",
        "        self.dsv4 = UnetDsv2(in_size=filters[3], out_size=n_classes, scale_factor=8)\n",
        "        self.dsv3 = UnetDsv2(in_size=filters[2], out_size=n_classes, scale_factor=4)\n",
        "        self.dsv2 = UnetDsv2(in_size=filters[1], out_size=n_classes, scale_factor=2)\n",
        "        self.dsv1 = nn.Conv2d(in_channels=filters[0], out_channels=n_classes, kernel_size=1)\n",
        "\n",
        "        # final conv (without any concat)\n",
        "        self.final = nn.Conv2d(n_classes*4, n_classes, 1)\n",
        "\n",
        "        # initialise weights\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                init_weights(m, init_type='kaiming')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                init_weights(m, init_type='kaiming')\n",
        "\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        # if self.use_cuda == False:\n",
        "        #     # inputs = inputs.to(dtype=torch.float64)\n",
        "        #     inputs = inputs.double()\n",
        "\n",
        "        # inputs = inputs.double()\n",
        "\n",
        "        # Feature Extraction\n",
        "        conv1 = self.conv1(inputs)\n",
        "        maxpool1 = self.maxpool1(conv1)\n",
        "\n",
        "        conv2 = self.conv2(maxpool1)\n",
        "        maxpool2 = self.maxpool2(conv2)\n",
        "\n",
        "        conv3 = self.conv3(maxpool2)\n",
        "        maxpool3 = self.maxpool3(conv3)\n",
        "\n",
        "        conv4 = self.conv4(maxpool3)\n",
        "        maxpool4 = self.maxpool4(conv4)\n",
        "\n",
        "        # Gating Signal Generation\n",
        "        center = self.center(maxpool4)\n",
        "        gating = self.gating(center)\n",
        "\n",
        "        # Attention Mechanism\n",
        "        # Upscaling Part (Decoder)\n",
        "        g_conv4, att4 = self.attentionblock4(conv4, gating)\n",
        "        up4 = self.up_concat4(g_conv4, center)\n",
        "        g_conv3, att3 = self.attentionblock3(conv3, up4)\n",
        "        up3 = self.up_concat3(g_conv3, up4)\n",
        "        g_conv2, att2 = self.attentionblock2(conv2, up3)\n",
        "        up2 = self.up_concat2(g_conv2, up3)\n",
        "        up1 = self.up_concat1(conv1, up2)\n",
        "\n",
        "        # Deep Supervision\n",
        "        dsv4 = self.dsv4(up4)\n",
        "        dsv3 = self.dsv3(up3)\n",
        "        dsv2 = self.dsv2(up2)\n",
        "        dsv1 = self.dsv1(up1)\n",
        "        final = self.final(torch.cat([dsv1,dsv2,dsv3,dsv4], dim=1))\n",
        "\n",
        "        final = torch.sigmoid(final)\n",
        "\n",
        "        return final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq628aADYjqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rle2mask(rle, width, height):\n",
        "    mask= np.zeros(width* height)\n",
        "    array = np.asarray([int(x) for x in rle.split()])\n",
        "    starts = array[0::2]\n",
        "    lengths = array[1::2]\n",
        "\n",
        "    current_position = 0\n",
        "    for index, start in enumerate(starts):\n",
        "        current_position += start\n",
        "        mask[current_position:current_position+lengths[index]] = 255\n",
        "        current_position += lengths[index]\n",
        "\n",
        "    return mask.reshape(width, height)\n",
        "    \n",
        "class SIMMDataset(Dataset):\n",
        "    \"\"\"SIMM dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, root_dir, dir_postfix, split, transform=None, preload_data=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            dicomPaths (Array<string>): Array of DICOM file Paths.\n",
        "            mask_csv_file (string): csv file with encoded masks (rle).\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "\n",
        "        self.root_dir = root_dir\n",
        "        self.dir_postfix = dir_postfix\n",
        "\n",
        "        self.im_height = 1024\n",
        "        self.im_width = 1024\n",
        "        self.im_chan = 1\n",
        "\n",
        "        ## Read masks file\n",
        "        mask_csv_file = root_dir + '/train-rle.csv' \n",
        "        self.encodedMasks = pd.read_csv(mask_csv_file, names=['ImageId', 'EncodedPixels'], index_col='ImageId')\n",
        "\n",
        "        ## Read dataset file names\n",
        "        dsFile = root_dir + '/simm_DS_' + split + '.csv'\n",
        "        dsFileData = pd.read_csv(dsFile)\n",
        "        self.dicomPaths = dsFileData['path'].tolist()\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dicomPaths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        dPath = self.dicomPaths[idx]\n",
        "        dicom = pydicom.dcmread(self.root_dir + self.dir_postfix + dPath)\n",
        "        \n",
        "#         image = np.zeros((1, im_height, im_width, im_chan), dtype=np.uint8)\n",
        "#         image = np.expand_dims(dicom.pixel_array, axis=2)\n",
        "        image = np.array(dicom.pixel_array)\n",
        "        \n",
        "        # get mask (in rle) from csv\n",
        "        landmarks = np.zeros((self.im_height, self.im_width), dtype=np.bool)\n",
        "        \n",
        "        fileId = dPath.split('/')[-1][:-4]\n",
        "        rle = self.encodedMasks.loc[fileId, 'EncodedPixels']\n",
        "        try:\n",
        "            if type(rle) == str: # if single rle\n",
        "                decodedRle = rle2mask(rle, self.im_height, self.im_width)\n",
        "#                 landmarks = np.expand_dims(decodedRle, axis=2)\n",
        "                landmarks = decodedRle\n",
        "            else: # if multiple rle\n",
        "                for x in rle:\n",
        "                    decodedRle = rle2mask(x, self.im_height, self.im_width)\n",
        "                    landmarks = landmarks + decodedRle\n",
        "#                     landmarks = landmarks + np.expand_dims(decodedRle, axis=2)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            \n",
        "        #### TODO - IMPORTANT::: CHECK THIS  \n",
        "        ## QUESTION: SHOULD WE TRANSPOSE THE MASK IN THE GETITEM FUNCTION \n",
        "        ## BECAUSE WHEN PLOTING THE GRAPHS WE HAVE TO TRANSPOSE IT.\n",
        "        landmarks = landmarks.T\n",
        "\n",
        "        # for some images, we have multiple masks, so we are adding the masks\n",
        "        # which results in some pixels to > 1\n",
        "        landmarks = (landmarks >= 1).astype('float64')\n",
        "            \n",
        "        sample = {'image': image, 'mask': landmarks}\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        img = np.expand_dims(sample['image'], axis=0)\n",
        "        mk = np.expand_dims(sample['mask'], axis=0)\n",
        "\n",
        "        img = img / 255\n",
        "\n",
        "        return img, mk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOuDOXyMaAtw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SIMMSoftDiceLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SIMMSoftDiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        smooth = 0.01\n",
        "        batch_size = input.size(0)\n",
        "\n",
        "        # input = torch.sigmoid(input).view(batch_size, -1)\n",
        "        input = input.view(batch_size, -1)\n",
        "        target = target.contiguous().view(batch_size, -1)\n",
        "\n",
        "        inter = torch.sum(input * target, 1) + smooth\n",
        "        union = torch.sum(input, 1) + torch.sum(target, 1) + smooth\n",
        "\n",
        "        score = torch.sum(2.0 * inter / union, 0)\n",
        "        score = 1.0 - score / float(batch_size)\n",
        "        \n",
        "        return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WJHsD61abow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "json_opts = {\n",
        "  \"use_cuda\": True,\n",
        "  \"network_debug\": 0,\n",
        "  \"training\": {\n",
        "    \"arch_type\": \"simm_unet\",\n",
        "    \"n_epochs\": 100,\n",
        "    \"save_epoch_freq\": 10,\n",
        "    \"lr_policy\": \"step\",\n",
        "    \"lr_decay_iters\": 25,\n",
        "    \"batchSize\": 4,\n",
        "    \"preloadData\": True,\n",
        "    \"network_debug\": 0\n",
        "  },\n",
        "  \"visualisation\":{\n",
        "    \"display_port\": 8097,\n",
        "    \"display_server\": \"http://54.89.248.230\",\n",
        "    \"no_html\": True,\n",
        "    \"display_winsize\": 256,\n",
        "    \"display_id\": 1,\n",
        "    \"display_single_pane_ncols\": 0\n",
        "  },\n",
        "  \"data_path\": {\n",
        "    \"simm_unet\": \"/content/data\",\n",
        "    \"postfix\": \"/input/siim/\"\n",
        "  },\n",
        "  \"augmentation\": {\n",
        "  },\n",
        "  \"model\":{\n",
        "    \"type\":\"seg\",\n",
        "    \"continue_train\": False,\n",
        "    \"which_epoch\": -1,\n",
        "    \"model_type\": \"unet_simm\",\n",
        "    \"tensor_dim\": \"2D\",\n",
        "    \"division_factor\": 16,\n",
        "    \"input_nc\": 1,\n",
        "    \"output_nc\": 1,\n",
        "    \"lr_rate\": 1e-4,\n",
        "    \"l2_reg_weight\": 1e-6,\n",
        "    \"feature_scale\": 4,\n",
        "    \"gpu_ids\": [],\n",
        "    \"isTrain\": True,\n",
        "    \"checkpoints_dir\": \"./checkpoints\",\n",
        "    \"experiment_name\": \"experiment_unet_simm\",\n",
        "    \"criterion\": \"SIMMSoftDiceLoss\",\n",
        "    \"optim\": \"adam\",\n",
        "    \"n_classes\": 1\n",
        "  }\n",
        "}\n",
        "\n",
        "import json\n",
        "import collections\n",
        "def json_file_to_pyobj(jsonStr):\n",
        "    def _json_object_hook(d): return collections.namedtuple('X', d.keys())(*d.values())\n",
        "    def json2obj(data): return json.loads(data, object_hook=_json_object_hook)\n",
        "    return json2obj(jsonStr)\n",
        "\n",
        "json_opts = json_file_to_pyobj(json.dumps(json_opts))\n",
        "train_opts = json_opts.training\n",
        "model_opts = json_opts.model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SNziec4bb8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numWorkers = 2\n",
        "# Setup Dataset and Augmentation\n",
        "ds_class = SIMMDataset\n",
        "ds_path = json_opts.data_path.simm_unet\n",
        "ds_postfix = json_opts.data_path.postfix\n",
        "\n",
        "# ds_transform = get_dataset_transformation(arch_type, opts=json_opts.augmentation)\n",
        "\n",
        "train_dataset = ds_class(ds_path, ds_postfix, split='train',      transform=None, preload_data=train_opts.preloadData)\n",
        "valid_dataset = ds_class(ds_path, ds_postfix, split='validation', transform=None, preload_data=train_opts.preloadData)\n",
        "# test_dataset  = ds_class(ds_path, split='test',       transform=None, preload_data=train_opts.preloadData)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, num_workers=numWorkers, batch_size=train_opts.batchSize, shuffle=True)\n",
        "valid_loader = DataLoader(dataset=valid_dataset, num_workers=numWorkers, batch_size=train_opts.batchSize, shuffle=False)\n",
        "# test_loader  = DataLoader(dataset=test_dataset,  num_workers=numWorkers, batch_size=train_opts.batchSize, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuFU4n1AXaG_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a728570d-a5d9-4580-a29f-03978c99c7e9"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  gpu_count = torch.cuda.device_count()\n",
        "  print(\"Available GPU count:\" + str(gpu_count))\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Available GPU count:1\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEsBmffec2SS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4b4e290f-3ac7-4223-8294-926746f57691"
      },
      "source": [
        "# Setup the NN Model\n",
        "# (self, feature_scale=4, n_classes=21, is_deconv=True, in_channels=3,\n",
        "#                  nonlocal_mode='concatenation', attention_dsample=(2,2,2), is_batchnorm=True)\n",
        "\n",
        "model = unet_simm(n_classes=1,\n",
        "                      is_batchnorm=True,\n",
        "                      in_channels=1,\n",
        "                      nonlocal_mode='concatenation',\n",
        "                      feature_scale=4,\n",
        "                      attention_dsample=(2,2),\n",
        "                      is_deconv=False)\n",
        "model = model.to(device)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWP0_B1Gf8-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualisation Parameters\n",
        "# visualizer = Visualiser(json_opts.visualisation, save_dir=model.save_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFqbfplFcymv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "outputId": "1e2347b6-f2fb-4a3a-ee15-9ab356d1596a"
      },
      "source": [
        "# if Config.use_cuda:\n",
        "    # torch.cuda.empty_cache()\n",
        "\n",
        "criterion = SIMMSoftDiceLoss()\n",
        "optimizer = optim.Adam(model.parameters(),\n",
        "                        lr=model_opts.lr_rate,\n",
        "                        betas=(0.9, 0.999),\n",
        "                        weight_decay=model_opts.l2_reg_weight)\n",
        "\n",
        "# optimizer = optim.SGD(params,\n",
        "#                               lr=option.lr_rate,\n",
        "#                               momentum=0.9,\n",
        "#                               nesterov=True,\n",
        "#                               weight_decay=option.l2_reg_weight)\n",
        "\n",
        "\n",
        "# Training Function\n",
        "# model.set_scheduler(train_opts)\n",
        "for epoch in range(model_opts.which_epoch, train_opts.n_epochs):\n",
        "    print('############# Running epoch: %d...\\n' % (epoch))\n",
        "\n",
        "    # Training Iterations\n",
        "    running_loss = 0.0\n",
        "    for epoch_iter, (images, labels) in tqdm(enumerate(train_loader, 1), total=len(train_loader)):\n",
        "        # Make a training update\n",
        "        inputs = images.float().to(device)\n",
        "        masks = labels.to(device)\n",
        "        # assert input.size() == target.size()\n",
        "        \n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, masks)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if epoch_iter % 20 == 0:\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, epoch_iter + 1, running_loss / 20))\n",
        "            running_loss = 0.0\n",
        "\n",
        "    # Update the model learning rate\n",
        "    # model.update_learning_rate()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "############# Running epoch: -1...\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/401 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "  5%|▍         | 20/401 [00:18<05:50,  1.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0,    21] loss: 0.964\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 10%|▉         | 40/401 [00:37<05:41,  1.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0,    41] loss: 0.942\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 15%|█▍        | 60/401 [00:56<05:30,  1.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0,    61] loss: 0.921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|█▉        | 80/401 [01:16<05:17,  1.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0,    81] loss: 0.924\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25%|██▍       | 100/401 [01:36<04:54,  1.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0,   101] loss: 0.920\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 30%|██▉       | 120/401 [01:55<04:31,  1.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0,   121] loss: 0.910\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35%|███▍      | 140/401 [02:14<04:11,  1.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0,   141] loss: 0.887\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|███▉      | 160/401 [02:34<03:54,  1.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0,   161] loss: 0.894\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 41%|████▏     | 166/401 [02:40<03:48,  1.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-7e61a1676df0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}